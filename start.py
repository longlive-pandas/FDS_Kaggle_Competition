# -*- coding: utf-8 -*-
"""start.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13S31YP5TJLbvHlOe_0yVYq87hQUCC0Wy
"""

import json
import pandas as pd
import os
from scipy.stats import linregress
# Simplified Pok√©mon type effectiveness chart
# Values: 2.0 = super effective, 0.5 = not very effective, 0.0 = no effect
type_chart = {
    "Normal":     {"Rock":0.5, "Ghost":0.0, "Steel":0.5},
    "Fire":       {"Fire":0.5, "Water":0.5, "Grass":2.0, "Ice":2.0, "Bug":2.0, "Rock":0.5, "Dragon":0.5, "Steel":2.0},
    "Water":      {"Fire":2.0, "Water":0.5, "Grass":0.5, "Ground":2.0, "Rock":2.0, "Dragon":0.5},
    "Electric":   {"Water":2.0, "Electric":0.5, "Grass":0.5, "Ground":0.0, "Flying":2.0, "Dragon":0.5},
    "Grass":      {"Fire":0.5, "Water":2.0, "Grass":0.5, "Poison":0.5, "Ground":2.0, "Flying":0.5, "Bug":0.5, "Rock":2.0, "Dragon":0.5, "Steel":0.5},
    "Ice":        {"Fire":0.5, "Water":0.5, "Grass":2.0, "Ground":2.0, "Flying":2.0, "Dragon":2.0, "Steel":0.5},
    "Fighting":   {"Normal":2.0, "Ice":2.0, "Rock":2.0, "Dark":2.0, "Steel":2.0, "Poison":0.5, "Flying":0.5, "Psychic":0.5, "Bug":0.5, "Ghost":0.0, "Fairy":0.5},
    "Poison":     {"Grass":2.0, "Poison":0.5, "Ground":0.5, "Rock":0.5, "Ghost":0.5, "Steel":0.0, "Fairy":2.0},
    "Ground":     {"Fire":2.0, "Electric":2.0, "Grass":0.5, "Poison":2.0, "Flying":0.0, "Bug":0.5, "Rock":2.0, "Steel":2.0},
    "Flying":     {"Electric":0.5, "Grass":2.0, "Fighting":2.0, "Bug":2.0, "Rock":0.5, "Steel":0.5},
    "Psychic":    {"Fighting":2.0, "Poison":2.0, "Psychic":0.5, "Dark":0.0, "Steel":0.5},
    "Bug":        {"Fire":0.5, "Grass":2.0, "Fighting":0.5, "Poison":0.5, "Flying":0.5, "Psychic":2.0, "Ghost":0.5, "Dark":2.0, "Steel":0.5, "Fairy":0.5},
    "Rock":       {"Fire":2.0, "Ice":2.0, "Fighting":0.5, "Ground":0.5, "Flying":2.0, "Bug":2.0, "Steel":0.5},
    "Ghost":      {"Normal":0.0, "Psychic":2.0, "Ghost":2.0, "Dark":0.5},
    "Dragon":     {"Dragon":2.0, "Steel":0.5, "Fairy":0.0},
    "Dark":       {"Fighting":0.5, "Psychic":2.0, "Ghost":2.0, "Fairy":0.5},
    "Steel":      {"Fire":0.5, "Water":0.5, "Electric":0.5, "Ice":2.0, "Rock":2.0, "Fairy":2.0, "Steel":0.5},
    "Fairy":      {"Fire":0.5, "Fighting":2.0, "Poison":0.5, "Dragon":2.0, "Dark":2.0, "Steel":0.5}
}

#0 Mean CV accuracy: 83.59% (+/- 0.64%)
#1 Mean CV accuracy: 83.62% (+/- 0.67%)
def hp_advantage_trend(battle):
    """Compute the linear slope of Player 1's HP advantage over 30 turns."""
    hp_adv = []
    for turn in battle['battle_timeline']:
        p1_hp = turn['p1_pokemon_state']['hp_pct']
        p2_hp = turn['p2_pokemon_state']['hp_pct']
        hp_adv.append(p1_hp - p2_hp)
    x = np.arange(len(hp_adv))
    slope, _, _, _, _ = linregress(x, hp_adv)
    return slope

#2 Mean CV accuracy: 83.55% (+/- 0.63%)
"""
A small decrease (‚âà 0.05 %) means:
The new status_duration_ratio feature adds noise but not independent signal.
The effect of bad statuses is already encoded in your existing features ‚Äî especially p1_bad_status_advantage and status_change_diff, both of which have strong correlations (¬±0.5 ‚Äì 0.6) with the target.
Logistic Regression, being linear, can‚Äôt easily ‚Äúdisentangle‚Äù two highly collinear features, so adding another version of the same concept just shifts weights slightly.
"""
def status_duration_ratio(battle):
    p1_turns_bad = sum(turn['p1_pokemon_state']['status'] != 'nostatus' for turn in battle['battle_timeline'])
    p2_turns_bad = sum(turn['p2_pokemon_state']['status'] != 'nostatus' for turn in battle['battle_timeline'])
    return (p2_turns_bad + 1) / (p1_turns_bad + 1)
#3 Pre-battle info
#Mean CV accuracy: 83.59% (+/- 0.64%)
"""
Your feature space is already highly saturated with the key linear signals ‚Äî the Logistic Regression can‚Äôt extract more because:
Many of your engineered variables (HP diffs, status advantages, competitiveness metrics) are strongly correlated with one another.
Logistic Regression can only assign one weight per direction of correlation, so redundant inputs don‚Äôt add discriminative power.
You‚Äôre probably sitting near the model‚Äôs linear ceiling for this dataset (~83‚Äì84%).
This is good news ‚Äî it means your data cleaning and baseline engineering are solid.
Now, the final 2‚Äì3% (to reach 86%) likely requires non-linear relationships or interaction modeling.
"""
def team_stat_variance(team):
    """Average variance of base stats within Player 1's team."""
    stats = ['base_hp', 'base_atk', 'base_def', 'base_spa', 'base_spd', 'base_spe']
    # Compute variance of each stat across the 6 Pok√©mon, then take the mean
    return float(np.mean([np.var([p[s] for p in team]) for s in stats]))

def team_type_diversity(team):
    """Proportion of distinct Pok√©mon types in the team."""
    all_types = [t for p in team for t in p['types'] if t != 'notype']
    if not all_types:
        return 0.0
    return len(set(all_types)) / len(all_types)

def lead_stat_diff(p1_team, p2_lead):
    """Average stat difference between Player 1's team mean and Player 2's lead Pok√©mon."""
    stats = ['base_hp', 'base_atk', 'base_def', 'base_spa', 'base_spd', 'base_spe']
    p1_mean = np.mean([[p[s] for s in stats] for p in p1_team], axis=0)
    p2_stats = np.array([p2_lead[s] for s in stats])
    return float(np.mean(p1_mean - p2_stats))

#5 p1_move_damage_mean, p2_move_damage_mean, diff_move_damage_mean
def move_damage_efficiency(battle):
    moves = [t.get('p1_move_details', {}) for t in battle['battle_timeline'] if t.get('p1_move_details')]
    if not moves: return 0
    total_damage = sum(m.get('damage', 0) for m in moves)
    return total_damage / len(moves)  # avg damage per move
#6 p1_first_strike_ratio, tempo_advantage = first_strike_ratio - 0.5
"""
Cross-validation accuracies: [0.844  0.827  0.831  0.8375 0.835 ]
Mean CV accuracy: 83.49% (+/- 0.58%)

1. Logistic regression doesn‚Äôt automatically benefit from new features
Even though new features (like p1_move_damage_mean or tempo_advantage) sound informative,
your model is a linear classifier with L1 penalty.
If the new variables:
are correlated with existing ones (hp_diff_mean, diff_final_hp, etc.),
or noisy (e.g. move damage varying randomly per battle),
then logistic regression‚Äôs L1 regularization will zero them out,
or worse ‚Äî slightly destabilize weights and hurt generalization by adding variance.
That‚Äôs why performance went from 83.52 ‚Üí 83.49% ‚Äî statistically flat, but slightly worse.
‚öôÔ∏è 2. These specific features overlap conceptually with existing ones
New Feature	Likely Redundant With	Explanation
p1_move_damage_mean, diff_move_damage_mean	diff_final_hp, hp_diff_mean	Both describe how much damage one side deals over time.
p1_first_strike_ratio, tempo_advantage	hp_delta_trend	Both encode ‚Äúinitiative‚Äù: who tends to lead or inflict earlier HP drops.
So they add little new orthogonal signal ‚Äî linear models can‚Äôt combine correlated predictors effectively.
üß© 3. Why it doesn‚Äôt mean they‚Äôre useless
These features might be valuable for:
nonlinear models (Random Forest, Gradient Boosting, XGBoost)
interaction terms (e.g. PolynomialFeatures, cross terms)
or temporal clustering if used with per-turn modeling.
But in your current setup (L1 LogisticRegressionCV), adding correlated variables = minor penalty.
"""
def first_strike_ratio(battle):
    timeline = battle.get("battle_timeline", [])
    if len(timeline) < 2:
        return 0.0

    p1_hp = [t["p1_pokemon_state"]["hp_pct"] for t in timeline if t.get("p1_pokemon_state")]
    p2_hp = [t["p2_pokemon_state"]["hp_pct"] for t in timeline if t.get("p2_pokemon_state")]

    # approximate: if p2_hp decreases before p1_hp does, p1 attacked first
    p1_first_hits = sum((p2_hp[i] - p2_hp[i+1]) > (p1_hp[i] - p1_hp[i+1]) for i in range(len(p1_hp)-1))
    ratio = p1_first_hits / (len(p1_hp) - 1)
    return ratio

#7 hp_momentum_flips, hp_flip_rate = flips / len(timeline)
"""perf drop
Cross-validation accuracies: [0.841  0.8285 0.832  0.8385 0.8355]
Mean CV accuracy: 83.51% (+/- 0.45%)
hp_momentum_flips is a temporal volatility feature ‚Äî it counts how many times the HP advantage flips between the two players.
It measures ‚Äúmomentum chaos‚Äù: stable battles (few flips) vs. back-and-forth ones (many flips).

Why performance drops when adding more features
You‚Äôre already near the linear ceiling.
Logistic regression is extracting essentially all the linear signal your data has ‚Äî roughly 83.6 ¬± 0.6 % looks like your model‚Äôs upper bound.
Additional features that are noisy or weakly correlated tend to only add variance, not information.
New features like hp_momentum_flips and hp_flip_rate are non-linear effects.
They‚Äôre based on the sequence dynamics of battles, which a linear model can‚Äôt capture well unless the relationship with player_won is monotonic.
Logistic regression assumes a smooth, single-direction effect ‚Äî but volatility in battles isn‚Äôt monotonic:
Some flips = competitive battle (either could win)
Too few flips = complete dominance (p1 wins or loses early)
That kind of U-shape is invisible to linear models.
L1 regularization doesn‚Äôt help if new variables are weakly correlated.
Even though the L1 penalty tries to zero out irrelevant features, slight noise in the cross-validation folds can make the coefficients dance a bit ‚Üí small accuracy drop.
‚öôÔ∏è What this means for you
‚úÖ Your base feature set is solid ‚Äî most meaningful information is already encoded in HP, final differences, and status metrics.
‚ö†Ô∏è New dynamic features (momentum, tempo, move damage) will help only if you switch to:
tree-based models (RandomForest, XGBoost, LightGBM), or
polynomial / interaction expansion of selected features.
"""
def hp_momentum_flips(battle):
    timeline = battle.get("battle_timeline", [])
    if len(timeline) < 2:
        return 0.0
    hp_adv = np.array([
        t.get("p1_pokemon_state", {}).get("hp_pct", 0) -
        t.get("p2_pokemon_state", {}).get("hp_pct", 0)
        for t in timeline
    ])
    # Count how many times the advantage sign changes
    flips = np.sum(np.sign(hp_adv[1:]) != np.sign(hp_adv[:-1]))
    return float(flips)

#8 p1_lead_type_advantage, p2_lead_type_advantage, diff_type_advantage
def type_effectiveness(attacker_types, defender_types):
    """Compute average type effectiveness multiplier between attacker and defender."""
    if not attacker_types or not defender_types:
        return 1.0  # neutral if missing

    values = []
    for a in attacker_types:
        if a not in type_chart:
            continue
        for d in defender_types:
            values.append(type_chart[a].get(d, 1.0))  # default to neutral (1.0)
    return np.mean(values) if values else 1.0

#9 battle_duration, hp_loss_rate = diff_final_hp / battle_duration
def battle_duration(battle):
    return len([t for t in battle['battle_timeline'] if t['p1_pokemon_state']['hp_pct'] > 0 and
                                                     t['p2_pokemon_state']['hp_pct'] > 0])
#10 p1_team_imbalance, p2_team_imbalance, diff_team_imbalance
"""
Why battle_duration and hp_loss_rate helped
These two features add time-normalized efficiency, which Logistic Regression can model linearly:
Feature	Meaning	Why it helps
battle_duration	How long both sides were active	Distinguishes between decisive vs drawn-out matches
hp_loss_rate	HP difference per turn	Captures speed of dominance ‚Äî short + large HP gap = strong linear win signal
They add orthogonal information to your HP and final-state metrics (diff_final_hp, hp_delta_trend), improving linear separability.
"""
def team_stat_imbalance(team):
    totals = [p['base_hp']+p['base_atk']+p['base_def']+p['base_spa']+p['base_spd']+p['base_spe'] for p in team]
    return np.std(totals) / np.mean(totals)
"""
attack_to_speed_ratio = diff_atk / (diff_spe + 1e-6)
hp_control_ratio = hp_diff_mean / hp_delta_std
status_pressure = status_change_diff / (hp_momentum_flips + 1)
"""
# --- Define the path to our data ---
COMPETITION_NAME = 'fds-pokemon-battles-prediction-2025'
DATA_PATH = os.path.join('input', COMPETITION_NAME)

train_file_path = os.path.join(DATA_PATH, 'train.jsonl')
test_file_path = os.path.join(DATA_PATH, 'test.jsonl')
train_data = []

# Read the file line by line
print(f"Loading data from '{train_file_path}'...")
try:
    with open(train_file_path, 'r') as f:
        for line in f:
            # json.loads() parses one line (one JSON object) into a Python dictionary
            train_data.append(json.loads(line))

    print(f"Successfully loaded {len(train_data)} battles.")

    # Let's inspect the first battle to see its structure
    print("\n--- Structure of the first train battle: ---")
    if train_data:
        first_battle = train_data[0]

        # To keep the output clean, we can create a copy and truncate the timeline
        battle_for_display = first_battle.copy()
        battle_for_display['battle_timeline'] = battle_for_display.get('battle_timeline', [])[:2] # Show first 2 turns

        # Use json.dumps for pretty-printing the dictionary
        print(json.dumps(battle_for_display, indent=4))
        if len(first_battle.get('battle_timeline', [])) > 3:
            print("    ...")
            print("    (battle_timeline has been truncated for #display)")


except FileNotFoundError:
    print(f"ERROR: Could not find the training file at '{train_file_path}'.")
    print("Please make sure you have added the competition data to this notebook.")

from tqdm.notebook import tqdm
import numpy as np
# --- Type effectiveness table (semplificata) ---
import numpy as np
TYPE_EFFECTIVENESS = {
    ('fire', 'grass'): 2.0,
    ('water', 'fire'): 2.0,
    ('electric', 'water'): 2.0,
    ('grass', 'water'): 2.0,
    ('ice', 'grass'): 2.0,
    ('psychic', 'poison'): 2.0,
    ('ground', 'electric'): 2.0,
    ('rock', 'fire'): 2.0,
    ('fighting', 'normal'): 2.0,
    ('ghost', 'psychic'): 2.0,
    # neutral = 1.0 if not found
}

def type_advantage(team_types: list[str], opp_types: list[str]) -> float:
    """
    Compute the average type advantage multiplier for player1's team
    against opponent's lead types.
    """
    scores = []
    for t1 in team_types:
        for t2 in opp_types:
            scores.append(TYPE_EFFECTIVENESS.get((t1.lower(), t2.lower()), 1.0))
    return np.mean(scores) if scores else 1.0


def create_simple_features(data: list[dict]) -> pd.DataFrame:
    feature_list = []
    #p1_bad_status_advantage = []
    status_change_diff = []
    for battle in tqdm(data, desc="Extracting features"):

        features = {}

        # --- Player 1 Team Features ---
        p1_mean_hp = p1_mean_spe = p1_mean_atk = p1_mean_def = p1_mean_sp = 0.0
        p1_lead_hp = p1_lead_spe = p1_lead_atk = p1_lead_def = p1_lead_sp = 0.0

        p1_team = battle.get('p1_team_details', [])
        if p1_team:

            p1_mean_hp = np.mean([p.get('base_hp', 0) for p in p1_team])
            p1_mean_spe = np.mean([p.get('base_spe', 0) for p in p1_team])
            p1_mean_atk = np.mean([p.get('base_atk', 0) for p in p1_team])
            p1_mean_def = np.mean([p.get('base_def', 0) for p in p1_team])
            p1_mean_sp = np.mean([p.get('base_spd', 0) for p in p1_team])

            features['p1_mean_hp'] = p1_mean_hp
            features['p1_mean_spe'] = p1_mean_spe
            features['p1_mean_atk'] = p1_mean_atk
            features['p1_mean_def'] = p1_mean_def
            features['p1_mean_sp'] = p1_mean_sp

            #PER UN CONFRONTO EQUO UTILIZZIAMO SOLO DATI DEL LEADER ANCHE NELLA SQUADRA 1 PER LE DIFFERENZE
            p1_lead_hp =  p1_team[0].get('base_hp', 0)
            p1_lead_spe = p1_team[0].get('base_spe', 0)
            p1_lead_atk = p1_team[0].get('base_atk', 0)
            p1_lead_def = p1_team[0].get('base_def', 0)
            p1_lead_sp =  p1_team[0].get('base_spd', 0)



        # --- Player 2 Lead Features ---
        p2_hp = p2_spe = p2_atk = p2_def = p2_sp= 0.0
        p2_lead = battle.get('p2_lead_details')
        if p2_lead:
            # Player 2's lead Pok√©mon's stats
            p2_hp = p2_lead.get('base_hp', 0)
            p2_spe = p2_lead.get('base_spe', 0)
            p2_atk = p2_lead.get('base_atk', 0)
            p2_def = p2_lead.get('base_def', 0)
            p2_sp = p2_lead.get('base_spd', 0)



        # I ADD THE DIFFS/DELTAS
        features['diff_hp']  = p1_lead_hp  - p2_hp
        features['diff_spe'] = p1_lead_spe - p2_spe
        features['diff_atk'] = p1_lead_atk - p2_atk
        features['diff_def'] = p1_lead_def - p2_def
        features['diff_sp'] =  p1_lead_sp - p2_sp

        #8 new
        """
        # --- Type advantage (lead vs. lead) ---
        p1_lead_types = [t for t in p1_team[0].get("types", []) if t != "notype"] if p1_team else []
        p2_lead_types = [t for t in p2_lead.get("types", []) if t != "notype"] if p2_lead else []

        features["p1_lead_type_advantage"] = type_effectiveness(p1_lead_types, p2_lead_types)
        features["p2_lead_type_advantage"] = type_effectiveness(p2_lead_types, p1_lead_types)
        features["diff_type_advantage"] = (
            features["p1_lead_type_advantage"] - features["p2_lead_type_advantage"]
        )
        """
        #new2
        #features['status_duration_ratio'] = status_duration_ratio(battle)

        #new3 - static feat
        """
        features['p1_team_stat_variance'] = team_stat_variance(battle['p1_team_details'])
        features['p1_type_diversity_ratio'] = team_type_diversity(battle['p1_team_details'])
        features['lead_stat_diff'] = lead_stat_diff(battle['p1_team_details'], battle['p2_lead_details'])
        """
        #DYNAMIC INFO
        #Chi mantiene pi√π HP medi e conduce pi√π turni,  nella maggior parte dei casi vince anche se la battaglia non √® ancora finita
        timeline = battle.get('battle_timeline', [])
        if timeline:
            #SALUTE
            p1_hp = [t['p1_pokemon_state']['hp_pct'] for t in timeline if t.get('p1_pokemon_state')]
            p2_hp = [t['p2_pokemon_state']['hp_pct'] for t in timeline if t.get('p2_pokemon_state')]
            #salute media dei pokemon del primo giocatore
            #features['p1_mean_hp_pct'] = np.mean(p1_hp)
            #salute media dei pokemon del secondo giocatore ATTENZIONE FEATURE BUONE CORRELATE CON hp_diff_mean 75%,VALUTAZIONE DELL'EEFFETTO SU BASE SINGOLA (CON HP DIFF)
            #features['p2_mean_hp_pct'] = np.mean(p2_hp)
            #vantaggio medio in salute (media della differenza tra la salute dei pokemon del primo giocatore e quella dei pokemon del secondo giocatore)
            features['hp_diff_mean'] = np.mean(np.array(p1_hp) - np.array(p2_hp))
            # TEST5V--- MOVE DAMAGE EFFICIENCY (uses helper) ---
            features['p1_move_damage_mean'] = move_damage_efficiency({
                'battle_timeline': [
                    t for t in timeline if t.get('p1_move_details')
                ]
            })
            features['p2_move_damage_mean'] = move_damage_efficiency({
                'battle_timeline': [
                    t for t in timeline if t.get('p2_move_details')
                ]
            })
            features['diff_move_damage_mean'] = (
                features['p1_move_damage_mean'] - features['p2_move_damage_mean']
            )
            """6 (performance drop)
            # --- FIRST STRIKE RATIO / TEMPO ADVANTAGE (uses helper) ---
            features['p1_first_strike_ratio'] = first_strike_ratio(battle)
            features['tempo_advantage'] = features['p1_first_strike_ratio'] - 0.5
            """
            #FINE TEST5V
            """
            # TEST5--- MOVE DAMAGE EFFICIENCY ---
            # Compute average damage per move for each player
            p1_moves = [t.get('p1_move_details', {}) for t in timeline if t.get('p1_move_details')]
            p2_moves = [t.get('p2_move_details', {}) for t in timeline if t.get('p2_move_details')]

            if p1_moves:
                p1_total_damage = sum(m.get('damage', 0) for m in p1_moves)
                features['p1_move_damage_mean'] = p1_total_damage / len(p1_moves)
            else:
                features['p1_move_damage_mean'] = 0.0

            if p2_moves:
                p2_total_damage = sum(m.get('damage', 0) for m in p2_moves)
                features['p2_move_damage_mean'] = p2_total_damage / len(p2_moves)
            else:
                features['p2_move_damage_mean'] = 0.0

            # Relative advantage: difference in mean damage dealt per move
            features['diff_move_damage_mean'] = (
                features['p1_move_damage_mean'] - features['p2_move_damage_mean']
            )
            #FINE  TEST5
            """

            #percentuale di tempo in vantaggio (ovvero media dei booleani che indicano il vantaggio => proporzione del vantaggio)
            features['p1_hp_advantage_mean'] = np.mean(np.array(p1_hp) > np.array(p2_hp))#GRAN BELLA OPZIONE DI CLASSIFICAZIONE POSSIBILE APPLICAZIONE DI EFFETTI DI ETEROGENEITA



            #SUM OF FINAL HP PERCENTAGE OF EACH PLAYER
            p1_hp_final ={}
            p2_hp_final ={}
            for t in timeline:
                if t.get('p1_pokemon_state'):
                    p1_hp_final[t['p1_pokemon_state']['name']]=t['p1_pokemon_state']['hp_pct']
                if t.get('p2_pokemon_state'):
                    p2_hp_final[t['p2_pokemon_state']['name']]=t['p2_pokemon_state']['hp_pct']
            #print(p1_hp_final)
            #numero di pockemon usati dal giocatore nei primi 30 turni
            features['p1_n_pokemon_use'] =len(p1_hp_final.keys())
            features['p2_n_pokemon_use'] =len(p2_hp_final.keys())
            #differenza nello schieramento pockemon dopo 30 turni
            features['diff_final_schieramento']=features['p1_n_pokemon_use']-features['p2_n_pokemon_use']
            nr_pokemon_sconfitti_p1 = np.sum([1 for e in list(p1_hp_final.values()) if e==0])
            nr_pokemon_sconfitti_p2 = np.sum([1 for e in list(p2_hp_final.values()) if e==0])
            features['nr_pokemon_sconfitti_p1'] = nr_pokemon_sconfitti_p1
            features['nr_pokemon_sconfitti_p2'] = nr_pokemon_sconfitti_p2
            #features['nr_pokemon_sconfitti_diff'] = nr_pokemon_sconfitti_p1-nr_pokemon_sconfitti_p2
            #DOVREBBERO ESSERE BOMBA VITA DELLE DUE SQUADRE DOPO I 30 TURNI
            features['p1_pct_final_hp'] =np.sum(list(p1_hp_final.values()))+(6-len(p1_hp_final.keys()))
            features['p2_pct_final_hp'] =np.sum(list(p2_hp_final.values()))+(6-len(p1_hp_final.keys()))
            #SAREBBE CLAMOROSO NORMALIZZARLA ANCHE IN BASE ALLA DIFFERENZA DI VITA ASSOLUTA DEI POCKEMON LEADER DEI 2 PLAYER
            features['diff_final_hp']=features['p1_pct_final_hp']-features['p2_pct_final_hp']

            #9 new
            # --- Battle duration and HP loss rate ---
            try:
                dur = battle_duration(battle)
            except Exception:
                dur = 0
            features["battle_duration"] = dur
            features["hp_loss_rate"] = (
                features["diff_final_hp"] / dur if dur > 0 else 0.0
            )

            







            #vedo anche come la salute media evolve nel tempo
            phases = 3 #early, mid, late game
            nr_turns = 30 #numero turni
            slice_idx = nr_turns // phases #slice index must be integer
            #print("slice_idx: ",slice_idx, "len p1_hp: ",len(p1_hp))
            features['early_hp_mean_diff'] = np.mean(np.array(p1_hp[:slice_idx]) - np.array(p2_hp[:slice_idx]))
            features['late_hp_mean_diff'] = np.mean(np.array(p1_hp[-slice_idx:]) - np.array(p2_hp[-slice_idx:]))
            
            
            

            #features['phases_hp_mean_diff'] = features['late_hp_mean_diff'] - features['early_hp_mean_diff']
            #77.94% (+/- 0.35%) => 77.94% (+/- 0.41%)
            hp_delta = np.array(p1_hp) - np.array(p2_hp)
            features['hp_delta_trend'] = np.polyfit(range(len(hp_delta)), hp_delta, 1)[0]
            #new
            features['hp_advantage_trend'] = hp_advantage_trend(battle)
            #6 new --- HP momentum (number of times advantage flips) ---
            """
            features['hp_momentum_flips'] = hp_momentum_flips(battle)
            features['hp_flip_rate'] = features['hp_momentum_flips'] / max(1, len(timeline))
            """
            #fluttuazioni negli hp (andamento della partita: stabile o molto caotica)
            #77.94% (+/- 0.41%) => 79.09% (+/- 1.02%)
            features['p1_hp_std'] = np.std(p1_hp)
            features['p2_hp_std'] = np.std(p2_hp)
            features['hp_delta_std'] = np.std(hp_delta)

            #9.2 new
            # --- Efficiency & stability metrics (#10) ---
            # 1Ô∏è‚É£ Damage per turn: how much advantage P1 gains in HP per turn
            features["damage_per_turn"] = (
                features["diff_move_damage_mean"] / max(1, features["battle_duration"])
            )
            """
            # 2Ô∏è‚É£ Early lead ratio: does early advantage translate into final dominance
            features["early_lead_ratio"] = (
                features["early_hp_mean_diff"] / (abs(features["diff_final_hp"]) + 1e-6)
            )

            # 3Ô∏è‚É£ HP stability ratio: volatility normalized by duration
            features["hp_stability_ratio"] = (
                features["hp_delta_std"] / max(1, features["battle_duration"])
            )
            """
            #fine 9.2

            ##STATUS (default nostatus, gli altri sono considerati negativi - i boost sono positivi)
            p1_status = [t['p1_pokemon_state'].get('status', 'nostatus') for t in timeline if t.get('p1_pokemon_state')]
            p2_status = [t['p2_pokemon_state'].get('status', 'nostatus') for t in timeline if t.get('p2_pokemon_state')]
            total_status = set(p1_status + p2_status)
            no_effect_status = {'nostatus', 'noeffect'}
            negative_status = {s for s in total_status if s not in no_effect_status}
            #mean of negative status
            p1_negative_status_mean = np.mean([s in negative_status for s in p1_status])
            p2_negative_status_mean = np.mean([s in negative_status for s in p2_status])
            #status advantage if p1 applied more status to p2 (differenza delle medie dei negativi)
            features['p1_bad_status_advantage'] = p2_negative_status_mean-p1_negative_status_mean
            #p1_bad_status_advantage.append(features['p1_bad_status_advantage'])
            #how many times status changed?
            # we have to check that first array shifted by 1 is
            # different from the same array excluding the last element
            # (so basically checking if status change in time)
            #somma il nr di volte in cui lo stato cambia, vedi se collineare
            p1_status_change = np.sum(np.array(p1_status[1:]) != np.array(p1_status[:-1]))
            p2_status_change = np.sum(np.array(p2_status[1:]) != np.array(p2_status[:-1]))
            #features['p1_status_change'] = p1_status_change
            #features['p2_status_change'] = p2_status_change
            features['status_change_diff'] = p1_status_change - p2_status_change
            status_change_diff.append(features['status_change_diff'])

            #QUANTO IL TEAM √® BILANCIATO (TIPI E VELOCITA)
            #79.09% (+/- 1.02%) => 79.29% (+/- 0.92%)
            p1_types = [t for p in p1_team for t in p.get('types', []) if t != 'notype']
            features['p1_type_diversity'] = len(set(p1_types))

            MEDIUM_SPEED_THRESHOLD = 90 #medium-speed pokemon
            HIGH_SPEED_THRESHOLD = 100 #fast pokemon
            speeds = np.array([p.get('base_spe', 0) for p in p1_team])
            features['p1_avg_speed_stat_battaglia'] = np.mean(np.array(speeds) > MEDIUM_SPEED_THRESHOLD)
            features['p1_avg_high_speed_stat_battaglia'] = np.mean(np.array(speeds) > HIGH_SPEED_THRESHOLD)


            #COMBINAZIONI DI FEATURE
            #combino vantaggio negli hp con l'avere pochi status negativi
            #79.09% (+/- 1.02%) => 79.13% (+/- 1.06%)
            #features['hp_advantage_no_negative_status'] = features['hp_delta_trend'] * (1 - p1_negative_status_mean)
            #LA FEATURE √® BELLA MA SUPER CORRELATA CON hp_delta_trend 95%
            #per il momento semplifico cosi capiamo poi √® facile aggiungere

        # We also need the ID and the target variable (if it exists)
        features['battle_id'] = battle.get('battle_id')
        if 'player_won' in battle:
            features['player_won'] = int(battle['player_won'])

        feature_list.append(features)

    return pd.DataFrame(feature_list).fillna(0)

# Create feature DataFrames for both training and test sets
print("Processing training data...")
train_df = create_simple_features(train_data)

print("\nProcessing test data...")
test_data = []
with open(test_file_path, 'r') as f:
    for line in f:
        test_data.append(json.loads(line))
test_df = create_simple_features(test_data)

print("\nTraining features preview:")
#display(train_df.head())

"""from sklearn.linear_model import LogisticRegression

# Define our features (X) and target (y)
features = [col for col in train_df.columns if col not in ['battle_id', 'player_won']]
X_train = train_df[features]
y_train = train_df['player_won']

X_test = test_df[features]

# Initialize and train the model
print("Training a simple Logistic Regression model...")
model = LogisticRegression(random_state=42, max_iter=1000)
model.fit(X_train, y_train)
print("Model training complete.")

# Make predictions on the test data
print("Generating predictions on the test set...")
test_predictions = model.predict(X_test)

# Create the submission DataFrame
submission_df = pd.DataFrame({
    'battle_id': test_df['battle_id'],
    'player_won': test_predictions
})

# Save the DataFrame to a .csv file
submission_df.to_csv('submission.csv', index=False)

print("\n'submission.csv' file created successfully!")
#display(submission_df.head())
"""

##new
"""
print(test_df.columns)
print(train_df.columns)
"""
"""
from sklearn.metrics import accuracy_score
val_accuracy = accuracy_score(y_val, val_predictions)
print(f"Validation accuracy: {val_accuracy*100:.2f}%")
"""

#train_df.describe()

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler

# Define features and target
features = [col for col in train_df.columns if col not in ['battle_id', 'player_won']]
X = train_df[features]
y = train_df['player_won']

"""
no, ora faccio k-fold cross validation (sotto)

# Split training data into train and validation sets (80/20 split)
X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, random_state=42
)
"""

"""### SCALING

# Create our scaler
scaler = StandardScaler()

# First, we want to fit our scaler to our training data and subsequently transform
# that training data through our scaler. This can all be done in a single command.
X_train = scaler.fit_transform(X_train)

# Next, we want to transform the test features by using the parameters learned
# from the training set
X_val = scaler.transform(X_val)

# Notice the values are now standardized
columns = X.columns
X_train_scaled_df = pd.DataFrame(X_train, columns = columns)
X_train_scaled_df.head()

### STUDIAMO LA CORRELAZIONE TRA FEATURE E OUTPUT E TRA FEATURE
"""







"""### PolynomialFeatures
crea nuove feature come potenze e relazioni tra le feature numeriche originali, per vedere relazioni non lineari; il modello cattura curvature e relazioni mantenendo la linearit√† nei parametri => purtroppo aggiunge $\binom{n+d}{n}$ feature (n=numero feature originali e d=degree=2 o altro intero) e aumenta il tempo di addestramento => valuta se usare una PCA per gestire l'esplosione dimensionale.

Usalo solo se le feature originali sono informative

### TRAIN AND SUBMIT
"""

"""
# Initialize and train the model
print("Training a simple Logistic Regression model...")
model = LogisticRegression(random_state=42, max_iter=1000)
model.fit(X_train, y_train)
print("Model training complete.")

# Evaluate on validation set
val_predictions = model.predict(X_val)
val_accuracy = accuracy_score(y_val, val_predictions)
print(f"Validation accuracy: {val_accuracy*100:.2f}%")
"""
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import KFold, cross_val_score

#feat_cols = [c for c in train_df.columns if c not in ("player_won","battle_id")]

# PCA?
USE_PCA = False
POLY_ENABLED = False# se enabled 77.64% (+/- 0.69%) altrimenti 77.94% (+/- 0.35%)

steps = []
if POLY_ENABLED:
    steps.append(("poly", PolynomialFeatures(degree=2, include_bias=False)))
#standardizza
steps.append(("scaler", StandardScaler()))
if USE_PCA:
    steps.append(("pca", PCA(n_components=0.95, svd_solver="full")))  # ~95% varianza
steps.append(("logreg", LogisticRegression(max_iter=2000, random_state=42)))

pipe = Pipeline(steps)

#kfold cross-validation
kfold = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold CV
print("Training Logistic Regression con 5-Fold Cross-Validation...\n")
scores = cross_val_score(pipe, X, y, cv=kfold, scoring='accuracy', n_jobs=-1)
print(f"Cross-validation accuracies: {np.round(scores, 4)}")
print(f"Mean CV accuracy: {np.mean(scores)*100:.2f}% (+/- {np.std(scores)*100:.2f}%)")

#Training finale
pipe.fit(X, y)
print("\nFinal model trained on all training data.")
"""
vecchio codice, senza k-fold cross-v

# Train
print("Training Logistic Regression (con scaler{}pca)...".format(" + " if USE_PCA else " senza "))
pipe.fit(X_train, y_train)
print("Model training complete.")

# Valutazione su validation
val_pred = pipe.predict(X_val)
val_acc = accuracy_score(y_val, val_pred)
print(f"Validation accuracy: {val_acc*100:.2f}%")

# Nr componenti PCA usate
if USE_PCA:
    print("Componenti PCA usate:", pipe.named_steps["pca"].n_components_)
"""

"""### SUBMIT"""

# Make predictions on the real test data
X_test = test_df[features]
print("Generating predictions on the test set...")
test_predictions = pipe.predict(X_test)

# Create the submission DataFrame
submission_df = pd.DataFrame({
    'battle_id': test_df['battle_id'],
    'player_won': test_predictions
})

# Save submission CSV
submission_df.to_csv('submission.csv', index=False)
print("\n'submission.csv' file created successfully!")
#display(submission_df.head())