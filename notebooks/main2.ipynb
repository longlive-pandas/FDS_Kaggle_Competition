{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b2b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import importlib\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#reload del modulo caricato la prima volta, per prendere la versione aggiornata\n",
    "import utils.type_effects as type_effects\n",
    "importlib.reload(type_effects)\n",
    "from utils.type_effects import TYPE_EFFECTIVENESS, type_advantage\n",
    "import utils.model as model\n",
    "importlib.reload(model)\n",
    "from utils.model import run_pca, show_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863b312",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbee5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the path to our data ---\n",
    "COMPETITION_NAME = 'fds-pokemon-battles-prediction-2025'\n",
    "DATA_PATH = os.path.join('../input', COMPETITION_NAME)\n",
    "\n",
    "train_file_path = os.path.join(DATA_PATH, 'train.jsonl')\n",
    "test_file_path = os.path.join(DATA_PATH, 'test.jsonl')\n",
    "train_data = []\n",
    "\n",
    "# Read the file line by line\n",
    "print(f\"Loading data from '{train_file_path}'...\")\n",
    "try:\n",
    "    with open(train_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            # json.loads() parses one line (one JSON object) into a Python dictionary\n",
    "            train_data.append(json.loads(line))\n",
    "\n",
    "    print(f\"Successfully loaded {len(train_data)} battles.\")\n",
    "\n",
    "    # Let's inspect the first battle to see its structure\n",
    "    print(\"\\n--- Structure of the first train battle: ---\")\n",
    "    if train_data:\n",
    "        first_battle = train_data[0]\n",
    "        \n",
    "        # To keep the output clean, we can create a copy and truncate the timeline\n",
    "        battle_for_display = first_battle.copy()\n",
    "        battle_for_display['battle_timeline'] = battle_for_display.get('battle_timeline', [])[:2] # Show first 2 turns\n",
    "        \n",
    "        # Use json.dumps for pretty-printing the dictionary\n",
    "        print(json.dumps(battle_for_display, indent=4))\n",
    "        if len(first_battle.get('battle_timeline', [])) > 3:\n",
    "            print(\"    ...\")\n",
    "            print(\"    (battle_timeline has been truncated for display)\")\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find the training file at '{train_file_path}'.\")\n",
    "    print(\"Please make sure you have added the competition data to this notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c97aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_features(data: list[dict]) -> pd.DataFrame:\n",
    "    feature_list = []\n",
    "    #p1_bad_status_advantage = []\n",
    "    status_change_diff = []\n",
    "    for battle in tqdm(data, desc=\"Extracting features\"):\n",
    "        \n",
    "        features = {}\n",
    "        \n",
    "        # --- Player 1 Team Features ---\n",
    "        p1_mean_hp = p1_mean_spe = p1_mean_atk = p1_mean_def = p1_mean_sp = 0.0\n",
    "        p1_lead_hp = p1_lead_spe = p1_lead_atk = p1_lead_def = p1_lead_sp = 0.0\n",
    "\n",
    "        p1_team = battle.get('p1_team_details', [])\n",
    "        if p1_team:\n",
    "\n",
    "            p1_mean_hp = np.mean([p.get('base_hp', 0) for p in p1_team])\n",
    "            p1_mean_spe = np.mean([p.get('base_spe', 0) for p in p1_team])\n",
    "            p1_mean_atk = np.mean([p.get('base_atk', 0) for p in p1_team])\n",
    "            p1_mean_def = np.mean([p.get('base_def', 0) for p in p1_team])\n",
    "            p1_mean_sp = np.mean([p.get('base_spd', 0) for p in p1_team])\n",
    "\n",
    "            features['p1_mean_hp'] = p1_mean_hp\n",
    "            features['p1_mean_spe'] = p1_mean_spe\n",
    "            features['p1_mean_atk'] = p1_mean_atk\n",
    "            features['p1_mean_def'] = p1_mean_def\n",
    "            features['p1_mean_sp'] = p1_mean_sp\n",
    "\n",
    "            #PER UN CONFRONTO EQUO UTILIZZIAMO SOLO DATI DEL LEADER ANCHE NELLA SQUADRA 1 PER LE DIFFERENZE            \n",
    "            p1_lead_hp =  p1_team[0].get('base_hp', 0)      \n",
    "            p1_lead_spe = p1_team[0].get('base_spe', 0)  \n",
    "            p1_lead_atk = p1_team[0].get('base_atk', 0)  \n",
    "            p1_lead_def = p1_team[0].get('base_def', 0)  \n",
    "            p1_lead_sp =  p1_team[0].get('base_spd', 0)  \n",
    "\n",
    "\n",
    "\n",
    "        # --- Player 2 Lead Features ---\n",
    "        p2_hp = p2_spe = p2_atk = p2_def = p2_sp= 0.0\n",
    "        p2_lead = battle.get('p2_lead_details')\n",
    "        if p2_lead:\n",
    "            # Player 2's lead Pokémon's stats\n",
    "            p2_hp = p2_lead.get('base_hp', 0)\n",
    "            p2_spe = p2_lead.get('base_spe', 0)\n",
    "            p2_atk = p2_lead.get('base_atk', 0)\n",
    "            p2_def = p2_lead.get('base_def', 0)\n",
    "            p2_sp = p2_lead.get('base_spd', 0)\n",
    "            \n",
    "\n",
    "\n",
    "        # I ADD THE DIFFS/DELTAS\n",
    "        features['diff_hp']  = p1_lead_hp  - p2_hp\n",
    "        features['diff_spe'] = p1_lead_spe - p2_spe\n",
    "        features['diff_atk'] = p1_lead_atk - p2_atk\n",
    "        features['diff_def'] = p1_lead_def - p2_def\n",
    "        features['diff_sp'] =  p1_lead_sp - p2_sp\n",
    "        \n",
    "\n",
    "\n",
    "        #DYNAMIC INFO\n",
    "        #Chi mantiene più HP medi e conduce più turni,  nella maggior parte dei casi vince anche se la battaglia non è ancora finita\n",
    "        timeline = battle.get('battle_timeline', [])\n",
    "        if timeline:\n",
    "            #SALUTE\n",
    "            p1_hp = [t['p1_pokemon_state']['hp_pct'] for t in timeline if t.get('p1_pokemon_state')]\n",
    "            p2_hp = [t['p2_pokemon_state']['hp_pct'] for t in timeline if t.get('p2_pokemon_state')]\n",
    "            #salute media dei pokemon del primo giocatore\n",
    "            #features['p1_mean_hp_pct'] = np.mean(p1_hp)\n",
    "            #salute media dei pokemon del secondo giocatore ATTENZIONE FEATURE BUONE CORRELATE CON hp_diff_mean 75%,VALUTAZIONE DELL'EEFFETTO SU BASE SINGOLA (CON HP DIFF)\n",
    "            #features['p2_mean_hp_pct'] = np.mean(p2_hp)\n",
    "            #vantaggio medio in salute (media della differenza tra la salute dei pokemon del primo giocatore e quella dei pokemon del secondo giocatore)\n",
    "            features['hp_diff_mean'] = np.mean(np.array(p1_hp) - np.array(p2_hp))\n",
    "            #percentuale di tempo in vantaggio (ovvero media dei booleani che indicano il vantaggio => proporzione del vantaggio)\n",
    "            features['p1_hp_advantage_mean'] = np.mean(np.array(p1_hp) > np.array(p2_hp))#GRAN BELLA OPZIONE DI CLASSIFICAZIONE POSSIBILE APPLICAZIONE DI EFFETTI DI ETEROGENEITA\n",
    "\n",
    "\n",
    "\n",
    "            #SUM OF FINAL HP PERCENTAGE OF EACH PLAYER\n",
    "            p1_hp_final ={}\n",
    "            p2_hp_final ={}\n",
    "            for t in timeline:\n",
    "                if t.get('p1_pokemon_state'):\n",
    "                    p1_hp_final[t['p1_pokemon_state']['name']]=t['p1_pokemon_state']['hp_pct']\n",
    "                if t.get('p2_pokemon_state'):\n",
    "                    p2_hp_final[t['p2_pokemon_state']['name']]=t['p2_pokemon_state']['hp_pct']\n",
    "            #print(p1_hp_final)\n",
    "            #numero di pockemon usati dal giocatore nei primi 30 turni\n",
    "            features['p1_n_pokemon_use'] =len(p1_hp_final.keys())\n",
    "            features['p2_n_pokemon_use'] =len(p2_hp_final.keys())\n",
    "            #differenza nello schieramento pockemon dopo 30 turni\n",
    "            features['diff_final_schieramento']=features['p1_n_pokemon_use']-features['p2_n_pokemon_use']\n",
    "            nr_pokemon_sconfitti_p1 = np.sum([1 for e in list(p1_hp_final.values()) if e==0])\n",
    "            nr_pokemon_sconfitti_p2 = np.sum([1 for e in list(p2_hp_final.values()) if e==0])\n",
    "            features['nr_pokemon_sconfitti_p1'] = nr_pokemon_sconfitti_p1\n",
    "            features['nr_pokemon_sconfitti_p2'] = nr_pokemon_sconfitti_p2\n",
    "            #features['nr_pokemon_sconfitti_diff'] = nr_pokemon_sconfitti_p1-nr_pokemon_sconfitti_p2\n",
    "            #DOVREBBERO ESSERE BOMBA VITA DELLE DUE SQUADRE DOPO I 30 TURNI\n",
    "            features['p1_pct_final_hp'] =np.sum(list(p1_hp_final.values()))+(6-len(p1_hp_final.keys()))\n",
    "            features['p2_pct_final_hp'] =np.sum(list(p2_hp_final.values()))+(6-len(p1_hp_final.keys()))\n",
    "            #SAREBBE CLAMOROSO NORMALIZZARLA ANCHE IN BASE ALLA DIFFERENZA DI VITA ASSOLUTA DEI POCKEMON LEADER DEI 2 PLAYER\n",
    "            features['diff_final_hp']=features['p1_pct_final_hp']-features['p2_pct_final_hp'] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #vedo anche come la salute media evolve nel tempo\n",
    "            phases = 3 #early, mid, late game\n",
    "            nr_turns = 30 #numero turni\n",
    "            slice_idx = nr_turns // phases #slice index must be integer\n",
    "            #print(\"slice_idx: \",slice_idx, \"len p1_hp: \",len(p1_hp))\n",
    "            features['early_hp_mean_diff'] = np.mean(np.array(p1_hp[:slice_idx]) - np.array(p2_hp[:slice_idx]))\n",
    "            features['late_hp_mean_diff'] = np.mean(np.array(p1_hp[-slice_idx:]) - np.array(p2_hp[-slice_idx:]))\n",
    "            #features['phases_hp_mean_diff'] = features['late_hp_mean_diff'] - features['early_hp_mean_diff']\n",
    "            #77.94% (+/- 0.35%) => 77.94% (+/- 0.41%)\n",
    "            hp_delta = np.array(p1_hp) - np.array(p2_hp)\n",
    "            features['hp_delta_trend'] = np.polyfit(range(len(hp_delta)), hp_delta, 1)[0]\n",
    "            \n",
    "            #fluttuazioni negli hp (andamento della partita: stabile o molto caotica)\n",
    "            #77.94% (+/- 0.41%) => 79.09% (+/- 1.02%)\n",
    "            features['p1_hp_std'] = np.std(p1_hp)\n",
    "            features['p2_hp_std'] = np.std(p2_hp)\n",
    "            features['hp_delta_std'] = np.std(hp_delta)\n",
    "\n",
    "            \n",
    "            ##STATUS (default nostatus, gli altri sono considerati negativi - i boost sono positivi)\n",
    "            p1_status = [t['p1_pokemon_state'].get('status', 'nostatus') for t in timeline if t.get('p1_pokemon_state')]\n",
    "            p2_status = [t['p2_pokemon_state'].get('status', 'nostatus') for t in timeline if t.get('p2_pokemon_state')]\n",
    "            total_status = set(p1_status + p2_status)\n",
    "            no_effect_status = {'nostatus', 'noeffect'}\n",
    "            negative_status = {s for s in total_status if s not in no_effect_status}\n",
    "            #mean of negative status\n",
    "            p1_negative_status_mean = np.mean([s in negative_status for s in p1_status])\n",
    "            p2_negative_status_mean = np.mean([s in negative_status for s in p2_status])\n",
    "            #status advantage if p1 applied more status to p2 (differenza delle medie dei negativi)\n",
    "            features['p1_bad_status_advantage'] = p2_negative_status_mean-p1_negative_status_mean\n",
    "            #p1_bad_status_advantage.append(features['p1_bad_status_advantage'])\n",
    "            #how many times status changed? \n",
    "            # we have to check that first array shifted by 1 is \n",
    "            # different from the same array excluding the last element \n",
    "            # (so basically checking if status change in time)\n",
    "            #somma il nr di volte in cui lo stato cambia, vedi se collineare\n",
    "            p1_status_change = np.sum(np.array(p1_status[1:]) != np.array(p1_status[:-1]))\n",
    "            p2_status_change = np.sum(np.array(p2_status[1:]) != np.array(p2_status[:-1]))\n",
    "            #features['p1_status_change'] = p1_status_change\n",
    "            #features['p2_status_change'] = p2_status_change\n",
    "            features['status_change_diff'] = p1_status_change - p2_status_change\n",
    "            status_change_diff.append(features['status_change_diff'])\n",
    "            \n",
    "            #QUANTO IL TEAM è BILANCIATO (TIPI E VELOCITA)\n",
    "            #79.09% (+/- 1.02%) => 79.29% (+/- 0.92%)\n",
    "            p1_types = [t for p in p1_team for t in p.get('types', []) if t != 'notype']\n",
    "            features['p1_type_diversity'] = len(set(p1_types))\n",
    "\n",
    "            MEDIUM_SPEED_THRESHOLD = 90 #medium-speed pokemon\n",
    "            HIGH_SPEED_THRESHOLD = 100 #fast pokemon\n",
    "            speeds = np.array([p.get('base_spe', 0) for p in p1_team])\n",
    "            features['p1_avg_speed_stat_battaglia'] = np.mean(np.array(speeds) > MEDIUM_SPEED_THRESHOLD)\n",
    "            features['p1_avg_high_speed_stat_battaglia'] = np.mean(np.array(speeds) > HIGH_SPEED_THRESHOLD)\n",
    "\n",
    "\n",
    "            #COMBINAZIONI DI FEATURE\n",
    "            #combino vantaggio negli hp con l'avere pochi status negativi\n",
    "            #79.09% (+/- 1.02%) => 79.13% (+/- 1.06%)\n",
    "            #features['hp_advantage_no_negative_status'] = features['hp_delta_trend'] * (1 - p1_negative_status_mean)\n",
    "            #LA FEATURE è BELLA MA SUPER CORRELATA CON hp_delta_trend 95%\n",
    "            #per il momento semplifico cosi capiamo poi è facile aggiungere\n",
    "\n",
    "        # We also need the ID and the target variable (if it exists)\n",
    "        features['battle_id'] = battle.get('battle_id')\n",
    "        if 'player_won' in battle:\n",
    "            features['player_won'] = int(battle['player_won'])\n",
    "            \n",
    "        feature_list.append(features)\n",
    "\n",
    "    return pd.DataFrame(feature_list).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create feature DataFrames for both training and test sets\n",
    "print(\"Processing training data...\")\n",
    "train_df = create_simple_features(train_data)\n",
    "\n",
    "print(\"\\nProcessing test data...\")\n",
    "test_data = []\n",
    "with open(test_file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        test_data.append(json.loads(line))\n",
    "test_df = create_simple_features(test_data)\n",
    "\n",
    "print(\"\\nTraining features preview:\")\n",
    "display(train_df.head())\n",
    "print(\"\\nForma del dataset\",train_df.shape)\n",
    "\n",
    "#phases_hp\n",
    "#hp_delta_trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d8081e",
   "metadata": {},
   "source": [
    "SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd7ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Select numerical feature columns (exclude 'player_won')\n",
    "feature_columns = [col for col in train_df.columns if col not in ['battle_id', 'player_won']]\n",
    "X = train_df[feature_columns]\n",
    "X_train = scaler.fit_transform(X)\n",
    "\n",
    "train_df_scaled = pd.DataFrame(X_train, columns=feature_columns)\n",
    "train_df_scaled['battle_id'] = train_df['battle_id']\n",
    "train_df_scaled['player_won'] = train_df['player_won']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e6e60a",
   "metadata": {},
   "source": [
    "RISTRUTTURAZIONE E VISONE DEL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5aa407",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_scaled.shape#shape mean that data is like matrix\n",
    "train_df_scaled.info()#description of variable\n",
    "\n",
    "print(train_df_scaled['diff_final_hp'].describe(include='all'))\n",
    "print(train_df_scaled['p1_pct_final_hp'].describe(include='all'))\n",
    "print(train_df_scaled['p2_pct_final_hp'].describe(include='all'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c8f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATTENZIONE LANCIA SOLO 1 VOLTA ALTRIMENTI CONTINUA A TOGLIERE COLONNE DAL DATASET !!!! PERICOLOSO\n",
    "#MA NON SO COME FARE\n",
    "print(train_df_scaled.iloc[:,0:5].head())\n",
    "pca_p1, pca_model_p1=run_pca(train_df_scaled.iloc[:,0:5])\n",
    "print(pca_model_p1.explained_variance_ratio_)#show the behavior of variance absorbation\n",
    "print(pca_model_p1.components_)#rinomino variabile come, competitivita, vita vs chi attacca prima, speed,attack vs defence\n",
    "pca_p1.columns = ['p1_mean_competivness', 'p1_mean_hp_vs_start','p1_mean_start_vs_speed','p1_mean_atk_vs_def']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d882189",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df_scaled.iloc[:,5:10].head())\n",
    "pca_diff, pca_model_diff=run_pca(train_df_scaled.iloc[:,5:10])\n",
    "print(pca_model_diff.explained_variance_ratio_)#show the behavior of variance absorbation\n",
    "print(pca_model_diff.components_)#rinomino variabile come, competitivita, vita vs chi attacca prima, speed,attack vs defence\n",
    "pca_diff.columns = ['diff_mean_competivness', 'diff_mean_hp_vs_start','diff_mean_start_vs_speed','diff_mean_atk_vs_def']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f63621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RICOMPONI IL DATASET INCORRELATO\n",
    "support=train_df_scaled.iloc[:,10:]\n",
    "train_df_scaled=pd.concat([pca_p1,pca_diff, support], axis=1)\n",
    "print(train_df_scaled.shape)#corretta ricostruzione del dataset verificata\n",
    "print(train_df_scaled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9361f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_scaled.describe()\n",
    "corr_matrix = train_df_scaled.corr(numeric_only=True).round(1)\n",
    "print(corr_matrix.shape)\n",
    "pd.set_option('display.max_columns', None)   # mostra tutte le colonne\n",
    "pd.set_option('display.max_rows', None)      # mostra tutte le righe\n",
    "pd.set_option('display.width', 0)            # evita line wrapping\n",
    "pd.set_option('display.max_colwidth', None)  # mostra nomi completi delle colonne\n",
    "\n",
    "\n",
    "#attenzione mostra solo colonne tanto correlate nel dataset\n",
    "# 1️⃣ Compute correlation matrix and filter strong correlations\n",
    "mask_strong = (corr_matrix.abs() > 0.5) & (corr_matrix.abs() < 1.0)\n",
    "strong_features = corr_matrix.columns[mask_strong.any()].tolist()\n",
    "subset_corr = corr_matrix.loc[strong_features, strong_features]\n",
    "\n",
    "# 2️⃣ Dynamically adjust figure size based on number of features\n",
    "n = len(subset_corr.columns)\n",
    "fig_width = max(12, n * 0.6)\n",
    "fig_height = max(10, n * 0.6)\n",
    "\n",
    "# 3️⃣ Plot with larger figure, higher DPI, and better layout\n",
    "plt.figure(figsize=(fig_width, fig_height), dpi=150)\n",
    "sns.heatmap(\n",
    "    subset_corr,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"coolwarm\",\n",
    "    square=True,\n",
    "    linewidths=0.5,        # small grid lines for separation\n",
    "    cbar_kws={'shrink': 0.8}\n",
    ")\n",
    "\n",
    "plt.title(\"Strong Feature Correlations (|r| > 0.5)\", fontsize=18, pad=20)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.yticks(rotation=0, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc308a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working with standardize we give more weight to variable that have absolute value in start smaller than other, example diff variable\n",
    "# Define features and target\n",
    "features = [col for col in train_df_scaled.columns if col not in ['battle_id', 'player_won']]\n",
    "X = train_df_scaled[features]\n",
    "print(X.shape)\n",
    "y = train_df_scaled['player_won']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8834295d",
   "metadata": {},
   "source": [
    "### STUDIAMO GRAFICAMENTE FEATURES E OUTPUT E TRA FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bb5a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print(train_df['player_won'].value_counts())#victory classes ar perfectly balance\n",
    "#best case for accuracy calcolation \n",
    "#show_graph(train_df_scaled[['p1_mean_competivness','battle_id']],train_df_scaled[['player_won']])\n",
    "show_graph(train_df_scaled[['diff_final_hp','diff_mean_competivness']],train_df_scaled[['player_won']])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dbfd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print(train_df_scaled.columns)\n",
    "#si cominciano ad intravedere effettive distribuzioni bivariate con eterogeneita tra gruppi di vincita e perdita\n",
    "show_graph(train_df_scaled[['diff_final_schieramento','diff_final_hp']],train_df_scaled[['player_won']])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997c9542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "552bd74b",
   "metadata": {},
   "source": [
    "### PolynomialFeatures \n",
    "crea nuove feature come potenze e relazioni tra le feature numeriche originali, per vedere relazioni non lineari; il modello cattura curvature e relazioni mantenendo la linearità nei parametri => purtroppo aggiunge $\\binom{n+d}{n}$ feature (n=numero feature originali e d=degree=2 o altro intero) e aumenta il tempo di addestramento => valuta se usare una PCA per gestire l'esplosione dimensionale.\n",
    "\n",
    "Usalo solo se le feature originali sono informative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf7162c",
   "metadata": {},
   "source": [
    "### TRAIN AND SUBMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb0ec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Initialize and train the model\n",
    "print(\"Training a simple Logistic Regression model...\")\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_predictions = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "\"\"\"\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# PCA?\n",
    "USE_PCA = False\n",
    "POLY_ENABLED = False# se enabled 77.64% (+/- 0.69%) altrimenti 77.94% (+/- 0.35%)\n",
    "\n",
    "steps = []\n",
    "if POLY_ENABLED:\n",
    "    steps.append((\"poly\", PolynomialFeatures(degree=2, include_bias=False)))\n",
    "#standardizza\n",
    "steps.append((\"scaler\", StandardScaler()))\n",
    "if USE_PCA:\n",
    "    steps.append((\"pca\", PCA(n_components=0.95, svd_solver=\"full\")))  # ~95% varianza\n",
    "\n",
    "steps.append((\"logreg\", LogisticRegression(max_iter=2000, random_state=42)))\n",
    "\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "#kfold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold CV\n",
    "print(\"Training Logistic Regression con 5-Fold Cross-Validation...\\n\")\n",
    "scores = cross_val_score(pipe, X, y, cv=kfold, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"Cross-validation accuracies: {np.round(scores, 4)}\")\n",
    "print(f\"Mean CV accuracy: {np.mean(scores)*100:.2f}% (+/- {np.std(scores)*100:.2f}%)\")\n",
    "\n",
    "#Training finale\n",
    "pipe.fit(X, y)\n",
    "print(\"\\nFinal model trained on all training data.\")\n",
    "#sm.logisticModel(tran_df[feate1,feature2,feature2**2,fature1*feature2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ee50e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75917fd3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbc77ac9",
   "metadata": {},
   "source": [
    "### SUBMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edf9fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the real test data\n",
    "X_test = test_df[features]\n",
    "print(\"Generating predictions on the test set...\")\n",
    "test_predictions = pipe.predict(X_test)\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'battle_id': test_df['battle_id'],\n",
    "    'player_won': test_predictions\n",
    "})\n",
    "\n",
    "# Save submission CSV\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"\\n'submission.csv' file created successfully!\")\n",
    "display(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcf4b769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from '../input/fds-pokemon-battles-prediction-2025/train.jsonl'...\n",
      "Successfully loaded 10000 battles.\n",
      "\n",
      "--- Structure of the first train battle: ---\n",
      "{\n",
      "    \"player_won\": true,\n",
      "    \"p1_team_details\": [\n",
      "        {\n",
      "            \"name\": \"starmie\",\n",
      "            \"level\": 100,\n",
      "            \"types\": [\n",
      "                \"psychic\",\n",
      "                \"water\"\n",
      "            ],\n",
      "            \"base_hp\": 60,\n",
      "            \"base_atk\": 75,\n",
      "            \"base_def\": 85,\n",
      "            \"base_spa\": 100,\n",
      "            \"base_spd\": 100,\n",
      "            \"base_spe\": 115\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"exeggutor\",\n",
      "            \"level\": 100,\n",
      "            \"types\": [\n",
      "                \"grass\",\n",
      "                \"psychic\"\n",
      "            ],\n",
      "            \"base_hp\": 95,\n",
      "            \"base_atk\": 95,\n",
      "            \"base_def\": 85,\n",
      "            \"base_spa\": 125,\n",
      "            \"base_spd\": 125,\n",
      "            \"base_spe\": 55\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"chansey\",\n",
      "            \"level\": 100,\n",
      "            \"types\": [\n",
      "                \"normal\",\n",
      "                \"notype\"\n",
      "            ],\n",
      "            \"base_hp\": 250,\n",
      "            \"base_atk\": 5,\n",
      "            \"base_def\": 5,\n",
      "            \"base_spa\": 105,\n",
      "            \"base_spd\": 105,\n",
      "            \"base_spe\": 50\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"snorlax\",\n",
      "            \"level\": 100,\n",
      "            \"types\": [\n",
      "                \"normal\",\n",
      "                \"notype\"\n",
      "            ],\n",
      "            \"base_hp\": 160,\n",
      "            \"base_atk\": 110,\n",
      "            \"base_def\": 65,\n",
      "            \"base_spa\": 65,\n",
      "            \"base_spd\": 65,\n",
      "            \"base_spe\": 30\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"tauros\",\n",
      "            \"level\": 100,\n",
      "            \"types\": [\n",
      "                \"normal\",\n",
      "                \"notype\"\n",
      "            ],\n",
      "            \"base_hp\": 75,\n",
      "            \"base_atk\": 100,\n",
      "            \"base_def\": 95,\n",
      "            \"base_spa\": 70,\n",
      "            \"base_spd\": 70,\n",
      "            \"base_spe\": 110\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"alakazam\",\n",
      "            \"level\": 100,\n",
      "            \"types\": [\n",
      "                \"notype\",\n",
      "                \"psychic\"\n",
      "            ],\n",
      "            \"base_hp\": 55,\n",
      "            \"base_atk\": 50,\n",
      "            \"base_def\": 45,\n",
      "            \"base_spa\": 135,\n",
      "            \"base_spd\": 135,\n",
      "            \"base_spe\": 120\n",
      "        }\n",
      "    ],\n",
      "    \"p2_lead_details\": {\n",
      "        \"name\": \"starmie\",\n",
      "        \"level\": 100,\n",
      "        \"types\": [\n",
      "            \"psychic\",\n",
      "            \"water\"\n",
      "        ],\n",
      "        \"base_hp\": 60,\n",
      "        \"base_atk\": 75,\n",
      "        \"base_def\": 85,\n",
      "        \"base_spa\": 100,\n",
      "        \"base_spd\": 100,\n",
      "        \"base_spe\": 115\n",
      "    },\n",
      "    \"battle_timeline\": [\n",
      "        {\n",
      "            \"turn\": 1,\n",
      "            \"p1_pokemon_state\": {\n",
      "                \"name\": \"starmie\",\n",
      "                \"hp_pct\": 1.0,\n",
      "                \"status\": \"nostatus\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p1_move_details\": {\n",
      "                \"name\": \"icebeam\",\n",
      "                \"type\": \"ICE\",\n",
      "                \"category\": \"SPECIAL\",\n",
      "                \"base_power\": 95,\n",
      "                \"accuracy\": 1.0,\n",
      "                \"priority\": 0\n",
      "            },\n",
      "            \"p2_pokemon_state\": {\n",
      "                \"name\": \"exeggutor\",\n",
      "                \"hp_pct\": 0.6895674300254453,\n",
      "                \"status\": \"frz\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p2_move_details\": null\n",
      "        },\n",
      "        {\n",
      "            \"turn\": 2,\n",
      "            \"p1_pokemon_state\": {\n",
      "                \"name\": \"exeggutor\",\n",
      "                \"hp_pct\": 1.0,\n",
      "                \"status\": \"nostatus\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p1_move_details\": null,\n",
      "            \"p2_pokemon_state\": {\n",
      "                \"name\": \"starmie\",\n",
      "                \"hp_pct\": 1.0,\n",
      "                \"status\": \"nostatus\",\n",
      "                \"effects\": [\n",
      "                    \"noeffect\"\n",
      "                ],\n",
      "                \"boosts\": {\n",
      "                    \"atk\": 0,\n",
      "                    \"def\": 0,\n",
      "                    \"spa\": 0,\n",
      "                    \"spd\": 0,\n",
      "                    \"spe\": 0\n",
      "                }\n",
      "            },\n",
      "            \"p2_move_details\": null\n",
      "        }\n",
      "    ],\n",
      "    \"battle_id\": 0\n",
      "}\n",
      "    ...\n",
      "    (battle_timeline has been truncated for display)\n",
      "Processing training data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9069c07d1454586baaba4ca03d7f93a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing test data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4809da2c8b90412ba8ad52e5891f8739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training features preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_mean_hp</th>\n",
       "      <th>p1_mean_spe</th>\n",
       "      <th>p1_mean_atk</th>\n",
       "      <th>p1_mean_def</th>\n",
       "      <th>p1_mean_sp</th>\n",
       "      <th>diff_hp</th>\n",
       "      <th>diff_spe</th>\n",
       "      <th>diff_atk</th>\n",
       "      <th>diff_def</th>\n",
       "      <th>diff_sp</th>\n",
       "      <th>...</th>\n",
       "      <th>p2_hp_std</th>\n",
       "      <th>hp_delta_std</th>\n",
       "      <th>damage_per_turn</th>\n",
       "      <th>p1_bad_status_advantage</th>\n",
       "      <th>status_change_diff</th>\n",
       "      <th>p1_type_diversity</th>\n",
       "      <th>p1_avg_speed_stat_battaglia</th>\n",
       "      <th>p1_avg_high_speed_stat_battaglia</th>\n",
       "      <th>battle_id</th>\n",
       "      <th>player_won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115.833333</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>63.333333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280925</td>\n",
       "      <td>0.368726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123.333333</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>65.833333</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>-25</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "      <td>-40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241442</td>\n",
       "      <td>0.378163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124.166667</td>\n",
       "      <td>65.833333</td>\n",
       "      <td>84.166667</td>\n",
       "      <td>71.666667</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>-155</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212332</td>\n",
       "      <td>0.334522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121.666667</td>\n",
       "      <td>75.833333</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>65.833333</td>\n",
       "      <td>103.333333</td>\n",
       "      <td>-15</td>\n",
       "      <td>0</td>\n",
       "      <td>-35</td>\n",
       "      <td>-35</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369359</td>\n",
       "      <td>0.421204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114.166667</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>75.833333</td>\n",
       "      <td>79.166667</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>-5</td>\n",
       "      <td>5</td>\n",
       "      <td>-25</td>\n",
       "      <td>-40</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281241</td>\n",
       "      <td>0.348348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>-5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   p1_mean_hp  p1_mean_spe  p1_mean_atk  p1_mean_def  p1_mean_sp  diff_hp  \\\n",
       "0  115.833333    80.000000    72.500000    63.333333  100.000000        0   \n",
       "1  123.333333    61.666667    72.500000    65.833333   90.000000       10   \n",
       "2  124.166667    65.833333    84.166667    71.666667   90.000000     -155   \n",
       "3  121.666667    75.833333    77.500000    65.833333  103.333333      -15   \n",
       "4  114.166667    72.500000    75.833333    79.166667   97.500000       -5   \n",
       "\n",
       "   diff_spe  diff_atk  diff_def  diff_sp  ...  p2_hp_std  hp_delta_std  \\\n",
       "0         0         0         0        0  ...   0.280925      0.368726   \n",
       "1       -25         0       -10      -40  ...   0.241442      0.378163   \n",
       "2         5        90        80       20  ...   0.212332      0.334522   \n",
       "3         0       -35       -35       60  ...   0.369359      0.421204   \n",
       "4         5       -25       -40       35  ...   0.281241      0.348348   \n",
       "\n",
       "   damage_per_turn  p1_bad_status_advantage  status_change_diff  \\\n",
       "0              0.0                 0.333333                  -1   \n",
       "1              0.0                -0.200000                   5   \n",
       "2              0.0                -0.033333                   6   \n",
       "3              0.0                -0.500000                   4   \n",
       "4              0.0                 0.433333                  -5   \n",
       "\n",
       "   p1_type_diversity  p1_avg_speed_stat_battaglia  \\\n",
       "0                  4                     0.500000   \n",
       "1                  5                     0.333333   \n",
       "2                  7                     0.333333   \n",
       "3                  7                     0.500000   \n",
       "4                  5                     0.333333   \n",
       "\n",
       "   p1_avg_high_speed_stat_battaglia  battle_id  player_won  \n",
       "0                          0.500000          0           1  \n",
       "1                          0.166667          1           1  \n",
       "2                          0.333333          2           1  \n",
       "3                          0.333333          3           1  \n",
       "4                          0.333333          4           1  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forma del dataset (10000, 40)\n",
      "(10000, 38)\n",
      "Training Logistic Regression con 5-Fold Cross-Validation...\n",
      "\n",
      "(10000, 38)\n",
      "['p1_mean_hp', 'p1_mean_spe', 'p1_mean_atk', 'p1_mean_def', 'p1_mean_sp', 'diff_hp', 'diff_spe', 'diff_atk', 'diff_def', 'diff_sp', 'hp_diff_mean', 'p1_move_damage_mean', 'p2_move_damage_mean', 'diff_move_damage_mean', 'p1_hp_advantage_mean', 'p1_n_pokemon_use', 'p2_n_pokemon_use', 'diff_final_schieramento', 'nr_pokemon_sconfitti_p1', 'nr_pokemon_sconfitti_p2', 'p1_pct_final_hp', 'p2_pct_final_hp', 'diff_final_hp', 'battle_duration', 'hp_loss_rate', 'early_hp_mean_diff', 'late_hp_mean_diff', 'hp_delta_trend', 'hp_advantage_trend', 'p1_hp_std', 'p2_hp_std', 'hp_delta_std', 'damage_per_turn', 'p1_bad_status_advantage', 'status_change_diff', 'p1_type_diversity', 'p1_avg_speed_stat_battaglia', 'p1_avg_high_speed_stat_battaglia']\n",
      "Cross-validation accuracies: [0.845  0.828  0.8375 0.841  0.8365]\n",
      "Mean CV accuracy: 83.76% (+/- 0.57%)\n",
      "candidate len: 38\n",
      "Training finale\n",
      "⏱️ Elapsed time: 19.97 seconds (0.33 minutes)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import linregress\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import importlib\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#reload del modulo caricato la prima volta, per prendere la versione aggiornata\n",
    "import utils.type_effects as type_effects\n",
    "importlib.reload(type_effects)\n",
    "#from utils.type_effects import TYPE_EFFECTIVENESS, type_advantage\n",
    "import utils.model as model\n",
    "importlib.reload(model)\n",
    "from utils.model import run_pca, show_graph\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# --- Define the path to our data ---\n",
    "COMPETITION_NAME = 'fds-pokemon-battles-prediction-2025'\n",
    "DATA_PATH = os.path.join('../input', COMPETITION_NAME)\n",
    "\n",
    "train_file_path = os.path.join(DATA_PATH, 'train.jsonl')\n",
    "test_file_path = os.path.join(DATA_PATH, 'test.jsonl')\n",
    "train_data = []\n",
    "\n",
    "# Read the file line by line\n",
    "print(f\"Loading data from '{train_file_path}'...\")\n",
    "try:\n",
    "    with open(train_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            # json.loads() parses one line (one JSON object) into a Python dictionary\n",
    "            train_data.append(json.loads(line))\n",
    "\n",
    "    print(f\"Successfully loaded {len(train_data)} battles.\")\n",
    "\n",
    "    # Let's inspect the first battle to see its structure\n",
    "    print(\"\\n--- Structure of the first train battle: ---\")\n",
    "    if train_data:\n",
    "        first_battle = train_data[0]\n",
    "        \n",
    "        # To keep the output clean, we can create a copy and truncate the timeline\n",
    "        battle_for_display = first_battle.copy()\n",
    "        battle_for_display['battle_timeline'] = battle_for_display.get('battle_timeline', [])[:2] # Show first 2 turns\n",
    "        \n",
    "        # Use json.dumps for pretty-printing the dictionary\n",
    "        print(json.dumps(battle_for_display, indent=4))\n",
    "        if len(first_battle.get('battle_timeline', [])) > 3:\n",
    "            print(\"    ...\")\n",
    "            print(\"    (battle_timeline has been truncated for display)\")\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find the training file at '{train_file_path}'.\")\n",
    "    print(\"Please make sure you have added the competition data to this notebook.\")\n",
    "# Simplified Pokémon type effectiveness chart\n",
    "# Values: 2.0 = super effective, 0.5 = not very effective, 0.0 = no effect\n",
    "type_chart = {\n",
    "    \"Normal\":     {\"Rock\":0.5, \"Ghost\":0.0, \"Steel\":0.5},\n",
    "    \"Fire\":       {\"Fire\":0.5, \"Water\":0.5, \"Grass\":2.0, \"Ice\":2.0, \"Bug\":2.0, \"Rock\":0.5, \"Dragon\":0.5, \"Steel\":2.0},\n",
    "    \"Water\":      {\"Fire\":2.0, \"Water\":0.5, \"Grass\":0.5, \"Ground\":2.0, \"Rock\":2.0, \"Dragon\":0.5},\n",
    "    \"Electric\":   {\"Water\":2.0, \"Electric\":0.5, \"Grass\":0.5, \"Ground\":0.0, \"Flying\":2.0, \"Dragon\":0.5},\n",
    "    \"Grass\":      {\"Fire\":0.5, \"Water\":2.0, \"Grass\":0.5, \"Poison\":0.5, \"Ground\":2.0, \"Flying\":0.5, \"Bug\":0.5, \"Rock\":2.0, \"Dragon\":0.5, \"Steel\":0.5},\n",
    "    \"Ice\":        {\"Fire\":0.5, \"Water\":0.5, \"Grass\":2.0, \"Ground\":2.0, \"Flying\":2.0, \"Dragon\":2.0, \"Steel\":0.5},\n",
    "    \"Fighting\":   {\"Normal\":2.0, \"Ice\":2.0, \"Rock\":2.0, \"Dark\":2.0, \"Steel\":2.0, \"Poison\":0.5, \"Flying\":0.5, \"Psychic\":0.5, \"Bug\":0.5, \"Ghost\":0.0, \"Fairy\":0.5},\n",
    "    \"Poison\":     {\"Grass\":2.0, \"Poison\":0.5, \"Ground\":0.5, \"Rock\":0.5, \"Ghost\":0.5, \"Steel\":0.0, \"Fairy\":2.0},\n",
    "    \"Ground\":     {\"Fire\":2.0, \"Electric\":2.0, \"Grass\":0.5, \"Poison\":2.0, \"Flying\":0.0, \"Bug\":0.5, \"Rock\":2.0, \"Steel\":2.0},\n",
    "    \"Flying\":     {\"Electric\":0.5, \"Grass\":2.0, \"Fighting\":2.0, \"Bug\":2.0, \"Rock\":0.5, \"Steel\":0.5},\n",
    "    \"Psychic\":    {\"Fighting\":2.0, \"Poison\":2.0, \"Psychic\":0.5, \"Dark\":0.0, \"Steel\":0.5},\n",
    "    \"Bug\":        {\"Fire\":0.5, \"Grass\":2.0, \"Fighting\":0.5, \"Poison\":0.5, \"Flying\":0.5, \"Psychic\":2.0, \"Ghost\":0.5, \"Dark\":2.0, \"Steel\":0.5, \"Fairy\":0.5},\n",
    "    \"Rock\":       {\"Fire\":2.0, \"Ice\":2.0, \"Fighting\":0.5, \"Ground\":0.5, \"Flying\":2.0, \"Bug\":2.0, \"Steel\":0.5},\n",
    "    \"Ghost\":      {\"Normal\":0.0, \"Psychic\":2.0, \"Ghost\":2.0, \"Dark\":0.5},\n",
    "    \"Dragon\":     {\"Dragon\":2.0, \"Steel\":0.5, \"Fairy\":0.0},\n",
    "    \"Dark\":       {\"Fighting\":0.5, \"Psychic\":2.0, \"Ghost\":2.0, \"Fairy\":0.5},\n",
    "    \"Steel\":      {\"Fire\":0.5, \"Water\":0.5, \"Electric\":0.5, \"Ice\":2.0, \"Rock\":2.0, \"Fairy\":2.0, \"Steel\":0.5},\n",
    "    \"Fairy\":      {\"Fire\":0.5, \"Fighting\":2.0, \"Poison\":0.5, \"Dragon\":2.0, \"Dark\":2.0, \"Steel\":0.5}\n",
    "}\n",
    "\n",
    "#0 Mean CV accuracy: 83.59% (+/- 0.64%)\n",
    "#1 Mean CV accuracy: 83.62% (+/- 0.67%)\n",
    "def hp_advantage_trend(battle):\n",
    "    \"\"\"Compute the linear slope of Player 1's HP advantage over 30 turns.\"\"\"\n",
    "    hp_adv = []\n",
    "    for turn in battle['battle_timeline']:\n",
    "        p1_hp = turn['p1_pokemon_state']['hp_pct']\n",
    "        p2_hp = turn['p2_pokemon_state']['hp_pct']\n",
    "        hp_adv.append(p1_hp - p2_hp)\n",
    "    x = np.arange(len(hp_adv))\n",
    "    slope, _, _, _, _ = linregress(x, hp_adv)\n",
    "    return slope\n",
    "\n",
    "#2 Mean CV accuracy: 83.55% (+/- 0.63%)\n",
    "\"\"\"\n",
    "A small decrease (≈ 0.05 %) means:\n",
    "The new status_duration_ratio feature adds noise but not independent signal.\n",
    "The effect of bad statuses is already encoded in your existing features — especially p1_bad_status_advantage and status_change_diff, both of which have strong correlations (±0.5 – 0.6) with the target.\n",
    "Logistic Regression, being linear, can’t easily “disentangle” two highly collinear features, so adding another version of the same concept just shifts weights slightly.\n",
    "\"\"\"\n",
    "def status_duration_ratio(battle):\n",
    "    p1_turns_bad = sum(turn['p1_pokemon_state']['status'] != 'nostatus' for turn in battle['battle_timeline'])\n",
    "    p2_turns_bad = sum(turn['p2_pokemon_state']['status'] != 'nostatus' for turn in battle['battle_timeline'])\n",
    "    return (p2_turns_bad + 1) / (p1_turns_bad + 1)\n",
    "#3 Pre-battle info\n",
    "#Mean CV accuracy: 83.59% (+/- 0.64%)\n",
    "\"\"\"\n",
    "Your feature space is already highly saturated with the key linear signals — the Logistic Regression can’t extract more because:\n",
    "Many of your engineered variables (HP diffs, status advantages, competitiveness metrics) are strongly correlated with one another.\n",
    "Logistic Regression can only assign one weight per direction of correlation, so redundant inputs don’t add discriminative power.\n",
    "You’re probably sitting near the model’s linear ceiling for this dataset (~83–84%).\n",
    "This is good news — it means your data cleaning and baseline engineering are solid.\n",
    "Now, the final 2–3% (to reach 86%) likely requires non-linear relationships or interaction modeling.\n",
    "\"\"\"\n",
    "def team_stat_variance(team):\n",
    "    \"\"\"Average variance of base stats within Player 1's team.\"\"\"\n",
    "    stats = ['base_hp', 'base_atk', 'base_def', 'base_spa', 'base_spd', 'base_spe']\n",
    "    # Compute variance of each stat across the 6 Pokémon, then take the mean\n",
    "    return float(np.mean([np.var([p[s] for p in team]) for s in stats]))\n",
    "\n",
    "def team_type_diversity(team):\n",
    "    \"\"\"Proportion of distinct Pokémon types in the team.\"\"\"\n",
    "    all_types = [t for p in team for t in p['types'] if t != 'notype']\n",
    "    if not all_types:\n",
    "        return 0.0\n",
    "    return len(set(all_types)) / len(all_types)\n",
    "\n",
    "def lead_stat_diff(p1_team, p2_lead):\n",
    "    \"\"\"Average stat difference between Player 1's team mean and Player 2's lead Pokémon.\"\"\"\n",
    "    stats = ['base_hp', 'base_atk', 'base_def', 'base_spa', 'base_spd', 'base_spe']\n",
    "    p1_mean = np.mean([[p[s] for s in stats] for p in p1_team], axis=0)\n",
    "    p2_stats = np.array([p2_lead[s] for s in stats])\n",
    "    return float(np.mean(p1_mean - p2_stats))\n",
    "\n",
    "#5 p1_move_damage_mean, p2_move_damage_mean, diff_move_damage_mean\n",
    "def move_damage_efficiency(battle):\n",
    "    moves = [t.get('p1_move_details', {}) for t in battle['battle_timeline'] if t.get('p1_move_details')]\n",
    "    if not moves: return 0\n",
    "    total_damage = sum(m.get('damage', 0) for m in moves)\n",
    "    return total_damage / len(moves)  # avg damage per move\n",
    "#6 p1_first_strike_ratio, tempo_advantage = first_strike_ratio - 0.5\n",
    "\"\"\"\n",
    "Cross-validation accuracies: [0.844  0.827  0.831  0.8375 0.835 ]\n",
    "Mean CV accuracy: 83.49% (+/- 0.58%)\n",
    "\n",
    "1. Logistic regression doesn’t automatically benefit from new features\n",
    "Even though new features (like p1_move_damage_mean or tempo_advantage) sound informative,\n",
    "your model is a linear classifier with L1 penalty.\n",
    "If the new variables:\n",
    "are correlated with existing ones (hp_diff_mean, diff_final_hp, etc.),\n",
    "or noisy (e.g. move damage varying randomly per battle),\n",
    "then logistic regression’s L1 regularization will zero them out,\n",
    "or worse — slightly destabilize weights and hurt generalization by adding variance.\n",
    "That’s why performance went from 83.52 → 83.49% — statistically flat, but slightly worse.\n",
    "⚙️ 2. These specific features overlap conceptually with existing ones\n",
    "New Feature\tLikely Redundant With\tExplanation\n",
    "p1_move_damage_mean, diff_move_damage_mean\tdiff_final_hp, hp_diff_mean\tBoth describe how much damage one side deals over time.\n",
    "p1_first_strike_ratio, tempo_advantage\thp_delta_trend\tBoth encode “initiative”: who tends to lead or inflict earlier HP drops.\n",
    "So they add little new orthogonal signal — linear models can’t combine correlated predictors effectively.\n",
    "🧩 3. Why it doesn’t mean they’re useless\n",
    "These features might be valuable for:\n",
    "nonlinear models (Random Forest, Gradient Boosting, XGBoost)\n",
    "interaction terms (e.g. PolynomialFeatures, cross terms)\n",
    "or temporal clustering if used with per-turn modeling.\n",
    "But in your current setup (L1 LogisticRegressionCV), adding correlated variables = minor penalty.\n",
    "\"\"\"\n",
    "def first_strike_ratio(battle):\n",
    "    timeline = battle.get(\"battle_timeline\", [])\n",
    "    if len(timeline) < 2:\n",
    "        return 0.0\n",
    "\n",
    "    p1_hp = [t[\"p1_pokemon_state\"][\"hp_pct\"] for t in timeline if t.get(\"p1_pokemon_state\")]\n",
    "    p2_hp = [t[\"p2_pokemon_state\"][\"hp_pct\"] for t in timeline if t.get(\"p2_pokemon_state\")]\n",
    "\n",
    "    # approximate: if p2_hp decreases before p1_hp does, p1 attacked first\n",
    "    p1_first_hits = sum((p2_hp[i] - p2_hp[i+1]) > (p1_hp[i] - p1_hp[i+1]) for i in range(len(p1_hp)-1))\n",
    "    ratio = p1_first_hits / (len(p1_hp) - 1)\n",
    "    return ratio\n",
    "\n",
    "#7 hp_momentum_flips, hp_flip_rate = flips / len(timeline)\n",
    "\"\"\"perf drop\n",
    "Cross-validation accuracies: [0.841  0.8285 0.832  0.8385 0.8355]\n",
    "Mean CV accuracy: 83.51% (+/- 0.45%)\n",
    "hp_momentum_flips is a temporal volatility feature — it counts how many times the HP advantage flips between the two players.\n",
    "It measures “momentum chaos”: stable battles (few flips) vs. back-and-forth ones (many flips).\n",
    "\n",
    "Why performance drops when adding more features\n",
    "You’re already near the linear ceiling.\n",
    "Logistic regression is extracting essentially all the linear signal your data has — roughly 83.6 ± 0.6 % looks like your model’s upper bound.\n",
    "Additional features that are noisy or weakly correlated tend to only add variance, not information.\n",
    "New features like hp_momentum_flips and hp_flip_rate are non-linear effects.\n",
    "They’re based on the sequence dynamics of battles, which a linear model can’t capture well unless the relationship with player_won is monotonic.\n",
    "Logistic regression assumes a smooth, single-direction effect — but volatility in battles isn’t monotonic:\n",
    "Some flips = competitive battle (either could win)\n",
    "Too few flips = complete dominance (p1 wins or loses early)\n",
    "That kind of U-shape is invisible to linear models.\n",
    "L1 regularization doesn’t help if new variables are weakly correlated.\n",
    "Even though the L1 penalty tries to zero out irrelevant features, slight noise in the cross-validation folds can make the coefficients dance a bit → small accuracy drop.\n",
    "⚙️ What this means for you\n",
    "✅ Your base feature set is solid — most meaningful information is already encoded in HP, final differences, and status metrics.\n",
    "⚠️ New dynamic features (momentum, tempo, move damage) will help only if you switch to:\n",
    "tree-based models (RandomForest, XGBoost, LightGBM), or\n",
    "polynomial / interaction expansion of selected features.\n",
    "\"\"\"\n",
    "def hp_momentum_flips(battle):\n",
    "    timeline = battle.get(\"battle_timeline\", [])\n",
    "    if len(timeline) < 2:\n",
    "        return 0.0\n",
    "    hp_adv = np.array([\n",
    "        t.get(\"p1_pokemon_state\", {}).get(\"hp_pct\", 0) -\n",
    "        t.get(\"p2_pokemon_state\", {}).get(\"hp_pct\", 0)\n",
    "        for t in timeline\n",
    "    ])\n",
    "    # Count how many times the advantage sign changes\n",
    "    flips = np.sum(np.sign(hp_adv[1:]) != np.sign(hp_adv[:-1]))\n",
    "    return float(flips)\n",
    "\n",
    "#8 p1_lead_type_advantage, p2_lead_type_advantage, diff_type_advantage\n",
    "def type_effectiveness(attacker_types, defender_types):\n",
    "    \"\"\"Compute average type effectiveness multiplier between attacker and defender.\"\"\"\n",
    "    if not attacker_types or not defender_types:\n",
    "        return 1.0  # neutral if missing\n",
    "\n",
    "    values = []\n",
    "    for a in attacker_types:\n",
    "        if a not in type_chart:\n",
    "            continue\n",
    "        for d in defender_types:\n",
    "            values.append(type_chart[a].get(d, 1.0))  # default to neutral (1.0)\n",
    "    return np.mean(values) if values else 1.0\n",
    "\n",
    "#9 battle_duration, hp_loss_rate = diff_final_hp / battle_duration\n",
    "def battle_duration(battle):\n",
    "    return len([t for t in battle['battle_timeline'] if t['p1_pokemon_state']['hp_pct'] > 0 and\n",
    "                                                     t['p2_pokemon_state']['hp_pct'] > 0])\n",
    "#10 p1_team_imbalance, p2_team_imbalance, diff_team_imbalance\n",
    "\"\"\"\n",
    "Why battle_duration and hp_loss_rate helped\n",
    "These two features add time-normalized efficiency, which Logistic Regression can model linearly:\n",
    "Feature\tMeaning\tWhy it helps\n",
    "battle_duration\tHow long both sides were active\tDistinguishes between decisive vs drawn-out matches\n",
    "hp_loss_rate\tHP difference per turn\tCaptures speed of dominance — short + large HP gap = strong linear win signal\n",
    "They add orthogonal information to your HP and final-state metrics (diff_final_hp, hp_delta_trend), improving linear separability.\n",
    "\"\"\"\n",
    "def team_stat_imbalance(team):\n",
    "    totals = [p['base_hp']+p['base_atk']+p['base_def']+p['base_spa']+p['base_spd']+p['base_spe'] for p in team]\n",
    "    return np.std(totals) / np.mean(totals)\n",
    "\"\"\"\n",
    "attack_to_speed_ratio = diff_atk / (diff_spe + 1e-6)\n",
    "hp_control_ratio = hp_diff_mean / hp_delta_std\n",
    "status_pressure = status_change_diff / (hp_momentum_flips + 1)\n",
    "\"\"\"\n",
    "def create_simple_features(data: list[dict]) -> pd.DataFrame:\n",
    "    feature_list = []\n",
    "    #p1_bad_status_advantage = []\n",
    "    status_change_diff = []\n",
    "    for battle in tqdm(data, desc=\"Extracting features\"):\n",
    "\n",
    "        features = {}\n",
    "\n",
    "        # --- Player 1 Team Features ---\n",
    "        p1_mean_hp = p1_mean_spe = p1_mean_atk = p1_mean_def = p1_mean_sp = 0.0\n",
    "        p1_lead_hp = p1_lead_spe = p1_lead_atk = p1_lead_def = p1_lead_sp = 0.0\n",
    "\n",
    "        p1_team = battle.get('p1_team_details', [])\n",
    "        if p1_team:\n",
    "\n",
    "            p1_mean_hp = np.mean([p.get('base_hp', 0) for p in p1_team])\n",
    "            p1_mean_spe = np.mean([p.get('base_spe', 0) for p in p1_team])\n",
    "            p1_mean_atk = np.mean([p.get('base_atk', 0) for p in p1_team])\n",
    "            p1_mean_def = np.mean([p.get('base_def', 0) for p in p1_team])\n",
    "            p1_mean_sp = np.mean([p.get('base_spd', 0) for p in p1_team])\n",
    "\n",
    "            features['p1_mean_hp'] = p1_mean_hp\n",
    "            features['p1_mean_spe'] = p1_mean_spe\n",
    "            features['p1_mean_atk'] = p1_mean_atk\n",
    "            features['p1_mean_def'] = p1_mean_def\n",
    "            features['p1_mean_sp'] = p1_mean_sp\n",
    "\n",
    "            #PER UN CONFRONTO EQUO UTILIZZIAMO SOLO DATI DEL LEADER ANCHE NELLA SQUADRA 1 PER LE DIFFERENZE\n",
    "            p1_lead_hp =  p1_team[0].get('base_hp', 0)\n",
    "            p1_lead_spe = p1_team[0].get('base_spe', 0)\n",
    "            p1_lead_atk = p1_team[0].get('base_atk', 0)\n",
    "            p1_lead_def = p1_team[0].get('base_def', 0)\n",
    "            p1_lead_sp =  p1_team[0].get('base_spd', 0)\n",
    "\n",
    "\n",
    "\n",
    "        # --- Player 2 Lead Features ---\n",
    "        p2_hp = p2_spe = p2_atk = p2_def = p2_sp= 0.0\n",
    "        p2_lead = battle.get('p2_lead_details')\n",
    "        if p2_lead:\n",
    "            # Player 2's lead Pokémon's stats\n",
    "            p2_hp = p2_lead.get('base_hp', 0)\n",
    "            p2_spe = p2_lead.get('base_spe', 0)\n",
    "            p2_atk = p2_lead.get('base_atk', 0)\n",
    "            p2_def = p2_lead.get('base_def', 0)\n",
    "            p2_sp = p2_lead.get('base_spd', 0)\n",
    "\n",
    "\n",
    "\n",
    "        # I ADD THE DIFFS/DELTAS\n",
    "        features['diff_hp']  = p1_lead_hp  - p2_hp\n",
    "        features['diff_spe'] = p1_lead_spe - p2_spe\n",
    "        features['diff_atk'] = p1_lead_atk - p2_atk\n",
    "        features['diff_def'] = p1_lead_def - p2_def\n",
    "        features['diff_sp'] =  p1_lead_sp - p2_sp\n",
    "\n",
    "        #8 new\n",
    "        \"\"\"\n",
    "        # --- Type advantage (lead vs. lead) ---\n",
    "        p1_lead_types = [t for t in p1_team[0].get(\"types\", []) if t != \"notype\"] if p1_team else []\n",
    "        p2_lead_types = [t for t in p2_lead.get(\"types\", []) if t != \"notype\"] if p2_lead else []\n",
    "\n",
    "        features[\"p1_lead_type_advantage\"] = type_effectiveness(p1_lead_types, p2_lead_types)\n",
    "        features[\"p2_lead_type_advantage\"] = type_effectiveness(p2_lead_types, p1_lead_types)\n",
    "        features[\"diff_type_advantage\"] = (\n",
    "            features[\"p1_lead_type_advantage\"] - features[\"p2_lead_type_advantage\"]\n",
    "        )\n",
    "        \"\"\"\n",
    "        #new2\n",
    "        #features['status_duration_ratio'] = status_duration_ratio(battle)\n",
    "\n",
    "        #new3 - static feat\n",
    "        \"\"\"\n",
    "        features['p1_team_stat_variance'] = team_stat_variance(battle['p1_team_details'])\n",
    "        features['p1_type_diversity_ratio'] = team_type_diversity(battle['p1_team_details'])\n",
    "        features['lead_stat_diff'] = lead_stat_diff(battle['p1_team_details'], battle['p2_lead_details'])\n",
    "        \"\"\"\n",
    "        #DYNAMIC INFO\n",
    "        #Chi mantiene più HP medi e conduce più turni,  nella maggior parte dei casi vince anche se la battaglia non è ancora finita\n",
    "        timeline = battle.get('battle_timeline', [])\n",
    "        if timeline:\n",
    "            #SALUTE\n",
    "            p1_hp = [t['p1_pokemon_state']['hp_pct'] for t in timeline if t.get('p1_pokemon_state')]\n",
    "            p2_hp = [t['p2_pokemon_state']['hp_pct'] for t in timeline if t.get('p2_pokemon_state')]\n",
    "            #salute media dei pokemon del primo giocatore\n",
    "            #features['p1_mean_hp_pct'] = np.mean(p1_hp)\n",
    "            #salute media dei pokemon del secondo giocatore ATTENZIONE FEATURE BUONE CORRELATE CON hp_diff_mean 75%,VALUTAZIONE DELL'EEFFETTO SU BASE SINGOLA (CON HP DIFF)\n",
    "            #features['p2_mean_hp_pct'] = np.mean(p2_hp)\n",
    "            #vantaggio medio in salute (media della differenza tra la salute dei pokemon del primo giocatore e quella dei pokemon del secondo giocatore)\n",
    "            features['hp_diff_mean'] = np.mean(np.array(p1_hp) - np.array(p2_hp))\n",
    "            # TEST5V--- MOVE DAMAGE EFFICIENCY (uses helper) ---\n",
    "            features['p1_move_damage_mean'] = move_damage_efficiency({\n",
    "                'battle_timeline': [\n",
    "                    t for t in timeline if t.get('p1_move_details')\n",
    "                ]\n",
    "            })\n",
    "            features['p2_move_damage_mean'] = move_damage_efficiency({\n",
    "                'battle_timeline': [\n",
    "                    t for t in timeline if t.get('p2_move_details')\n",
    "                ]\n",
    "            })\n",
    "            features['diff_move_damage_mean'] = (\n",
    "                features['p1_move_damage_mean'] - features['p2_move_damage_mean']\n",
    "            )\n",
    "            \"\"\"6 (performance drop)\n",
    "            # --- FIRST STRIKE RATIO / TEMPO ADVANTAGE (uses helper) ---\n",
    "            features['p1_first_strike_ratio'] = first_strike_ratio(battle)\n",
    "            features['tempo_advantage'] = features['p1_first_strike_ratio'] - 0.5\n",
    "            \"\"\"\n",
    "            #FINE TEST5V\n",
    "            \"\"\"\n",
    "            # TEST5--- MOVE DAMAGE EFFICIENCY ---\n",
    "            # Compute average damage per move for each player\n",
    "            p1_moves = [t.get('p1_move_details', {}) for t in timeline if t.get('p1_move_details')]\n",
    "            p2_moves = [t.get('p2_move_details', {}) for t in timeline if t.get('p2_move_details')]\n",
    "\n",
    "            if p1_moves:\n",
    "                p1_total_damage = sum(m.get('damage', 0) for m in p1_moves)\n",
    "                features['p1_move_damage_mean'] = p1_total_damage / len(p1_moves)\n",
    "            else:\n",
    "                features['p1_move_damage_mean'] = 0.0\n",
    "\n",
    "            if p2_moves:\n",
    "                p2_total_damage = sum(m.get('damage', 0) for m in p2_moves)\n",
    "                features['p2_move_damage_mean'] = p2_total_damage / len(p2_moves)\n",
    "            else:\n",
    "                features['p2_move_damage_mean'] = 0.0\n",
    "\n",
    "            # Relative advantage: difference in mean damage dealt per move\n",
    "            features['diff_move_damage_mean'] = (\n",
    "                features['p1_move_damage_mean'] - features['p2_move_damage_mean']\n",
    "            )\n",
    "            #FINE  TEST5\n",
    "            \"\"\"\n",
    "\n",
    "            #percentuale di tempo in vantaggio (ovvero media dei booleani che indicano il vantaggio => proporzione del vantaggio)\n",
    "            features['p1_hp_advantage_mean'] = np.mean(np.array(p1_hp) > np.array(p2_hp))#GRAN BELLA OPZIONE DI CLASSIFICAZIONE POSSIBILE APPLICAZIONE DI EFFETTI DI ETEROGENEITA\n",
    "\n",
    "\n",
    "\n",
    "            #SUM OF FINAL HP PERCENTAGE OF EACH PLAYER\n",
    "            p1_hp_final ={}\n",
    "            p2_hp_final ={}\n",
    "            for t in timeline:\n",
    "                if t.get('p1_pokemon_state'):\n",
    "                    p1_hp_final[t['p1_pokemon_state']['name']]=t['p1_pokemon_state']['hp_pct']\n",
    "                if t.get('p2_pokemon_state'):\n",
    "                    p2_hp_final[t['p2_pokemon_state']['name']]=t['p2_pokemon_state']['hp_pct']\n",
    "            #print(p1_hp_final)\n",
    "            #numero di pockemon usati dal giocatore nei primi 30 turni\n",
    "            features['p1_n_pokemon_use'] =len(p1_hp_final.keys())\n",
    "            features['p2_n_pokemon_use'] =len(p2_hp_final.keys())\n",
    "            #differenza nello schieramento pockemon dopo 30 turni\n",
    "            features['diff_final_schieramento']=features['p1_n_pokemon_use']-features['p2_n_pokemon_use']\n",
    "            nr_pokemon_sconfitti_p1 = np.sum([1 for e in list(p1_hp_final.values()) if e==0])\n",
    "            nr_pokemon_sconfitti_p2 = np.sum([1 for e in list(p2_hp_final.values()) if e==0])\n",
    "            features['nr_pokemon_sconfitti_p1'] = nr_pokemon_sconfitti_p1\n",
    "            features['nr_pokemon_sconfitti_p2'] = nr_pokemon_sconfitti_p2\n",
    "            #features['nr_pokemon_sconfitti_diff'] = nr_pokemon_sconfitti_p1-nr_pokemon_sconfitti_p2\n",
    "            #DOVREBBERO ESSERE BOMBA VITA DELLE DUE SQUADRE DOPO I 30 TURNI\n",
    "            features['p1_pct_final_hp'] =np.sum(list(p1_hp_final.values()))+(6-len(p1_hp_final.keys()))\n",
    "            features['p2_pct_final_hp'] =np.sum(list(p2_hp_final.values()))+(6-len(p1_hp_final.keys()))\n",
    "            #SAREBBE CLAMOROSO NORMALIZZARLA ANCHE IN BASE ALLA DIFFERENZA DI VITA ASSOLUTA DEI POCKEMON LEADER DEI 2 PLAYER\n",
    "            features['diff_final_hp']=features['p1_pct_final_hp']-features['p2_pct_final_hp']\n",
    "\n",
    "            #9 new\n",
    "            # --- Battle duration and HP loss rate ---\n",
    "            try:\n",
    "                dur = battle_duration(battle)\n",
    "            except Exception:\n",
    "                dur = 0\n",
    "            features[\"battle_duration\"] = dur\n",
    "            features[\"hp_loss_rate\"] = (\n",
    "                features[\"diff_final_hp\"] / dur if dur > 0 else 0.0\n",
    "            )\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #vedo anche come la salute media evolve nel tempo\n",
    "            phases = 3 #early, mid, late game\n",
    "            nr_turns = 30 #numero turni\n",
    "            slice_idx = nr_turns // phases #slice index must be integer\n",
    "            #print(\"slice_idx: \",slice_idx, \"len p1_hp: \",len(p1_hp))\n",
    "            features['early_hp_mean_diff'] = np.mean(np.array(p1_hp[:slice_idx]) - np.array(p2_hp[:slice_idx]))\n",
    "            features['late_hp_mean_diff'] = np.mean(np.array(p1_hp[-slice_idx:]) - np.array(p2_hp[-slice_idx:]))\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            #features['phases_hp_mean_diff'] = features['late_hp_mean_diff'] - features['early_hp_mean_diff']\n",
    "            #77.94% (+/- 0.35%) => 77.94% (+/- 0.41%)\n",
    "            hp_delta = np.array(p1_hp) - np.array(p2_hp)\n",
    "            features['hp_delta_trend'] = np.polyfit(range(len(hp_delta)), hp_delta, 1)[0]\n",
    "            #new\n",
    "            features['hp_advantage_trend'] = hp_advantage_trend(battle)\n",
    "            #6 new --- HP momentum (number of times advantage flips) ---\n",
    "            \"\"\"\n",
    "            features['hp_momentum_flips'] = hp_momentum_flips(battle)\n",
    "            features['hp_flip_rate'] = features['hp_momentum_flips'] / max(1, len(timeline))\n",
    "            \"\"\"\n",
    "            #fluttuazioni negli hp (andamento della partita: stabile o molto caotica)\n",
    "            #77.94% (+/- 0.41%) => 79.09% (+/- 1.02%)\n",
    "            features['p1_hp_std'] = np.std(p1_hp)\n",
    "            features['p2_hp_std'] = np.std(p2_hp)\n",
    "            features['hp_delta_std'] = np.std(hp_delta)\n",
    "\n",
    "            #9.2 new\n",
    "            # --- Efficiency & stability metrics (#10) ---\n",
    "            # 1️⃣ Damage per turn: how much advantage P1 gains in HP per turn\n",
    "            features[\"damage_per_turn\"] = (\n",
    "                features[\"diff_move_damage_mean\"] / max(1, features[\"battle_duration\"])\n",
    "            )\n",
    "            \"\"\"\n",
    "            # 2️⃣ Early lead ratio: does early advantage translate into final dominance\n",
    "            features[\"early_lead_ratio\"] = (\n",
    "                features[\"early_hp_mean_diff\"] / (abs(features[\"diff_final_hp\"]) + 1e-6)\n",
    "            )\n",
    "\n",
    "            # 3️⃣ HP stability ratio: volatility normalized by duration\n",
    "            features[\"hp_stability_ratio\"] = (\n",
    "                features[\"hp_delta_std\"] / max(1, features[\"battle_duration\"])\n",
    "            )\n",
    "            \"\"\"\n",
    "            #fine 9.2\n",
    "\n",
    "            ##STATUS (default nostatus, gli altri sono considerati negativi - i boost sono positivi)\n",
    "            p1_status = [t['p1_pokemon_state'].get('status', 'nostatus') for t in timeline if t.get('p1_pokemon_state')]\n",
    "            p2_status = [t['p2_pokemon_state'].get('status', 'nostatus') for t in timeline if t.get('p2_pokemon_state')]\n",
    "            total_status = set(p1_status + p2_status)\n",
    "            no_effect_status = {'nostatus', 'noeffect'}\n",
    "            negative_status = {s for s in total_status if s not in no_effect_status}\n",
    "            #mean of negative status\n",
    "            p1_negative_status_mean = np.mean([s in negative_status for s in p1_status])\n",
    "            p2_negative_status_mean = np.mean([s in negative_status for s in p2_status])\n",
    "            #status advantage if p1 applied more status to p2 (differenza delle medie dei negativi)\n",
    "            features['p1_bad_status_advantage'] = p2_negative_status_mean-p1_negative_status_mean\n",
    "            #p1_bad_status_advantage.append(features['p1_bad_status_advantage'])\n",
    "            #how many times status changed?\n",
    "            # we have to check that first array shifted by 1 is\n",
    "            # different from the same array excluding the last element\n",
    "            # (so basically checking if status change in time)\n",
    "            #somma il nr di volte in cui lo stato cambia, vedi se collineare\n",
    "            p1_status_change = np.sum(np.array(p1_status[1:]) != np.array(p1_status[:-1]))\n",
    "            p2_status_change = np.sum(np.array(p2_status[1:]) != np.array(p2_status[:-1]))\n",
    "            #features['p1_status_change'] = p1_status_change\n",
    "            #features['p2_status_change'] = p2_status_change\n",
    "            features['status_change_diff'] = p1_status_change - p2_status_change\n",
    "            status_change_diff.append(features['status_change_diff'])\n",
    "\n",
    "            #QUANTO IL TEAM è BILANCIATO (TIPI E VELOCITA)\n",
    "            #79.09% (+/- 1.02%) => 79.29% (+/- 0.92%)\n",
    "            p1_types = [t for p in p1_team for t in p.get('types', []) if t != 'notype']\n",
    "            features['p1_type_diversity'] = len(set(p1_types))\n",
    "\n",
    "            MEDIUM_SPEED_THRESHOLD = 90 #medium-speed pokemon\n",
    "            HIGH_SPEED_THRESHOLD = 100 #fast pokemon\n",
    "            speeds = np.array([p.get('base_spe', 0) for p in p1_team])\n",
    "            features['p1_avg_speed_stat_battaglia'] = np.mean(np.array(speeds) > MEDIUM_SPEED_THRESHOLD)\n",
    "            features['p1_avg_high_speed_stat_battaglia'] = np.mean(np.array(speeds) > HIGH_SPEED_THRESHOLD)\n",
    "\n",
    "\n",
    "            #COMBINAZIONI DI FEATURE\n",
    "            #combino vantaggio negli hp con l'avere pochi status negativi\n",
    "            #79.09% (+/- 1.02%) => 79.13% (+/- 1.06%)\n",
    "            #features['hp_advantage_no_negative_status'] = features['hp_delta_trend'] * (1 - p1_negative_status_mean)\n",
    "            #LA FEATURE è BELLA MA SUPER CORRELATA CON hp_delta_trend 95%\n",
    "            #per il momento semplifico cosi capiamo poi è facile aggiungere\n",
    "\n",
    "        # We also need the ID and the target variable (if it exists)\n",
    "        features['battle_id'] = battle.get('battle_id')\n",
    "        if 'player_won' in battle:\n",
    "            features['player_won'] = int(battle['player_won'])\n",
    "\n",
    "        feature_list.append(features)\n",
    "\n",
    "    return pd.DataFrame(feature_list).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create feature DataFrames for both training and test sets\n",
    "print(\"Processing training data...\")\n",
    "train_df = create_simple_features(train_data)\n",
    "\n",
    "print(\"\\nProcessing test data...\")\n",
    "test_data = []\n",
    "with open(test_file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        test_data.append(json.loads(line))\n",
    "test_df = create_simple_features(test_data)\n",
    "\n",
    "print(\"\\nTraining features preview:\")\n",
    "display(train_df.head())\n",
    "print(\"\\nForma del dataset\",train_df.shape)\n",
    "\n",
    "######UNICA CELLA?step2\n",
    "# Create scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Select numerical feature columns (exclude 'player_won')\n",
    "feature_columns = [col for col in train_df.columns if col not in ['battle_id', 'player_won']]\n",
    "X = train_df[feature_columns]\n",
    "X_train = scaler.fit_transform(X)\n",
    "\n",
    "train_df_scaled = pd.DataFrame(X_train, columns=feature_columns)\n",
    "train_df_scaled['battle_id'] = train_df['battle_id']\n",
    "train_df_scaled['player_won'] = train_df['player_won']\n",
    "\n",
    "\n",
    "#step3\n",
    "#working with standardize we give more weight to variable that have absolute value in start smaller than other, example diff variable\n",
    "# Define features and target\n",
    "features = [col for col in train_df_scaled.columns if col not in ['battle_id', 'player_won']]\n",
    "X = train_df_scaled[features]\n",
    "print(X.shape)\n",
    "y = train_df_scaled['player_won']\n",
    "#step4\n",
    "import time\n",
    "start = time.perf_counter()\n",
    "\"\"\"\n",
    "# Initialize and train the model\n",
    "print(\"Training a simple Logistic Regression model...\")\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_predictions = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Add just above your pipeline\n",
    "USE_L1_SELECTION = True\n",
    "\n",
    "# PCA?\n",
    "USE_PCA = False\n",
    "POLY_ENABLED = False#False#True se enabled 77.64% (+/- 0.69%) altrimenti 77.94% (+/- 0.35%)\n",
    "steps = []\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "interaction_features = [\n",
    "    \"hp_diff_mean\",\n",
    "    \"p1_pct_final_hp\",\n",
    "    \"p1_bad_status_advantage\",\n",
    "    \"status_change_diff\",\n",
    "    \"diff_final_schieramento\",\n",
    "    \"p1_hp_advantage_mean\"\n",
    "]\n",
    "\n",
    "# Polynomial transformer only on selected columns\n",
    "poly = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"poly_subset\", PolynomialFeatures(degree=2, interaction_only=True, include_bias=False), interaction_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # keep all other features unchanged\n",
    ")\n",
    "\n",
    "\n",
    "if POLY_ENABLED:\n",
    "    steps.append((\"poly_subset\", poly))\n",
    "\"\"\"\n",
    "if POLY_ENABLED:\n",
    "    steps.append((\"poly\", PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)))\n",
    "\n",
    "#standardizza\n",
    "steps.append((\"scaler\", StandardScaler()))\n",
    "if USE_PCA:\n",
    "    steps.append((\"pca\", PCA(n_components=0.95, svd_solver=\"full\")))  # ~95% varianza\n",
    "\n",
    "#steps.append((\"logreg\", LogisticRegression(max_iter=2000, random_state=42)))\n",
    "\"\"\"\n",
    "Cross-validation accuracies: [0.845  0.829  0.832  0.8405 0.8355]\n",
    "Mean CV accuracy: 83.64% (+/- 0.58%)\n",
    "\n",
    "a modest but real improvement (≈ +0.05 %) and, more importantly, reduced variance across folds (± 0.58 % → better generalization).\n",
    "That confirms two things:\n",
    "Your feature set is strong — the model is already extracting nearly all available linear signal.\n",
    "L1 regularization is cleaning up minor redundancy, giving you a slightly more stable model.\n",
    "\"\"\"\n",
    "Cs_grid = [0.01, 0.03, 0.08,0.1,0.2, 0.3, 1, 3, 10]\n",
    "if USE_L1_SELECTION:\n",
    "    logreg = LogisticRegressionCV(\n",
    "        Cs=Cs_grid,#20,\n",
    "        cv=5,\n",
    "        penalty=\"l1\",\n",
    "        solver=\"liblinear\",\n",
    "        scoring=\"accuracy\",\n",
    "        max_iter=5000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "else:\n",
    "    logreg = LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        random_state=42,\n",
    "        C=1.0,\n",
    "        penalty=\"l2\",\n",
    "        solver=\"liblinear\"\n",
    "    )\n",
    "\n",
    "steps.append((\"logreg\", logreg))\n",
    "pipe = Pipeline(steps)\n",
    "\n",
    "#kfold cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold CV\n",
    "print(\"Training Logistic Regression con 5-Fold Cross-Validation...\\n\")\n",
    "#print(X)\n",
    "X = train_df_scaled[features]\n",
    "print(X.shape)\n",
    "\n",
    "\"\"\"\n",
    "scores = cross_val_score(pipe, X, y, cv=kfold, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"Cross-validation accuracies: {np.round(scores, 4)}\")\n",
    "print(f\"Mean CV accuracy: {np.mean(scores)*100:.2f}% (+/- {np.std(scores)*100:.2f}%)\")\n",
    "\n",
    "#Training finale\n",
    "pipe.fit(X, y)\n",
    "print(\"\\nFinal model trained on all training data.\")\n",
    "print(logreg.C_ if logreg.C_ else \"not found\")\n",
    "#sm.logisticModel(tran_df[feate1,feature2,feature2**2,fature1*feature2])\n",
    "\"\"\"\n",
    "\n",
    "features = [col for col in train_df_scaled.columns if col not in ['battle_id', 'player_won']]\n",
    "print(features)\n",
    "\n",
    "\n",
    "\n",
    "def sequential_forward_selection(pipe, X, y, kfold, max_features=10):\n",
    "    remaining_features = [col for col in train_df_scaled.columns if col not in ['battle_id', 'player_won']]#list(X.columns)\n",
    "    selected_features = []\n",
    "    best_scores = []\n",
    "    current_best_score = 0\n",
    "\n",
    "    print(f\"\\n🔍 Sequential Forward Selection (up to {max_features} features)\\n\")\n",
    "\n",
    "    for step in range(max_features):\n",
    "        step_results = []\n",
    "\n",
    "        # Try adding each remaining feature and evaluate CV accuracy\n",
    "        for f in remaining_features:\n",
    "            candidate_features = selected_features + [f]\n",
    "            X_subset = X[candidate_features]\n",
    "            scores = cross_val_score(pipe, X_subset, y, cv=kfold, scoring='accuracy', n_jobs=-1)\n",
    "            mean_acc = np.mean(scores)\n",
    "            step_results.append((f, mean_acc))\n",
    "\n",
    "        # Pick the best new feature\n",
    "        best_feature, best_score = max(step_results, key=lambda x: x[1])\n",
    "        improvement = best_score - current_best_score\n",
    "\n",
    "        print(f\"Step {step+1}: added '{best_feature}' → mean CV: {best_score*100:.2f}% (Δ={improvement*100:.2f}%)\")\n",
    "\n",
    "        # Update selections\n",
    "        selected_features.append(best_feature)\n",
    "        remaining_features.remove(best_feature)\n",
    "        best_scores.append(best_score)\n",
    "        current_best_score = best_score\n",
    "\n",
    "    # Return final results\n",
    "    results_df = pd.DataFrame({\n",
    "        \"n_features\": range(1, len(best_scores)+1),\n",
    "        \"cv_accuracy\": np.array(best_scores)*100\n",
    "    })\n",
    "    return selected_features, results_df\n",
    "Greedy = False\n",
    "Tree = False#True\n",
    "if Greedy:\n",
    "  selected, results_df = sequential_forward_selection(pipe, train_df_scaled, y, kfold, max_features=10)\n",
    "\n",
    "  print(\"\\n✅ Selected features in order of addition:\")\n",
    "  print(selected)\n",
    "\n",
    "  print(\"\\n📈 Accuracy progression:\")\n",
    "  print(results_df)\n",
    "elif Tree:\n",
    "  scaler = StandardScaler()\n",
    "  X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "  rf = RandomForestClassifier(\n",
    "      n_estimators=200,\n",
    "      max_depth=5,\n",
    "      random_state=42\n",
    "  )\n",
    "  rf.fit(X_scaled, y)\n",
    "  importances = pd.Series(rf.feature_importances_, index=X_scaled.columns)\n",
    "  top_rf = importances.sort_values(ascending=False).head(10)\n",
    "  print([k for k in top_rf.keys()])\n",
    "else:\n",
    "  #candidate_features = ['status_change_diff', 'diff_final_schieramento']#, 'p1_pct_final_hp', 'p1_bad_status_advantage', 'nr_pokemon_sconfitti_p1']\n",
    "  #candidate_features = ['status_change_diff', 'diff_final_schieramento', 'p1_pct_final_hp', 'p1_bad_status_advantage', 'nr_pokemon_sconfitti_p1', 'p2_n_pokemon_use', 'diff_final_hp', 'hp_diff_mean', 'p1_hp_std', 'late_hp_mean_diff']\n",
    "  #candidate_features = ['status_change_diff', 'diff_final_schieramento', 'p1_pct_final_hp', 'p1_bad_status_advantage', 'nr_pokemon_sconfitti_p1', 'p2_n_pokemon_use', 'diff_final_hp', 'hp_diff_mean', 'p1_hp_std', 'late_hp_mean_diff', 'p2_hp_std', 'p1_n_pokemon_use', 'p1_hp_advantage_mean', 'p2_pct_final_hp', 'early_hp_mean_diff']\n",
    "  #tutte\n",
    "  candidate_features = features\n",
    "  X_subset = X[candidate_features]\n",
    "  #scores = cross_val_score(pipe, X_subset, y, cv=kfold, scoring='accuracy', n_jobs=-1)\n",
    "  #mean_acc = np.mean(scores)\n",
    "  #print(candidate_features, scores, mean_acc)\n",
    "\n",
    "  scores = cross_val_score(pipe, X_subset, y, cv=kfold, scoring='accuracy', n_jobs=-1)\n",
    "  print(f\"Cross-validation accuracies: {np.round(scores, 4)}\")\n",
    "  print(f\"Mean CV accuracy: {np.mean(scores)*100:.2f}% (+/- {np.std(scores)*100:.2f}%)\")\n",
    "  print(f\"candidate len: {len(candidate_features)}\")\n",
    "  print(\"Training finale\")\n",
    "  pipe.fit(X, y)\n",
    "elapsed = time.perf_counter() - start\n",
    "print(f\"⏱️ Elapsed time: {elapsed:.2f} seconds ({elapsed/60:.2f} minutes)\")\n",
    "\n",
    "#phases_hp\n",
    "#hp_delta_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc2a92f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions on the test set...\n",
      "\n",
      "'submission.csv' file created successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battle_id</th>\n",
       "      <th>player_won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   battle_id  player_won\n",
       "0          0           0\n",
       "1          1           0\n",
       "2          2           0\n",
       "3          3           0\n",
       "4          4           0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions on the real test data\n",
    "X_test = test_df[features]\n",
    "print(\"Generating predictions on the test set...\")\n",
    "test_predictions = pipe.predict(X_test)\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'battle_id': test_df['battle_id'],\n",
    "    'player_won': test_predictions\n",
    "})\n",
    "\n",
    "# Save submission CSV\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"\\n'submission.csv' file created successfully!\")\n",
    "display(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fds-kaggle-competition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
