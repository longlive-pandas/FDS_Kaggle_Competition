{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d98fdfed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c3a0ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import os\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingClassifier, \n",
    "    RandomForestClassifier, \n",
    "    StackingClassifier,\n",
    "    VotingClassifier,\n",
    "    AdaBoostClassifier\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from typing import Dict, Iterable\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from typing import Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cc3623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "STAT_FIELDS = [\"base_hp\", \"base_atk\", \"base_def\", \"base_spa\", \"base_spd\", \"base_spe\"]\n",
    "type_chart = {\n",
    "    \"NORMAL\":     {\"ROCK\":0.5, \"GHOST\":0.0, \"STEEL\":0.5},\n",
    "    \"FIRE\":       {\"FIRE\":0.5, \"WATER\":0.5, \"GRASS\":2.0, \"ICE\":2.0, \"BUG\":2.0, \"ROCK\":0.5, \"DRAGON\":0.5, \"STEEL\":2.0},\n",
    "    \"WATER\":      {\"FIRE\":2.0, \"WATER\":0.5, \"GRASS\":0.5, \"GROUND\":2.0, \"ROCK\":2.0, \"DRAGON\":0.5},\n",
    "    \"ELECTRIC\":   {\"WATER\":2.0, \"ELECTRIC\":0.5, \"GRASS\":0.5, \"GROUND\":0.0, \"FLYING\":2.0, \"DRAGON\":0.5},\n",
    "    \"GRASS\":      {\"FIRE\":0.5, \"WATER\":2.0, \"GRASS\":0.5, \"POISON\":0.5, \"GROUND\":2.0, \"FLYING\":0.5, \"BUG\":0.5, \"ROCK\":2.0, \"DRAGON\":0.5, \"STEEL\":0.5},\n",
    "    \"ICE\":        {\"FIRE\":0.5, \"WATER\":0.5, \"GRASS\":2.0, \"ICE\": 0.5, \"GROUND\":2.0, \"FLYING\":2.0, \"DRAGON\":2.0, \"STEEL\":0.5},\n",
    "    \"FIGHTING\":   {\"NORMAL\":2.0, \"ICE\":2.0, \"POISON\":0.5, \"FLYING\":0.5, \"PSYCHIC\":0.5, \"BUG\":0.5, \"ROCK\":2.0, \"GHOST\":0.0, \"DARK\":2.0, \"STEEL\":2.0, \"FAIRY\":0.5},\n",
    "    \"POISON\":     {\"GRASS\":2.0, \"POISON\":0.5, \"GROUND\":0.5, \"ROCK\":0.5, \"GHOST\":0.5, \"STEEL\":0.0, \"FAIRY\":2.0},\n",
    "    \"GROUND\":     {\"FIRE\":2.0, \"ELECTRIC\":2.0, \"GRASS\":0.5, \"POISON\":2.0, \"FLYING\":0.0, \"BUG\":0.5, \"ROCK\":2.0, \"STEEL\":2.0},\n",
    "    \"FLYING\":     {\"ELECTRIC\":0.5, \"GRASS\":2.0, \"FIGHTING\":2.0, \"BUG\":2.0, \"ROCK\":0.5, \"STEEL\":0.5},\n",
    "    \"PSYCHIC\":    {\"FIGHTING\":2.0, \"POISON\":2.0, \"PSYCHIC\":0.5, \"DARK\":0.0, \"STEEL\":0.5},\n",
    "    \"BUG\":        {\"FIRE\":0.5, \"GRASS\":2.0, \"FIGHTING\":0.5, \"POISON\":0.5, \"FLYING\":0.5, \"PSYCHIC\":2.0, \"GHOST\":0.5, \"DARK\":2.0, \"STEEL\":0.5, \"FAIRY\":0.5},\n",
    "    \"ROCK\":       {\"FIRE\":2.0, \"ICE\":2.0, \"FIGHTING\":0.5, \"GROUND\":0.5, \"FLYING\":2.0, \"BUG\":2.0, \"STEEL\":0.5},\n",
    "    \"GHOST\":      {\"NORMAL\":0.0, \"PSYCHIC\":2.0, \"GHOST\":2.0, \"DARK\":0.5},\n",
    "    \"DRAGON\":     {\"DRAGON\":2.0, \"STEEL\":0.5, \"FAIRY\":0.0},\n",
    "    \"DARK\":       {\"FIGHTING\":0.5, \"PSYCHIC\":2.0, \"GHOST\":2.0, \"DARK\": 0.5, \"FAIRY\":0.5},\n",
    "    \"STEEL\":      {\"FIRE\":0.5, \"WATER\":0.5, \"ELECTRIC\":0.5, \"ICE\":2.0, \"ROCK\":2.0, \"STEEL\":0.5, \"FAIRY\":2.0},\n",
    "    \"FAIRY\":      {\"FIRE\":0.5, \"FIGHTING\":2.0, \"POISON\":0.5, \"DRAGON\":2.0, \"DARK\":2.0, \"STEEL\":0.5}\n",
    "}\n",
    "BOOST_MULT = {\n",
    "    -6: 2/8, -5: 2/7, -4: 2/6, -3: 2/5, -2: 2/4, -1: 2/3,\n",
    "     0: 1.0,\n",
    "     1: 1.5,  2: 2.0,  3: 2.5,  4: 3.0,  5: 3.5,  6: 4.0\n",
    "}\n",
    "#12\n",
    "important_effects = [\n",
    "    \"substitute\", \"reflect\", \"light_screen\",\n",
    "    \"leech_seed\", \"bind\", \"wrap\", \"clamp\",\n",
    "    \"confusion\", \"toxic\", \"poison\", \"burn\", \"paralysis\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6845ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_train_data(train_file_path):\n",
    "    train_data = []\n",
    "    try:\n",
    "        with open(train_file_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                train_data.append(json.loads(line))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Could not find the training file at {train_file_path}.\")\n",
    "        print(\"Please make sure you have added the competition data to this notebook.\")\n",
    "    finally:\n",
    "        return train_data\n",
    "def read_test_data(test_file_path):\n",
    "    test_data = []\n",
    "    with open(test_file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            test_data.append(json.loads(line))\n",
    "    return test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7efee3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPETITION_NAME = \"fds-pokemon-battles-prediction-2025\"\n",
    "DATA_PATH = os.path.join(\"input\", COMPETITION_NAME)\n",
    "train_file_path = os.path.join(DATA_PATH, \"train.jsonl\")\n",
    "test_file_path = os.path.join(DATA_PATH, \"test.jsonl\")\n",
    "train_data = read_train_data(train_file_path)\n",
    "test_data = read_test_data(test_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09d2d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "######FEATURES UTILITIES/HELPERS\n",
    "def calculate_interaction_features(features):\n",
    "    \"\"\"\n",
    "    Generate interaction features without modifying the original feature dictionary.\n",
    "    \"\"\"\n",
    "    # Statuts-related interactions\n",
    "    p1_inflict = features.get(\"p1_major_status_infliction_rate\", 0.0)\n",
    "    p2_inflict = features.get(\"p2_major_status_infliction_rate\", 0.0)\n",
    "\n",
    "    p1_suffered = features.get(\"p1_cumulative_major_status_turns_pct\", 0.0)\n",
    "    p2_suffered = features.get(\"p2_cumulative_major_status_turns_pct\", 0.0)\n",
    "\n",
    "    # Offensive/Speed interactions\n",
    "    p1_max_spe = features.get(\"p1_max_speed_stat\", 0.0)\n",
    "    p1_max_off = features.get(\"p1_max_offensive_stat\", 0.0)\n",
    "\n",
    "    # Final HP / KO ratio\n",
    "    p1_final_hp = features.get(\"p1_pct_final_hp\", 0.0)\n",
    "    p1_ko_count = features.get(\"nr_pokemon_sconfitti_p1\", 0)\n",
    "\n",
    "    return {\n",
    "        \"net_major_status_infliction\": p1_inflict - p2_inflict,\n",
    "        \"net_major_status_suffering\": p2_suffered - p1_suffered,\n",
    "        \"p1_max_speed_offense_product\": p1_max_spe * p1_max_off,\n",
    "        \"p1_final_hp_per_ko\": p1_final_hp / (p1_ko_count + 1)\n",
    "    }\n",
    "def compute_status_features(timeline):\n",
    "    \"\"\"\n",
    "    Unifica:\n",
    "      - conta_status_anomali\n",
    "      - calculate_status_efficacy_features\n",
    "      - calculate_p2_status_control_features\n",
    "\n",
    "    Restituisce TUTTE le feature sullo status in un'unica passata.\n",
    "    \"\"\"\n",
    "\n",
    "    # Default response for empty timeline\n",
    "    if not timeline:\n",
    "        return {\n",
    "            # Counts\n",
    "            \"status_p1\": 0,\n",
    "            \"status_p2\": 0,\n",
    "            \"diff_status\": 0,\n",
    "            \"major_status_p1\": 0,\n",
    "            \"major_status_p2\": 0,\n",
    "            \"major_status_diff\": 0,\n",
    "\n",
    "            # Status change\n",
    "            \"p1_status_change\": 0,\n",
    "            \"p2_status_change\": 0,\n",
    "            \"status_change_diff\": 0,\n",
    "\n",
    "            # P1 infliction\n",
    "            \"p1_major_status_infliction_rate\": 0.0,\n",
    "            \"p1_cumulative_major_status_turns_pct\": 0.0,\n",
    "\n",
    "            # P2 infliction\n",
    "            \"p2_major_status_infliction_rate\": 0.0,\n",
    "            \"p2_cumulative_major_status_turns_pct\": 0.0,\n",
    "\n",
    "            # Advantage (negative status mean)\n",
    "            \"p1_bad_status_advantage\": 0.0,\n",
    "        }\n",
    "\n",
    "    MAJOR_STATUSES = {\"slp\", \"frz\"}\n",
    "    MAJOR_STATUS_MOVES = {\"sleeppowder\", \"spore\", \"lovely kiss\", \"sing\"}\n",
    "    NO_EFFECT = {\"nostatus\", \"noeffect\"}\n",
    "\n",
    "    # Counts\n",
    "    status_count_p1 = 0\n",
    "    status_count_p2 = 0\n",
    "    major_count_p1 = 0\n",
    "    major_count_p2 = 0\n",
    "\n",
    "    # Status lists (for change detection & negative mean)\n",
    "    p1_status_list = []\n",
    "    p2_status_list = []\n",
    "\n",
    "    # Major status attempts and successes\n",
    "    p1_attempt = p1_success = 0\n",
    "    p2_attempt = p2_success = 0\n",
    "\n",
    "    # Cumulative major status turns (suffered)\n",
    "    p1_major_suffer = 0\n",
    "    p2_major_suffer = 0\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    #        SINGLE PASS SCAN\n",
    "    # ------------------------------------------------------\n",
    "    for turn in timeline:\n",
    "        # === P1 ===\n",
    "        p1_state = turn.get(\"p1_pokemon_state\", {})\n",
    "        s1 = p1_state.get(\"status\", \"nostatus\").lower()\n",
    "        p1_status_list.append(s1)\n",
    "\n",
    "        if s1 not in NO_EFFECT:\n",
    "            status_count_p1 += 1\n",
    "            if s1 in MAJOR_STATUSES:\n",
    "                major_count_p1 += 1\n",
    "                p1_major_suffer += 1\n",
    "\n",
    "        # === P2 ===\n",
    "        p2_state = turn.get(\"p2_pokemon_state\", {})\n",
    "        s2 = p2_state.get(\"status\", \"nostatus\").lower()\n",
    "        p2_status_list.append(s2)\n",
    "\n",
    "        if s2 not in NO_EFFECT:\n",
    "            status_count_p2 += 1\n",
    "            if s2 in MAJOR_STATUSES:\n",
    "                major_count_p2 += 1\n",
    "                p2_major_suffer += 1\n",
    "\n",
    "        # === P1 Infliction Attempt (P1 hitting P2) ===\n",
    "        m1 = turn.get(\"p1_move_details\")\n",
    "        if m1:\n",
    "            name = m1.get(\"name\", \"\").lower()\n",
    "            if name in MAJOR_STATUS_MOVES:\n",
    "                p1_attempt += 1\n",
    "                if s2 in MAJOR_STATUSES:\n",
    "                    p1_success += 1\n",
    "\n",
    "        # === P2 Infliction Attempt (P2 hitting P1) ===\n",
    "        m2 = turn.get(\"p2_move_details\")\n",
    "        if m2:\n",
    "            name = m2.get(\"name\", \"\").lower()\n",
    "            if name in MAJOR_STATUS_MOVES:\n",
    "                p2_attempt += 1\n",
    "                if s1 in MAJOR_STATUSES:\n",
    "                    p2_success += 1\n",
    "\n",
    "    total_turns = len(timeline)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Compute derived features\n",
    "    # ------------------------------------------------------\n",
    "\n",
    "    # Status changes\n",
    "    p1_status_change = int(np.sum(np.array(p1_status_list[1:]) != np.array(p1_status_list[:-1])))\n",
    "    p2_status_change = int(np.sum(np.array(p2_status_list[1:]) != np.array(p2_status_list[:-1])))\n",
    "\n",
    "    # Negative status means\n",
    "    total_status_set = set(p1_status_list + p2_status_list)\n",
    "    negative_status = {s for s in total_status_set if s not in NO_EFFECT}\n",
    "\n",
    "    p1_negative_mean = np.mean([s in negative_status for s in p1_status_list])\n",
    "    p2_negative_mean = np.mean([s in negative_status for s in p2_status_list])\n",
    "\n",
    "    # Infliction rates\n",
    "    p1_infliction_rate = (p1_success / p1_attempt) if p1_attempt > 0 else 0.0\n",
    "    p2_infliction_rate = (p2_success / p2_attempt) if p2_attempt > 0 else 0.0\n",
    "\n",
    "    # Cumulative suffers\n",
    "    p1_cumulative_pct = p1_major_suffer / total_turns\n",
    "    p2_cumulative_pct = p2_major_suffer / total_turns\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # Return unified result\n",
    "    # ------------------------------------------------------\n",
    "    return {\n",
    "        # Basic counts\n",
    "        \"status_p1\": status_count_p1,\n",
    "        \"status_p2\": status_count_p2,\n",
    "        \"diff_status\": status_count_p1 - status_count_p2,\n",
    "\n",
    "        \"major_status_p1\": major_count_p1,\n",
    "        \"major_status_p2\": major_count_p2,\n",
    "        \"major_status_diff\": major_count_p1 - major_count_p2,\n",
    "\n",
    "        # Changes\n",
    "        \"p1_status_change\": p1_status_change,\n",
    "        \"p2_status_change\": p2_status_change,\n",
    "        \"status_change_diff\": p1_status_change - p2_status_change,\n",
    "\n",
    "        # Negative status advantage\n",
    "        \"p1_bad_status_advantage\": p2_negative_mean - p1_negative_mean,\n",
    "\n",
    "        # Infliction\n",
    "        \"p1_major_status_infliction_rate\": p1_infliction_rate,\n",
    "        \"p1_cumulative_major_status_turns_pct\": p1_cumulative_pct,\n",
    "        \"p2_major_status_infliction_rate\": p2_infliction_rate,\n",
    "        \"p2_cumulative_major_status_turns_pct\": p2_cumulative_pct,\n",
    "    }\n",
    "def get_type_multiplier(move_type: str, defender_types: list, type_chart: dict) -> float:\n",
    "    \"\"\"Calculates the combined type effectiveness multiplier.\"\"\"\n",
    "    if not defender_types or move_type.upper() == \"NOTYPE\":\n",
    "        return 1.0\n",
    "    \n",
    "    multiplier = 1.0\n",
    "    for def_type in defender_types:\n",
    "        try:\n",
    "            # Look up multiplier: TypeChart[Attacking Type][Defending Type]\n",
    "            effectiveness = type_chart.get(move_type.upper(), {}).get(def_type.upper(), 1.0)\n",
    "            multiplier *= effectiveness\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    return multiplier\n",
    "def calculate_team_coverage_features(battle, type_chart):\n",
    "    features = {}\n",
    "    p1_team = battle.get(\"p1_team_details\", [])\n",
    "    p2_lead = battle.get(\"p2_lead_details\", {})\n",
    "    if not p1_team or not p2_lead:\n",
    "        return {\"p1_team_super_effective_moves\": 0.0}\n",
    "    p2_defender_types = [t for t in p2_lead.get(\"types\", []) if t != \"notype\"]\n",
    "    super_effective_count = 0\n",
    "    for p1_poke in p1_team:\n",
    "        p1_poke_types = [t for t in p1_poke.get(\"types\", []) if t != \"notype\"]\n",
    "        has_super_effective_type = False\n",
    "        for p1_type in p1_poke_types:\n",
    "            type_mult = get_type_multiplier(p1_type, p2_defender_types, type_chart)\n",
    "            if type_mult >= 2.0:\n",
    "                has_super_effective_type = True\n",
    "                break\n",
    "        if has_super_effective_type:\n",
    "            super_effective_count += 1\n",
    "    features[\"p1_team_super_effective_moves\"] = float(super_effective_count)\n",
    "    return features\n",
    "def calculate_action_efficiency_features(battle: Dict[str, Any]) -> Dict[str, float]:\n",
    "    features = {}\n",
    "    timeline = battle.get(\"battle_timeline\", [])\n",
    "    \n",
    "    if not timeline:\n",
    "        return {\"p1_status_move_rate\": 0.0}\n",
    "    p1_status_move_count = 0\n",
    "    p1_total_moves = 0\n",
    "    \n",
    "    for turn in timeline:\n",
    "        p1_move = turn.get(\"p1_move_details\")\n",
    "        \n",
    "        if p1_move and p1_move.get(\"category\"):\n",
    "            p1_total_moves += 1\n",
    "            if p1_move[\"category\"].upper() == \"STATUS\":\n",
    "                p1_status_move_count += 1\n",
    "    \n",
    "    if p1_total_moves > 0:\n",
    "        features[\"p1_status_move_rate\"] = p1_status_move_count / p1_total_moves\n",
    "    else:\n",
    "        features[\"p1_status_move_rate\"] = 0.0\n",
    "        \n",
    "    return features\n",
    "def get_pokemon_stats(team, name):\n",
    "    for p in team:\n",
    "        if p.get(\"name\") == name:\n",
    "            return {\n",
    "                \"base_hp\": p.get(\"base_hp\", 0),\n",
    "                \"base_atk\": p.get(\"base_atk\", 0),\n",
    "                \"base_def\": p.get(\"base_def\", 0),\n",
    "                \"base_spa\": p.get(\"base_spa\", 0),\n",
    "                \"base_spd\": p.get(\"base_spd\", 0),\n",
    "                \"base_spe\": p.get(\"base_spe\", 0)\n",
    "            }\n",
    "    return None\n",
    "def compute_mean_stab_moves(timeline, pokemon_dict):\n",
    "    if not timeline:\n",
    "        return {\n",
    "            \"p1_mean_stab\": 0.0,\n",
    "            \"p2_mean_stab\": 0.0,\n",
    "            \"diff_mean_stab\": 0.0\n",
    "        }\n",
    "    p1_stab_counts, p2_stab_counts = [], []\n",
    "    for turn in timeline:\n",
    "        # --- Player 1 ---\n",
    "        p1_state = turn.get(\"p1_pokemon_state\", {})\n",
    "        p1_move = turn.get(\"p1_move_details\", {})\n",
    "        if p1_state and p1_move:\n",
    "            p1_name = p1_state.get(\"name\", \"\").lower()\n",
    "            move_type = p1_move.get(\"type\", \"\").upper()\n",
    "            p1_types = pokemon_dict.get(p1_name, [])\n",
    "            # Check STAB\n",
    "            if move_type in [t.upper() for t in p1_types]:\n",
    "                p1_stab_counts.append(1)\n",
    "            else:\n",
    "                p1_stab_counts.append(0)\n",
    "        # --- Player 2 ---\n",
    "        p2_state = turn.get(\"p2_pokemon_state\", {})\n",
    "        p2_move = turn.get(\"p2_move_details\", {})\n",
    "        if p2_state and p2_move:\n",
    "            p2_name = p2_state.get(\"name\", \"\").lower()\n",
    "            move_type = p2_move.get(\"type\", \"\").upper()\n",
    "            p2_types = pokemon_dict.get(p2_name, [])\n",
    "            if move_type in [t.upper() for t in p2_types]:\n",
    "                p2_stab_counts.append(1)\n",
    "            else:\n",
    "                p2_stab_counts.append(0)\n",
    "    # Compute means\n",
    "    p1_mean_stab = np.sum(p1_stab_counts) if p1_stab_counts else 0.0\n",
    "    p2_mean_stab = np.sum(p2_stab_counts) if p2_stab_counts else 0.0\n",
    "    return {\n",
    "        \"p1_mean_stab\": p1_mean_stab,\n",
    "        \"p2_mean_stab\": p2_mean_stab,\n",
    "        \"diff_mean_stab\": p1_mean_stab - p2_mean_stab\n",
    "    }\n",
    "def compute_avg_offensive_potential(timeline, pokemon_dict):\n",
    "    if not timeline:\n",
    "        return {\n",
    "            \"p1_type_advantage\": 1.0,\n",
    "            \"p2_type_advantage\": 1.0,\n",
    "            \"diff_type_advantage\": 0.0\n",
    "        }\n",
    "    p1_advantages = []\n",
    "    p2_advantages = []\n",
    "    all_move_types = list(type_chart.keys())\n",
    "    for turn in timeline:\n",
    "        p1_name = turn.get(\"p1_pokemon_state\", {}).get(\"name\")\n",
    "        p2_name = turn.get(\"p2_pokemon_state\", {}).get(\"name\")\n",
    "        if not p1_name or not p2_name:\n",
    "            continue\n",
    "        p1_types = pokemon_dict.get(p1_name.lower(), [])\n",
    "        p2_types = pokemon_dict.get(p2_name.lower(), [])\n",
    "        if not p1_types or not p2_types:\n",
    "            continue\n",
    "        #P1 vs P2: Calculate average effectiveness of ALL move types\n",
    "        p1_mult = []\n",
    "        for atk_type in all_move_types:\n",
    "            mult = 1.0\n",
    "            for def_type in p2_types:\n",
    "                mult *= type_chart.get(atk_type.upper(), {}).get(def_type.upper(), 1.0)\n",
    "            p1_mult.append(mult)\n",
    "        #turn summary\n",
    "        p1_adv = np.mean(p1_mult) if p1_mult else 1.0\n",
    "        #P2 vs P1: Calculate average effectiveness of ALL move types\n",
    "        p2_mult = []\n",
    "        for atk_type in all_move_types:\n",
    "            mult = 1.0\n",
    "            for def_type in p1_types:\n",
    "                mult *= type_chart.get(atk_type.upper(), {}).get(def_type.upper(), 1.0)\n",
    "            p2_mult.append(mult)\n",
    "        #turn summary\n",
    "        p2_adv = np.mean(p2_mult) if p2_mult else 1.0\n",
    "        p1_advantages.append(p1_adv)\n",
    "        p2_advantages.append(p2_adv)\n",
    "    if not p1_advantages or not p2_advantages:\n",
    "        return {\n",
    "            \"p1_type_advantage\": 1.0,\n",
    "            \"p2_type_advantage\": 1.0,\n",
    "            \"diff_type_advantage\": 0.0\n",
    "        }\n",
    "    p1_avg = np.mean(p1_advantages)\n",
    "    p2_avg = np.mean(p2_advantages)\n",
    "    \n",
    "    return {\n",
    "        \"p1_type_advantage\": p1_avg,\n",
    "        \"p2_type_advantage\": p2_avg,\n",
    "        \"diff_type_advantage\": p1_avg - p2_avg\n",
    "    }\n",
    "#vedi se usarla\n",
    "def compute_statistics(values: Iterable[float], prefix: str) -> Dict[str, float]:\n",
    "    seq = list(values)\n",
    "    if not seq:\n",
    "        return {\n",
    "            f\"{prefix}_mean\": 0.0,\n",
    "            f\"{prefix}_std\": 0.0,\n",
    "            #less informative: min/max statistics removed\n",
    "            f\"{prefix}_min\": 0.0,\n",
    "            f\"{prefix}_max\": 0.0,\n",
    "        }\n",
    "    arr = np.asarray(seq, dtype=float)\n",
    "    return {\n",
    "        f\"{prefix}_mean\": float(arr.mean()),\n",
    "        f\"{prefix}_std\": float(arr.std(ddof=0)),\n",
    "        #less informative: min/max statistics removed\n",
    "        f\"{prefix}_min\": float(arr.min()),\n",
    "        f\"{prefix}_max\": float(arr.max()),\n",
    "    }\n",
    "def extract_full_hp_features(timeline, battle, team_size=6):\n",
    "    \"\"\"\n",
    "    Unifica tutte le features basate su HP in una sola funzione.\n",
    "    Include:\n",
    "    - HP diff per turno\n",
    "    - vantaggio HP medio\n",
    "    - trend HP (regressione lineare)\n",
    "    - early/late HP advantage\n",
    "    - final HP % delle squadre\n",
    "    - numero Pokémon utilizzati\n",
    "    - numero KO (sconfitti)\n",
    "    - HP instability (std)\n",
    "    - durata battaglia\n",
    "    \"\"\"\n",
    "\n",
    "    if not timeline:\n",
    "        # fallback per battaglie vuote\n",
    "        return {k: 0.0 for k in [\n",
    "            \"hp_diff_mean\", \"p1_hp_advantage_mean\",\n",
    "            \"p1_n_pokemon_use\", \"p2_n_pokemon_use\",\n",
    "            \"diff_final_schieramento\", \"nr_pokemon_sconfitti_p1\",\n",
    "            \"nr_pokemon_sconfitti_p2\", \"nr_pokemon_sconfitti_diff\",\n",
    "            \"p1_pct_final_hp\", \"p2_pct_final_hp\", \"diff_final_hp\",\n",
    "            \"battle_duration\", \"hp_loss_rate\",\n",
    "            \"early_hp_mean_diff\", \"late_hp_mean_diff\",\n",
    "            \"hp_delta_trend\", \"p1_hp_std\", \"p2_hp_std\", \"hp_delta_std\",\n",
    "        ]}\n",
    "\n",
    "    # ================================\n",
    "    # HP arrays per turno\n",
    "    # ================================\n",
    "    p1_hp = [t[\"p1_pokemon_state\"][\"hp_pct\"] for t in timeline if t.get(\"p1_pokemon_state\")]\n",
    "    p2_hp = [t[\"p2_pokemon_state\"][\"hp_pct\"] for t in timeline if t.get(\"p2_pokemon_state\")]\n",
    "\n",
    "    p1_hp = np.array(p1_hp)\n",
    "    p2_hp = np.array(p2_hp)\n",
    "    hp_delta = p1_hp - p2_hp\n",
    "\n",
    "    # ================================\n",
    "    # Feature base sugli HP\n",
    "    # ================================\n",
    "    hp_diff_mean = float(np.mean(hp_delta))\n",
    "    p1_hp_advantage_mean = float(np.mean(p1_hp > p2_hp))\n",
    "\n",
    "    # ================================\n",
    "    # Pokémon finali (ultimo HP noto)\n",
    "    # ================================\n",
    "\n",
    "    p1_hp_final = {}\n",
    "    p2_hp_final = {}\n",
    "\n",
    "    for t in timeline:\n",
    "        if t.get(\"p1_pokemon_state\"):\n",
    "            p1_hp_final[t[\"p1_pokemon_state\"][\"name\"]] = t[\"p1_pokemon_state\"][\"hp_pct\"]\n",
    "        if t.get(\"p2_pokemon_state\"):\n",
    "            p2_hp_final[t[\"p2_pokemon_state\"][\"name\"]] = t[\"p2_pokemon_state\"][\"hp_pct\"]\n",
    "\n",
    "    p1_n_pokemon_use = len(p1_hp_final)\n",
    "    p2_n_pokemon_use = len(p2_hp_final)\n",
    "    diff_final_schieramento = p1_n_pokemon_use - p2_n_pokemon_use\n",
    "\n",
    "    nr_pokemon_sconfitti_p1 = sum(v == 0 for v in p1_hp_final.values())\n",
    "    nr_pokemon_sconfitti_p2 = sum(v == 0 for v in p2_hp_final.values())\n",
    "    nr_pokemon_sconfitti_diff = nr_pokemon_sconfitti_p1 - nr_pokemon_sconfitti_p2\n",
    "\n",
    "    # ================================\n",
    "    # Final HP percent\n",
    "    # (normalizzato anche per Pokémon non entrati)\n",
    "    # ================================\n",
    "    p1_pct_final_hp = sum(p1_hp_final.values()) + (team_size - len(p1_hp_final))\n",
    "    p2_pct_final_hp = sum(p2_hp_final.values()) + (team_size - len(p2_hp_final))\n",
    "    diff_final_hp = p1_pct_final_hp - p2_pct_final_hp\n",
    "\n",
    "    # ================================\n",
    "    # Durata della battaglia\n",
    "    # ================================\n",
    "    try:\n",
    "        duration = sum(\n",
    "            t[\"p1_pokemon_state\"][\"hp_pct\"] > 0 and \n",
    "            t[\"p2_pokemon_state\"][\"hp_pct\"] > 0\n",
    "            for t in timeline\n",
    "        )\n",
    "    except:\n",
    "        duration = len(timeline)\n",
    "\n",
    "    hp_loss_rate = diff_final_hp / duration if duration > 0 else 0.0\n",
    "\n",
    "    # ================================\n",
    "    # Early / Late game HP differences\n",
    "    # ================================\n",
    "    phases = 3\n",
    "    slice_idx = len(p1_hp) // phases\n",
    "\n",
    "    early_hp_mean_diff = float(np.mean(hp_delta[:slice_idx])) if slice_idx > 0 else 0.0\n",
    "    late_hp_mean_diff  = float(np.mean(hp_delta[-slice_idx:])) if slice_idx > 0 else 0.0\n",
    "\n",
    "    # ================================\n",
    "    # Trend HP (regressione)\n",
    "    # ================================\n",
    "    if len(hp_delta) > 1:\n",
    "        slope, _, _, _, _ = linregress(np.arange(len(hp_delta)), hp_delta)\n",
    "        hp_delta_trend = float(slope)\n",
    "    else:\n",
    "        hp_delta_trend = 0.0\n",
    "\n",
    "    # Instabilità HP\n",
    "    p1_hp_std = float(np.std(p1_hp))\n",
    "    p2_hp_std = float(np.std(p2_hp))\n",
    "    hp_delta_std = float(np.std(hp_delta))\n",
    "\n",
    "    return {\n",
    "        \"hp_diff_mean\": hp_diff_mean,\n",
    "        \"p1_hp_advantage_mean\": p1_hp_advantage_mean,\n",
    "\n",
    "        \"p1_n_pokemon_use\": p1_n_pokemon_use,\n",
    "        \"p2_n_pokemon_use\": p2_n_pokemon_use,\n",
    "        \"diff_final_schieramento\": diff_final_schieramento,\n",
    "\n",
    "        \"nr_pokemon_sconfitti_p1\": nr_pokemon_sconfitti_p1,\n",
    "        \"nr_pokemon_sconfitti_p2\": nr_pokemon_sconfitti_p2,\n",
    "        \"nr_pokemon_sconfitti_diff\": nr_pokemon_sconfitti_diff,\n",
    "\n",
    "        \"p1_pct_final_hp\": p1_pct_final_hp,\n",
    "        \"p2_pct_final_hp\": p2_pct_final_hp,\n",
    "        \"diff_final_hp\": diff_final_hp,\n",
    "\n",
    "        \"battle_duration\": duration,\n",
    "        \"hp_loss_rate\": hp_loss_rate,\n",
    "\n",
    "        \"early_hp_mean_diff\": early_hp_mean_diff,\n",
    "        \"late_hp_mean_diff\":  late_hp_mean_diff,\n",
    "\n",
    "        \"hp_delta_trend\": hp_delta_trend,\n",
    "        \"p1_hp_std\": p1_hp_std,\n",
    "        \"p2_hp_std\": p2_hp_std,\n",
    "        \"hp_delta_std\": hp_delta_std,\n",
    "    }\n",
    "def get_full_move_features(timeline):\n",
    "    p1_move_power_weighted = []\n",
    "    p2_move_power_weighted = []\n",
    "\n",
    "    p1_number_attacks = p2_number_attacks = 0\n",
    "    p1_number_status = p2_number_status = 0\n",
    "\n",
    "    p1_sum_negative_priority = 0\n",
    "    p2_sum_negative_priority = 0\n",
    "\n",
    "    # --- PRIORITY TRACKING ---\n",
    "    p1_priorities = []\n",
    "    p2_priorities = []\n",
    "\n",
    "    for turn in timeline:\n",
    "        # ======================================\n",
    "        #           PLAYER 1\n",
    "        # ======================================\n",
    "        move = turn.get(\"p1_move_details\")\n",
    "        if isinstance(move, dict):\n",
    "            acc = move.get(\"accuracy\", 1.0)\n",
    "            base = move.get(\"base_power\", 0)\n",
    "            prio = move.get(\"priority\", 0)\n",
    "\n",
    "            weighted_power = base if acc == 0 else base * acc\n",
    "            p1_move_power_weighted.append(weighted_power)\n",
    "\n",
    "            category = move.get(\"category\", \"STATUS\").upper()\n",
    "            if category in [\"PHYSICAL\", \"SPECIAL\"]:\n",
    "                p1_number_attacks += 1\n",
    "            else:\n",
    "                p1_number_status += 1\n",
    "\n",
    "            if prio == -1:\n",
    "                p1_sum_negative_priority += 1\n",
    "\n",
    "            if prio is not None:\n",
    "                p1_priorities.append(prio)\n",
    "\n",
    "        # ======================================\n",
    "        #           PLAYER 2\n",
    "        # ======================================\n",
    "        move = turn.get(\"p2_move_details\")\n",
    "        if isinstance(move, dict):\n",
    "            acc = move.get(\"accuracy\", 1.0)\n",
    "            base = move.get(\"base_power\", 0)\n",
    "            prio = move.get(\"priority\", 0)\n",
    "\n",
    "            weighted_power = base if acc == 0 else base * acc\n",
    "            p2_move_power_weighted.append(weighted_power)\n",
    "\n",
    "            category = move.get(\"category\", \"STATUS\").upper()\n",
    "            if category in [\"PHYSICAL\", \"SPECIAL\"]:\n",
    "                p2_number_attacks += 1\n",
    "            else:\n",
    "                p2_number_status += 1\n",
    "\n",
    "            if prio == -1:\n",
    "                p2_sum_negative_priority += 1\n",
    "\n",
    "            if prio is not None:\n",
    "                p2_priorities.append(prio)\n",
    "\n",
    "    # =================================================\n",
    "    #      PRIORITY ADVANTAGE METRICS (UNIFIED)\n",
    "    # =================================================\n",
    "    if p1_priorities and p2_priorities:\n",
    "        avg_p1 = np.mean(p1_priorities)\n",
    "        avg_p2 = np.mean(p2_priorities)\n",
    "\n",
    "        priority_diff = avg_p1 - avg_p2\n",
    "\n",
    "        # fraction of turns where P1 had higher priority\n",
    "        min_len = min(len(p1_priorities), len(p2_priorities))\n",
    "        higher = sum(p1_priorities[i] > p2_priorities[i] for i in range(min_len))\n",
    "        priority_rate_advantage = higher / max(1, min_len)\n",
    "    else:\n",
    "        priority_diff = 0.0\n",
    "        priority_rate_advantage = 0.0\n",
    "\n",
    "    return {\n",
    "        \"p1_move_power_weighted\": np.sum(p1_move_power_weighted),\n",
    "        \"p1_number_attacks\": p1_number_attacks,\n",
    "        \"p1_number_status\": p1_number_status,\n",
    "\n",
    "        \"p2_move_power_weighted\": np.sum(p2_move_power_weighted),\n",
    "        \"p2_number_attacks\": p2_number_attacks,\n",
    "        \"p2_number_status\": p2_number_status,\n",
    "\n",
    "        \"diff_number_attack\": p1_number_attacks - p2_number_attacks,\n",
    "        \"diff_number_status\": p1_number_status - p2_number_status,\n",
    "\n",
    "        \"p1_sum_negative_priority\": p1_sum_negative_priority,\n",
    "        \"p2_sum_negative_priority\": p2_sum_negative_priority,\n",
    "        \"diff_negative_priority\": p1_sum_negative_priority - p2_sum_negative_priority,\n",
    "\n",
    "        # Integrated priority metrics\n",
    "        \"priority_diff\": priority_diff,\n",
    "        \"priority_rate_advantage\": priority_rate_advantage,\n",
    "    }\n",
    "def shuffle_dict(d, seed=1234):\n",
    "    rnd = random.Random(seed)       # generatore deterministico\n",
    "    items = list(d.items())\n",
    "    rnd.shuffle(items)              # shuffle riproducibile\n",
    "    return dict(items)\n",
    "def create_pokemon_dict(data):\n",
    "    pokemon_dict = {}\n",
    "    for battle in data:\n",
    "        p1_team = battle.get(\"p1_team_details\", [])\n",
    "        for p in p1_team:\n",
    "            name = p.get(\"name\")\n",
    "            types = [t for t in p.get(\"types\", []) if t != \"notype\"]\n",
    "            if name:\n",
    "                if name not in pokemon_dict:\n",
    "                    pokemon_dict[name] = set()\n",
    "                pokemon_dict[name].update(types)\n",
    "        p2_lead = battle.get(\"p2_lead_details\")\n",
    "        if p2_lead:\n",
    "            name = p2_lead.get(\"name\")\n",
    "            types = [t for t in p2_lead.get(\"types\", []) if t != \"notype\"]\n",
    "            if name:\n",
    "                if name not in pokemon_dict:\n",
    "                    pokemon_dict[name] = set()\n",
    "                pokemon_dict[name].update(types)\n",
    "    return pokemon_dict\n",
    "def compute_static_stats_features(battle):\n",
    "    p1_mean_hp = p1_mean_spe = p1_mean_atk = p1_mean_def = p1_mean_spd = p1_mean_spa = 0.0\n",
    "    p1_lead_hp = p1_lead_spe = p1_lead_atk = p1_lead_def = p1_lead_spd = p1_lead_spa = 0.0\n",
    "    #feature statiche\n",
    "    features = {}\n",
    "    p1_team = battle.get(\"p1_team_details\", [])\n",
    "    if p1_team:\n",
    "        stats = {\n",
    "            \"hp\":  [p.get(\"base_hp\", 0)  for p in p1_team],\n",
    "            \"spe\": [p.get(\"base_spe\", 0) for p in p1_team],\n",
    "            \"atk\": [p.get(\"base_atk\", 0) for p in p1_team],\n",
    "            \"def\": [p.get(\"base_def\", 0) for p in p1_team],\n",
    "            \"spd\": [p.get(\"base_spd\", 0) for p in p1_team],\n",
    "            \"spa\": [p.get(\"base_spa\", 0) for p in p1_team],\n",
    "        }\n",
    "\n",
    "        # max offense and speed\n",
    "        features[\"p1_max_offensive_stat\"] = max(\n",
    "            max(a, s) for a, s in zip(stats[\"atk\"], stats[\"spa\"])\n",
    "        )\n",
    "        features[\"p1_max_speed_stat\"] = max(stats[\"spe\"])\n",
    "\n",
    "        # means\n",
    "        features[\"p1_mean_hp\"]  = np.mean(stats[\"hp\"])\n",
    "        features[\"p1_mean_spe\"] = np.mean(stats[\"spe\"])\n",
    "        features[\"p1_mean_atk\"] = np.mean(stats[\"atk\"])\n",
    "        features[\"p1_mean_def\"] = np.mean(stats[\"def\"])\n",
    "        features[\"p1_mean_sp\"]  = np.mean(stats[\"spd\"])\n",
    "\n",
    "        # Lead stats (primo Pokémon)\n",
    "        lead = p1_team[0]\n",
    "        p1_lead_hp  = lead.get(\"base_hp\", 0)\n",
    "        p1_lead_spe = lead.get(\"base_spe\", 0)\n",
    "        p1_lead_atk = lead.get(\"base_atk\", 0)\n",
    "        p1_lead_def = lead.get(\"base_def\", 0)\n",
    "        p1_lead_spd = lead.get(\"base_spd\", 0)\n",
    "\n",
    "\n",
    "    #Player 2 Lead\n",
    "    p2_hp = p2_spe = p2_atk = p2_def = p2_spd = 0.0\n",
    "    p2_lead = battle.get(\"p2_lead_details\")\n",
    "    if p2_lead:\n",
    "        p2_hp = p2_lead.get(\"base_hp\", 0)\n",
    "        p2_spe = p2_lead.get(\"base_spe\", 0)\n",
    "        p2_atk = p2_lead.get(\"base_atk\", 0)\n",
    "        p2_def = p2_lead.get(\"base_def\", 0)\n",
    "        p2_spd = p2_lead.get(\"base_spd\", 0)\n",
    "\n",
    "    features[\"diff_hp\"]  = p1_lead_hp  - p2_hp\n",
    "    features[\"diff_spe\"] = p1_lead_spe - p2_spe\n",
    "    features[\"diff_atk\"] = p1_lead_atk - p2_atk\n",
    "    features[\"diff_def\"] = p1_lead_def - p2_def\n",
    "    features[\"diff_spd\"] =  p1_lead_spd - p2_spd\n",
    "    return features\n",
    "def compute_boost_features(timeline, base_stats_p1=None, base_stats_p2=None):\n",
    "    if not timeline:\n",
    "        return {\n",
    "            # dynamic boost features\n",
    "            \"p1_max_offense_boost_diff\": 0.0,\n",
    "            # cumulative boost features\n",
    "            \"boost_p1\": 0,\n",
    "            \"boost_p2\": 0,\n",
    "            # extract_boost_features summary\n",
    "            \"diff_boost_last_turn\": 0,\n",
    "            \"diff_boost_atk_last_turn\": 0,\n",
    "            \"diff_boost_def_last_turn\": 0,\n",
    "            \"diff_boost_spa_last_turn\": 0,\n",
    "            \"diff_boost_spd_last_turn\": 0,\n",
    "            \"diff_boost_spe_last_turn\": 0,\n",
    "            \"diff_boost_count_turni\": 0,\n",
    "            \"diff_turn_first_boost\": 0,\n",
    "            \"diff_effective_offense\": 0,\n",
    "            \"diff_effective_defense\": 0,\n",
    "            \"p1_is_faster_effective\": 0,\n",
    "        }\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Init\n",
    "    # ----------------------------------------------------------\n",
    "    offense_boost_diff_list = []\n",
    "    sum_boost_p1 = 0\n",
    "    sum_boost_p2 = 0\n",
    "\n",
    "    p1_boost_count = 0\n",
    "    p2_boost_count = 0\n",
    "    p1_first_turn = None\n",
    "    p2_first_turn = None\n",
    "\n",
    "    last_b1 = None\n",
    "    last_b2 = None\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # SINGLE SCAN OF TIMELINE\n",
    "    # ----------------------------------------------------------\n",
    "    for entry in timeline:\n",
    "        turn = entry.get(\"turn\", None)\n",
    "        b1 = entry.get(\"p1_pokemon_state\", {}).get(\"boosts\", {})\n",
    "        b2 = entry.get(\"p2_pokemon_state\", {}).get(\"boosts\", {})\n",
    "\n",
    "        # save last\n",
    "        last_b1 = b1\n",
    "        last_b2 = b2\n",
    "\n",
    "        # cumulative\n",
    "        sum_boost_p1 += sum(b1.values())\n",
    "        sum_boost_p2 += sum(b2.values())\n",
    "\n",
    "        # dynamic offense/speed diff\n",
    "        p1_off = b1.get(\"atk\", 0) + b1.get(\"spa\", 0)\n",
    "        p2_off = b2.get(\"atk\", 0) + b2.get(\"spa\", 0)\n",
    "        offense_boost_diff_list.append(p1_off - p2_off)\n",
    "\n",
    "        # counts\n",
    "        if any(v != 0 for v in b1.values()):\n",
    "            p1_boost_count += 1\n",
    "            if p1_first_turn is None:\n",
    "                p1_first_turn = turn\n",
    "\n",
    "        if any(v != 0 for v in b2.values()):\n",
    "            p2_boost_count += 1\n",
    "            if p2_first_turn is None:\n",
    "                p2_first_turn = turn\n",
    "\n",
    "    # default last boosts if missing\n",
    "    if last_b1 is None:\n",
    "        last_b1 = {\"atk\":0,\"def\":0,\"spa\":0,\"spd\":0,\"spe\":0}\n",
    "    if last_b2 is None:\n",
    "        last_b2 = {\"atk\":0,\"def\":0,\"spa\":0,\"spd\":0,\"spe\":0}\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # LAST TURN DIFFS\n",
    "    # ----------------------------------------------------------\n",
    "    diff_atk = last_b1[\"atk\"] - last_b2[\"atk\"]\n",
    "    diff_def = last_b1[\"def\"] - last_b2[\"def\"]\n",
    "    diff_spa = last_b1[\"spa\"] - last_b2[\"spa\"]\n",
    "    diff_spd = last_b1[\"spd\"] - last_b2[\"spd\"]\n",
    "    diff_spe = last_b1[\"spe\"] - last_b2[\"spe\"]\n",
    "\n",
    "    diff_total = sum(last_b1.values()) - sum(last_b2.values())\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # EFFECTIVE STATS (only if base stats provided)\n",
    "    # ----------------------------------------------------------\n",
    "    diff_eff_off = 0\n",
    "    diff_eff_def = 0\n",
    "    p1_is_faster_effective = 0\n",
    "\n",
    "    if base_stats_p1 and base_stats_p2:\n",
    "        eff = lambda base, stage: base * BOOST_MULT.get(stage, 1.0)\n",
    "\n",
    "        eff1 = {\n",
    "            s: eff(base_stats_p1[f\"base_{s}\"], last_b1[s]) \n",
    "            for s in [\"atk\",\"def\",\"spa\",\"spd\",\"spe\"]\n",
    "        }\n",
    "        eff2 = {\n",
    "            s: eff(base_stats_p2[f\"base_{s}\"], last_b2[s]) \n",
    "            for s in [\"atk\",\"def\",\"spa\",\"spd\",\"spe\"]\n",
    "        }\n",
    "\n",
    "        diff_eff_off = (eff1[\"atk\"] + eff1[\"spa\"]) - (eff2[\"atk\"] + eff2[\"spa\"])\n",
    "        diff_eff_def = (eff1[\"def\"] + eff1[\"spd\"]) - (eff2[\"def\"] + eff2[\"spd\"])\n",
    "        p1_is_faster_effective = int(eff1[\"spe\"] > eff2[\"spe\"])\n",
    "\n",
    "    return {\n",
    "        # dynamic (max difference)\n",
    "        \"p1_max_offense_boost_diff\": max(offense_boost_diff_list),\n",
    "\n",
    "        # cumulative boosts\n",
    "        \"boost_p1\": sum_boost_p1,\n",
    "        \"boost_p2\": sum_boost_p2,\n",
    "\n",
    "        # last-turn raw differences\n",
    "        \"diff_boost_last_turn\": diff_total,\n",
    "        \"diff_boost_atk_last_turn\": diff_atk,\n",
    "        \"diff_boost_def_last_turn\": diff_def,\n",
    "        \"diff_boost_spa_last_turn\": diff_spa,\n",
    "        \"diff_boost_spd_last_turn\": diff_spd,\n",
    "        \"diff_boost_spe_last_turn\": diff_spe,\n",
    "\n",
    "        # temporal info\n",
    "        \"diff_boost_count_turni\": p1_boost_count - p2_boost_count,\n",
    "        \"diff_turn_first_boost\": (p1_first_turn or 31) - (p2_first_turn or 31),\n",
    "\n",
    "        # effective stats\n",
    "        \"diff_effective_offense\": diff_eff_off,\n",
    "        \"diff_effective_defense\": diff_eff_def,\n",
    "        \"p1_is_faster_effective\": p1_is_faster_effective,\n",
    "    }\n",
    "def compute_effect_features(timeline):\n",
    "    freq = {\n",
    "        \"p1\": {eff: 0 for eff in important_effects},\n",
    "        \"p2\": {eff: 0 for eff in important_effects},\n",
    "    }\n",
    "    first_turn = {\n",
    "        \"p1\": {eff: None for eff in important_effects},\n",
    "        \"p2\": {eff: None for eff in important_effects},\n",
    "    }\n",
    "\n",
    "    # ---- SINGLE PASS ----\n",
    "    for entry in timeline:\n",
    "        turn = entry.get(\"turn\", None)\n",
    "\n",
    "        for prefix, state_key in ((\"p1\", \"p1_pokemon_state\"), (\"p2\", \"p2_pokemon_state\")):\n",
    "            state = entry.get(state_key, {})\n",
    "            effects = state.get(\"effects\", [])\n",
    "\n",
    "            for eff in important_effects:\n",
    "                if eff in effects:\n",
    "                    freq[prefix][eff] += 1\n",
    "                    if first_turn[prefix][eff] is None:\n",
    "                        first_turn[prefix][eff] = turn\n",
    "\n",
    "    # replace None with 31\n",
    "    for prefix in (\"p1\", \"p2\"):\n",
    "        for eff in important_effects:\n",
    "            if first_turn[prefix][eff] is None:\n",
    "                first_turn[prefix][eff] = 31\n",
    "\n",
    "    # ---- flatten result in feature dict ----\n",
    "    out = {}\n",
    "    for prefix in (\"p1\", \"p2\"):\n",
    "        for eff in important_effects:\n",
    "            out[f\"{prefix}_{eff}_freq\"] = freq[prefix][eff]\n",
    "            out[f\"{prefix}_{eff}_first_turn\"] = first_turn[prefix][eff]\n",
    "\n",
    "    return out\n",
    "def calculate_expected_damage_ratio_turn_1(battle, type_chart):\n",
    "    try:\n",
    "        timeline = battle.get(\"battle_timeline\", [])\n",
    "        p1_team = battle.get(\"p1_team_details\", [])\n",
    "        p2_lead = battle.get(\"p2_lead_details\", {})\n",
    "\n",
    "        if not timeline or not p1_team or not p2_lead:\n",
    "            return 0.0\n",
    "\n",
    "        turn_1 = timeline[0]\n",
    "        p1_move = turn_1.get(\"p1_move_details\")\n",
    "        p2_move = turn_1.get(\"p2_move_details\")\n",
    "\n",
    "        p1_lead_stats = p1_team[0]\n",
    "        p2_lead_stats = p2_lead\n",
    "\n",
    "        # defender types\n",
    "        p1_defender_types = [t for t in p1_lead_stats.get(\"types\", []) if t != \"notype\"]\n",
    "        p2_defender_types = [t for t in p2_lead_stats.get(\"types\", []) if t != \"notype\"]\n",
    "\n",
    "        p1_expected_damage = 0.0\n",
    "        p2_expected_damage = 0.0\n",
    "\n",
    "        # -----------------------------\n",
    "        # P1 damage on P2\n",
    "        # -----------------------------\n",
    "        if p1_move and p1_move.get(\"category\") in [\"SPECIAL\", \"PHYSICAL\"]:\n",
    "            base_power = p1_move.get(\"base_power\", 0)\n",
    "            move_type = p1_move.get(\"type\", \"\").upper()\n",
    "            cat = p1_move.get(\"category\", \"\").upper()\n",
    "\n",
    "            if cat == \"SPECIAL\":\n",
    "                att = p1_lead_stats.get(\"base_spa\", 1)\n",
    "                dfn = p2_lead_stats.get(\"base_spd\", 1)\n",
    "            else:\n",
    "                att = p1_lead_stats.get(\"base_atk\", 1)\n",
    "                dfn = p2_lead_stats.get(\"base_def\", 1)\n",
    "\n",
    "            m = get_type_multiplier(move_type, p2_defender_types, type_chart)\n",
    "            p1_expected_damage = base_power * (att / dfn) * m\n",
    "\n",
    "        # -----------------------------\n",
    "        # P2 damage on P1\n",
    "        # -----------------------------\n",
    "        if p2_move and p2_move.get(\"category\") in [\"SPECIAL\", \"PHYSICAL\"]:\n",
    "            base_power = p2_move.get(\"base_power\", 0)\n",
    "            move_type = p2_move.get(\"type\", \"\").upper()\n",
    "            cat = p2_move.get(\"category\", \"\").upper()\n",
    "\n",
    "            if cat == \"SPECIAL\":\n",
    "                att = p2_lead_stats.get(\"base_spa\", 1)\n",
    "                dfn = p1_lead_stats.get(\"base_spd\", 1)\n",
    "            else:\n",
    "                att = p2_lead_stats.get(\"base_atk\", 1)\n",
    "                dfn = p1_lead_stats.get(\"base_def\", 1)\n",
    "\n",
    "            m = get_type_multiplier(move_type, p1_defender_types, type_chart)\n",
    "            p2_expected_damage = base_power * (att / dfn) * m\n",
    "\n",
    "        # -----------------------------\n",
    "        # Log-smoothed advantage\n",
    "        # -----------------------------\n",
    "        p1_smooth = p1_expected_damage + 1.0\n",
    "        p2_smooth = p2_expected_damage + 1.0\n",
    "\n",
    "        return float(np.log(p1_smooth) - np.log(p2_smooth))\n",
    "\n",
    "    except Exception:\n",
    "        # Qualsiasi errore → fallback sicuro\n",
    "        return 0.0\n",
    "def extract_dynamic_stat_diffs(timeline, p1_team, battle):\n",
    "    MEDIUM_SPEED_THRESHOLD = 90   # medium-speed Pokémon\n",
    "    HIGH_SPEED_THRESHOLD = 100    # high-speed Pokémon\n",
    "\n",
    "    # ====================================================\n",
    "    # 1) TEAM SPEED-BASED FEATURES (NUOVE)\n",
    "    # ====================================================\n",
    "    speeds = np.array([p.get(\"base_spe\", 0) for p in p1_team])\n",
    "\n",
    "    p1_avg_speed_stat_battaglia = float(np.mean(speeds > MEDIUM_SPEED_THRESHOLD))\n",
    "    p1_avg_high_speed_stat_battaglia = float(np.mean(speeds > HIGH_SPEED_THRESHOLD))\n",
    "\n",
    "    # ====================================================\n",
    "    # 2) DYNAMIC STAT DIFFERENCES P1 ACTIVE VS P2 LEAD\n",
    "    # ====================================================\n",
    "    stat_keys = [\"base_atk\", \"base_spa\", \"base_spe\"]\n",
    "    stat_diffs = {k: [] for k in stat_keys}\n",
    "\n",
    "    p2_lead = battle.get(\"p2_lead_details\", {})\n",
    "\n",
    "    for t in timeline:\n",
    "        p1_state = t.get(\"p1_pokemon_state\", {})\n",
    "        p2_state = t.get(\"p2_pokemon_state\", {})\n",
    "\n",
    "        p1_name = p1_state.get(\"name\")\n",
    "        p2_name = p2_state.get(\"name\")\n",
    "\n",
    "        # Recupera stats Pokémon attivo P1\n",
    "        p1_stats = get_pokemon_stats(p1_team, p1_name) if p1_name else None\n",
    "\n",
    "        # Recupera stats Pokémon lead P2 se è quello attivo\n",
    "        p2_stats = None\n",
    "        if p2_name and p2_lead and p2_lead.get(\"name\") == p2_name:\n",
    "            p2_stats = {\n",
    "                \"base_hp\":  p2_lead.get(\"base_hp\", 0),\n",
    "                \"base_atk\": p2_lead.get(\"base_atk\", 0),\n",
    "                \"base_def\": p2_lead.get(\"base_def\", 0),\n",
    "                \"base_spa\": p2_lead.get(\"base_spa\", 0),\n",
    "                \"base_spd\": p2_lead.get(\"base_spd\", 0),\n",
    "                \"base_spe\": p2_lead.get(\"base_spe\", 0)\n",
    "            }\n",
    "\n",
    "        if not p1_stats or not p2_stats:\n",
    "            continue\n",
    "\n",
    "        # Accumula differenze dinamiche\n",
    "        for stat in stat_keys:\n",
    "            stat_diffs[stat].append(p1_stats[stat] - p2_stats[stat])\n",
    "\n",
    "    # ====================================================\n",
    "    # 3) Aggregazioni finali\n",
    "    # ====================================================\n",
    "    results = {}\n",
    "\n",
    "    for stat, values in stat_diffs.items():\n",
    "        if values:\n",
    "            results[f\"mean_{stat}_diff_timeline\"] = float(np.mean(values))\n",
    "            results[f\"std_{stat}_diff_timeline\"]  = float(np.std(values))\n",
    "        else:\n",
    "            results[f\"mean_{stat}_diff_timeline\"] = 0.0\n",
    "            results[f\"std_{stat}_diff_timeline\"]  = 0.0\n",
    "\n",
    "    # =========================\n",
    "    # ADD THE NEW SPEED FEATURES\n",
    "    # =========================\n",
    "    results[\"p1_avg_speed_stat_battaglia\"] = p1_avg_speed_stat_battaglia\n",
    "    results[\"p1_avg_high_speed_stat_battaglia\"] = p1_avg_high_speed_stat_battaglia\n",
    "\n",
    "    return results\n",
    "def extract_type_advantage_features(battle, timeline, p1_team, pokemon_dict, type_chart):\n",
    "    features = {}\n",
    "    all_types = list(type_chart.keys())\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # 1. TEAM TYPE DIVERSITY (P1)\n",
    "    # ---------------------------------------------\n",
    "    p1_types = [t for p in p1_team for t in p.get(\"types\", []) if t != \"notype\"]\n",
    "    features[\"p1_type_diversity\"] = len(set(p1_types))\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # 2. TEAM RESISTANCE + WEAKNESS (P1)\n",
    "    # ---------------------------------------------\n",
    "    def team_weakness(team):\n",
    "        weakness_counts = []\n",
    "        for p in team:\n",
    "            types = [t for t in p.get(\"types\", []) if t != \"notype\"]\n",
    "            if not types:\n",
    "                continue\n",
    "            weak_to = 0\n",
    "            for atk in all_types:\n",
    "                mult = 1.0\n",
    "                for d in types:\n",
    "                    mult *= type_chart.get(atk.upper(), {}).get(d.upper(), 1.0)\n",
    "                if mult > 1.0:\n",
    "                    weak_to += 1\n",
    "            weakness_counts.append(weak_to)\n",
    "        if not weakness_counts:\n",
    "            return 0.0\n",
    "        mean_weak = np.mean(weakness_counts)\n",
    "        return mean_weak / len(all_types)\n",
    "\n",
    "    def team_resistance(team):\n",
    "        weakness_counts = []\n",
    "        for p in team:\n",
    "            types = [t for t in p.get(\"types\", []) if t != \"notype\"]\n",
    "            if not types:\n",
    "                continue\n",
    "            weak_to = 0\n",
    "            for atk in all_types:\n",
    "                mult = 1.0\n",
    "                for d in types:\n",
    "                    mult *= type_chart.get(atk.upper(), {}).get(d.upper(), 1.0)\n",
    "                if mult > 1.0:\n",
    "                    weak_to += 1\n",
    "            weakness_counts.append(weak_to)\n",
    "        if not weakness_counts:\n",
    "            return 1.0\n",
    "        mean_weak = np.mean(weakness_counts)\n",
    "        return 1.0 / mean_weak if mean_weak > 0 else 1.0\n",
    "\n",
    "    features[\"p1_type_resistance\"] = team_resistance(p1_team)\n",
    "    features[\"p1_type_weakness\"] = team_weakness(p1_team)\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # 3. COVERAGE: P1 ha tipi super-effective vs P2 lead?\n",
    "    # ---------------------------------------------\n",
    "    p2_lead = battle.get(\"p2_lead_details\", {})\n",
    "    if p2_lead:\n",
    "        p2_types = [t for t in p2_lead.get(\"types\", []) if t != \"notype\"]\n",
    "        count_supereffective = 0\n",
    "\n",
    "        for p1 in p1_team:\n",
    "            p1_types = [t for t in p1.get(\"types\", []) if t != \"notype\"]\n",
    "            found = False\n",
    "            for atk in p1_types:\n",
    "                if get_type_multiplier(atk, p2_types, type_chart) >= 2.0:\n",
    "                    found = True\n",
    "                    break\n",
    "            if found:\n",
    "                count_supereffective += 1\n",
    "\n",
    "        features[\"p1_team_super_effective_moves\"] = float(count_supereffective)\n",
    "    else:\n",
    "        features[\"p1_team_super_effective_moves\"] = 0.0\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # 4. TIMELINE TYPE ADVANTAGE (P1 vs P2)\n",
    "    # ---------------------------------------------\n",
    "    def avg_advantage_over_timeline():\n",
    "        p1_adv_list = []\n",
    "        p2_adv_list = []\n",
    "\n",
    "        for turn in timeline:\n",
    "            p1_name = turn.get(\"p1_pokemon_state\", {}).get(\"name\", \"\")\n",
    "            p2_name = turn.get(\"p2_pokemon_state\", {}).get(\"name\", \"\")\n",
    "            if not p1_name or not p2_name:\n",
    "                continue\n",
    "\n",
    "            p1_types = pokemon_dict.get(p1_name.lower(), [])\n",
    "            p2_types = pokemon_dict.get(p2_name.lower(), [])\n",
    "            if not p1_types or not p2_types:\n",
    "                continue\n",
    "\n",
    "            # P1 attacking P2\n",
    "            p1_results = []\n",
    "            for atk in all_types:\n",
    "                mult = 1.0\n",
    "                for d in p2_types:\n",
    "                    mult *= type_chart.get(atk.upper(), {}).get(d.upper(), 1.0)\n",
    "                p1_results.append(mult)\n",
    "\n",
    "            # P2 attacking P1\n",
    "            p2_results = []\n",
    "            for atk in all_types:\n",
    "                mult = 1.0\n",
    "                for d in p1_types:\n",
    "                    mult *= type_chart.get(atk.upper(), {}).get(d.upper(), 1.0)\n",
    "                p2_results.append(mult)\n",
    "\n",
    "            if p1_results:\n",
    "                p1_adv_list.append(np.mean(p1_results))\n",
    "            if p2_results:\n",
    "                p2_adv_list.append(np.mean(p2_results))\n",
    "\n",
    "        if not p1_adv_list or not p2_adv_list:\n",
    "            return (1.0, 1.0, 0.0)\n",
    "\n",
    "        p1_avg = np.mean(p1_adv_list)\n",
    "        p2_avg = np.mean(p2_adv_list)\n",
    "        return (p1_avg, p2_avg, p1_avg - p2_avg)\n",
    "\n",
    "    p1_adv, p2_adv, diff_adv = avg_advantage_over_timeline()\n",
    "\n",
    "    features[\"p1_type_advantage\"] = p1_adv\n",
    "    features[\"p2_type_advantage\"] = p2_adv\n",
    "    features[\"diff_type_advantage\"] = diff_adv\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "292b6d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_features(data: list[dict], is_test=False) -> pd.DataFrame:\n",
    "    feature_list = []\n",
    "    pokemon_dict = create_pokemon_dict(data)\n",
    "    #definiamo le features\n",
    "    for battle in tqdm(data, desc=\"Extracting features\"):\n",
    "        battle_id = battle.get(\"battle_id\")\n",
    "        features = {}\n",
    "        #STATISTICHE\n",
    "        features.update(compute_static_stats_features(battle))\n",
    "        p1_team = battle[\"p1_team_details\"]\n",
    "        p1_lead = p1_team[0]\n",
    "        p2_lead = battle[\"p2_lead_details\"]\n",
    "        timeline = battle.get(\"battle_timeline\", [])\n",
    "        if timeline:\n",
    "            #HP\n",
    "            features.update(extract_full_hp_features(timeline, battle, team_size=len(p1_team)))\n",
    "            #BOOST\n",
    "            features.update(compute_boost_features(timeline, p1_lead, p2_lead))\n",
    "            #TYPE\n",
    "            features.update(\n",
    "                extract_type_advantage_features(battle, timeline, p1_team, pokemon_dict, type_chart)\n",
    "            )\n",
    "            #MOVES and priority\n",
    "            features.update(get_full_move_features(timeline))\n",
    "            #STATUS\n",
    "            features.update(compute_status_features(timeline))\n",
    "            #EFFECTS\n",
    "            features.update(compute_effect_features(timeline))\n",
    "            #EXPECTED DAMAGE TURN1\n",
    "            features[\"expected_damage_ratio_turn_1\"] = calculate_expected_damage_ratio_turn_1(battle, type_chart)\n",
    "            #DYNAMIC STATS\n",
    "            features.update(extract_dynamic_stat_diffs(timeline, p1_team, battle))\n",
    "            #STABS\n",
    "            features.update(compute_mean_stab_moves(timeline, pokemon_dict))\n",
    "            #interaction\n",
    "            features.update(calculate_interaction_features(features))\n",
    "        features[\"battle_id\"] = battle_id\n",
    "        if \"player_won\" in battle:\n",
    "            features[\"player_won\"] = int(battle[\"player_won\"])\n",
    "        #features = dict(sorted(features.items()))\n",
    "        features = shuffle_dict(features, seed=5678)\n",
    "        feature_list.append(features)\n",
    "    return pd.DataFrame(feature_list).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "337ed096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be9955fad4c544b59d73df18b6a21cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2a538d3ac841c787631e90a5187896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = create_features(train_data)\n",
    "test_df = create_features(test_data)\n",
    "features = [col for col in train_df.columns if col not in [\"battle_id\", \"player_won\"]]\n",
    "X = train_df[features]\n",
    "y = train_df[\"player_won\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32217bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipe(USE_PCA=False, POLY_ENABLED=False, seed=1234):\n",
    "    steps = []\n",
    "    if POLY_ENABLED:\n",
    "        steps.append((\"poly\", PolynomialFeatures(degree=2, include_bias=False)))\n",
    "    steps.append((\"scaler\", StandardScaler()))\n",
    "    if USE_PCA:\n",
    "        steps.append((\"pca\", PCA(n_components=0.95, svd_solver=\"full\")))\n",
    "    steps.append((\"logreg\", LogisticRegression(max_iter=4000, random_state=seed)))\n",
    "    pipe = Pipeline(steps)\n",
    "    param_grid = [\n",
    "        {\n",
    "            \"logreg__solver\": [\"liblinear\"],\n",
    "            \"logreg__penalty\": [\"l1\", \"l2\"],\n",
    "            \"logreg__C\": [0.01, 0.1, 1, 10],\n",
    "        },\n",
    "        {\n",
    "            \"logreg__solver\": [\"lbfgs\"],\n",
    "            \"logreg__penalty\": [\"l2\"],\n",
    "            \"logreg__C\": [0.01, 0.1, 1, 10],\n",
    "        },\n",
    "    ]\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"accuracy\",#roc_auc#accuracy\n",
    "        n_jobs=4,        # use 4 cores in parallel\n",
    "        cv=kfold,            # 5-fold cross-validation, more on this later\n",
    "        refit=True,      # retrain the best model on the full training set\n",
    "        return_train_score=True\n",
    "    )\n",
    "    return grid_search  # not fitted yet — caller will call `fit(X, y)`\n",
    "def predict_and_submit(test_df, features, pipe, prefix=\"\"):\n",
    "    os.makedirs(\"output\", exist_ok=True)\n",
    "    # Make predictions on the real test data\n",
    "    X_test = test_df[features]\n",
    "    print(\"Generating predictions on the test set...\")\n",
    "    test_predictions = pipe.predict(X_test)\n",
    "    # Create the submission DataFrame\n",
    "    submission_df = pd.DataFrame({\n",
    "        \"battle_id\": test_df[\"battle_id\"],\n",
    "        \"player_won\": test_predictions\n",
    "    })\n",
    "    submission_df.to_csv(f\"output/{prefix}_submission.csv\", index=False)\n",
    "    print(\"\\nsubmission.csv file created successfully!\")\n",
    "def train_regularization(X, y, USE_PCA=False, POLY_ENABLED=False, seed=1234):\n",
    "    grid_search = build_pipe(USE_PCA=USE_PCA, POLY_ENABLED=POLY_ENABLED, seed=seed)\n",
    "    grid_search.fit(X, y)\n",
    "    print(f\"Best params: {grid_search.best_params_}\")\n",
    "    mean_score = grid_search.best_score_\n",
    "    std_score = grid_search.cv_results_[\"std_test_score\"][grid_search.best_index_]\n",
    "    print(f\"Best CV mean: {mean_score:.4f} ± {std_score:.4f}\")\n",
    "    best_model = grid_search.best_estimator_\n",
    "    return best_model\n",
    "def get_power_set_non_empty_as_list(array):\n",
    "  n = len(array)\n",
    "  combinations_iterators = (\n",
    "      itertools.combinations(array, k) for k in range(1, n + 1)\n",
    "  )\n",
    "  non_empty_subsets_tuples = itertools.chain.from_iterable(combinations_iterators)\n",
    "  non_empty_subsets_lists = [\n",
    "      list(subset_tuple) for subset_tuple in non_empty_subsets_tuples\n",
    "  ]\n",
    "  return non_empty_subsets_lists\n",
    "def select_top_features(model, X, y, k=50, scoring=\"roc_auc\"):\n",
    "    print(f\"\\nCalcolo permutation importances (Top {k})...\")\n",
    "    t0 = time.time()\n",
    "    model.fit(X, y)\n",
    "    result = permutation_importance(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        scoring=scoring,\n",
    "        n_repeats=10,\n",
    "        random_state=1234,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    importances = result.importances_mean\n",
    "    feature_names = np.array(X.columns)\n",
    "    idx_sorted = np.argsort(importances)[::-1]\n",
    "    top_features = feature_names[idx_sorted][:k]\n",
    "    top_scores = importances[idx_sorted][:k]\n",
    "    importance_df = pd.DataFrame({\n",
    "        \"feature\": top_features,\n",
    "        \"importance\": top_scores\n",
    "    })\n",
    "    print(importance_df.head(20))\n",
    "    print(f\"[Permutation Importance completato in {time.time()-t0:.2f}s]\")\n",
    "    return list(top_features), importance_df\n",
    "#COSTRUZIONE DEL VOTING MODEL (XGB + RF + LR)\n",
    "def build_voting_model():\n",
    "    #Logistic Regression (regolarizzata)\n",
    "    lr = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lr\", LogisticRegression(\n",
    "            C=0.3,\n",
    "            penalty=\"l2\",\n",
    "            solver=\"liblinear\",\n",
    "            max_iter=1500,\n",
    "            random_state=1234\n",
    "        ))\n",
    "    ])\n",
    "    #Random Forest (meno overfitting)\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=4,\n",
    "        min_samples_leaf=4,\n",
    "        max_features=\"sqrt\",\n",
    "        bootstrap=True,\n",
    "        n_jobs=-1,\n",
    "        random_state=1234\n",
    "    )\n",
    "    #XGBoost (modello principale)\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=350,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        min_child_weight=3,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        reg_lambda=1.5,\n",
    "        reg_alpha=0.1,\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        tree_method=\"hist\",\n",
    "        random_state=1234,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    #Voting Ensemble\n",
    "    model = VotingClassifier(\n",
    "        estimators=[\n",
    "            (\"xgb\", xgb),\n",
    "            (\"rf\", rf),\n",
    "            (\"lr\", lr)\n",
    "        ],\n",
    "        voting=\"soft\",\n",
    "        weights=[4, 1, 1],   #XGB più influente\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    return model\n",
    "def train_with_feature_selection(X, y, k=50):\n",
    "    print(\"\\nFASE 1: Training iniziale con tutte le feature\")\n",
    "    base_model = build_voting_model()\n",
    "    t0 = time.time()\n",
    "    base_model.fit(X, y)\n",
    "    print(f\"Modello iniziale addestrato in {time.time()-t0:.2f}s\")\n",
    "    #Feature Selection\n",
    "    selected_features, importance_df = select_top_features(base_model, X, y, k=k)\n",
    "    print(f\"\\nTop-{k} feature selezionate:\")\n",
    "    print(selected_features)\n",
    "    print(\"\\nFASE 2: Retraining con feature selezionate\")\n",
    "    final_model = build_voting_model()\n",
    "    X_sel = X[selected_features]\n",
    "    t1 = time.time()\n",
    "    final_model.fit(X_sel, y)\n",
    "    print(f\"Retraining completato in {time.time()-t1:.2f}s\\n\")\n",
    "    #Performance\n",
    "    y_pred = final_model.predict(X_sel)\n",
    "    y_proba = final_model.predict_proba(X_sel)[:, 1]\n",
    "    acc_cv = cross_val_score(final_model, X_sel, y, cv=5, scoring=\"accuracy\")\n",
    "    auc_cv = cross_val_score(final_model, X_sel, y, cv=5, scoring=\"roc_auc\")\n",
    "    print(\"\\nRISULTATI FINALI\")\n",
    "    print(f\"Training Accuracy: {accuracy_score(y, y_pred):.4f}\")\n",
    "    print(f\"Training AUC: {roc_auc_score(y, y_proba):.4f}\")\n",
    "    print(f\"CV Accuracy: {acc_cv.mean():.4f} ± {acc_cv.std():.4f}\")\n",
    "    print(f\"CV AUC: {auc_cv.mean():.4f} ± {auc_cv.std():.4f}\")\n",
    "    return final_model, selected_features, importance_df\n",
    "def correlation_pruning(X, threshold=0.90):\n",
    "    corr = X.corr().abs()\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "    to_drop = [col for col in upper.columns if any(upper[col] > threshold)]\n",
    "    print(f\"Dropped {len(to_drop)} correlated features: {to_drop} (>{threshold}).\")\n",
    "    return [f for f in X.columns if f not in to_drop]\n",
    "def final(model, prefix=\"\"):\n",
    "    selected = features\n",
    "    X_selected = X[selected]\n",
    "    model.fit(X_selected, y)\n",
    "    final_pipe = model\n",
    "    y_train_pred = final_pipe.predict(X_selected)\n",
    "    y_train_proba = final_pipe.predict_proba(X_selected)[:, 1]\n",
    "    acc = cross_val_score(final_pipe, X_selected, y, cv=5, scoring=\"accuracy\")\n",
    "    auc = cross_val_score(final_pipe, X_selected, y, cv=5, scoring=\"roc_auc\")\n",
    "    end_time = time.time()\n",
    "    print(\"featureArray,accuracy_score_training,roc_auc_score,accuracy_cross_val_score,roc_auc_cross_val_score\")\n",
    "    print(f\"{[f for f in selected]},\\n[{int(end_time-middle_time)}sec-{len(selected)}feat]\\n{accuracy_score(y, y_train_pred)}->{acc.mean():.4f} ± {acc.std():.4f}, {roc_auc_score(y, y_train_proba)}->{auc.mean():.4f} ± {auc.std():.4f}\")\n",
    "    complete_prefix = prefix+str(int(10000*accuracy_score(y, y_train_pred)))+\"_\"+str(int(10000*acc.mean()))\n",
    "    predict_and_submit(test_df, selected, final_pipe, prefix=complete_prefix)\n",
    "    print(f\"Total execution time: {int(end_time-start_time)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6361fa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FASE 1: Training iniziale con tutte le feature\n",
      "Modello iniziale addestrato in 2.60s\n",
      "\n",
      "Calcolo permutation importances (Top 80)...\n",
      "                        feature  importance\n",
      "0                 diff_final_hp    0.021684\n",
      "1                  hp_loss_rate    0.006199\n",
      "2       diff_final_schieramento    0.006132\n",
      "3              p2_n_pokemon_use    0.005772\n",
      "4                  hp_delta_std    0.003442\n",
      "5               p2_pct_final_hp    0.002962\n",
      "6               battle_duration    0.002928\n",
      "7                  hp_diff_mean    0.002713\n",
      "8                     p1_hp_std    0.002313\n",
      "9             p1_type_advantage    0.002007\n",
      "10      p1_bad_status_advantage    0.002001\n",
      "11  mean_base_spe_diff_timeline    0.001965\n",
      "12      nr_pokemon_sconfitti_p1    0.001873\n",
      "13         p1_hp_advantage_mean    0.001866\n",
      "14  net_major_status_infliction    0.001560\n",
      "15  mean_base_spa_diff_timeline    0.001538\n",
      "16           early_hp_mean_diff    0.001512\n",
      "17                    p2_hp_std    0.001470\n",
      "18                     boost_p2    0.001409\n",
      "19       diff_effective_offense    0.001240\n",
      "[Permutation Importance completato in 26.01s]\n",
      "\n",
      "Top-80 feature selezionate:\n",
      "['diff_final_hp', 'hp_loss_rate', 'diff_final_schieramento', 'p2_n_pokemon_use', 'hp_delta_std', 'p2_pct_final_hp', 'battle_duration', 'hp_diff_mean', 'p1_hp_std', 'p1_type_advantage', 'p1_bad_status_advantage', 'mean_base_spe_diff_timeline', 'nr_pokemon_sconfitti_p1', 'p1_hp_advantage_mean', 'net_major_status_infliction', 'mean_base_spa_diff_timeline', 'early_hp_mean_diff', 'p2_hp_std', 'boost_p2', 'diff_effective_offense', 'p1_pct_final_hp', 'diff_hp', 'nr_pokemon_sconfitti_p2', 'status_p1', 'p1_type_weakness', 'priority_diff', 'hp_delta_trend', 'p1_cumulative_major_status_turns_pct', 'p2_move_power_weighted', 'p1_number_status', 'diff_number_status', 'p1_mean_atk', 'diff_spd', 'p1_mean_sp', 'p1_mean_stab', 'nr_pokemon_sconfitti_diff', 'p1_mean_hp', 'std_base_spa_diff_timeline', 'boost_p1', 'p1_move_power_weighted', 'diff_type_advantage', 'diff_turn_first_boost', 'late_hp_mean_diff', 'net_major_status_suffering', 'p2_type_advantage', 'p1_major_status_infliction_rate', 'p1_mean_spe', 'major_status_p2', 'status_p2', 'std_base_atk_diff_timeline', 'diff_atk', 'p2_confusion_freq', 'expected_damage_ratio_turn_1', 'std_base_spe_diff_timeline', 'p2_major_status_infliction_rate', 'diff_spe', 'p2_number_status', 'p2_mean_stab', 'p1_final_hp_per_ko', 'p1_number_attacks', 'p1_mean_def', 'mean_base_atk_diff_timeline', 'p1_team_super_effective_moves', 'p1_reflect_first_turn', 'p1_type_diversity', 'diff_number_attack', 'diff_mean_stab', 'diff_effective_defense', 'p2_status_change', 'p1_avg_high_speed_stat_battaglia', 'diff_def', 'diff_boost_count_turni', 'p1_max_speed_offense_product', 'p1_confusion_first_turn', 'p2_number_attacks', 'p1_max_speed_stat', 'p1_max_offense_boost_diff', 'p2_reflect_freq', 'p1_reflect_freq', 'p2_reflect_first_turn']\n",
      "\n",
      "FASE 2: Retraining con feature selezionate\n",
      "Retraining completato in 0.91s\n",
      "\n",
      "\n",
      "RISULTATI FINALI\n",
      "Training Accuracy: 0.8788\n",
      "Training AUC: 0.9524\n",
      "CV Accuracy: 0.8414 ± 0.0085\n",
      "CV AUC: 0.9134 ± 0.0065\n",
      "Dropped 3 correlated features: ['hp_loss_rate', 'nr_pokemon_sconfitti_p1', 'diff_effective_defense'] (>0.92).\n",
      "\n",
      "Modello finale pronto!\n",
      "featureArray,accuracy_score_training,roc_auc_score,accuracy_cross_val_score,roc_auc_cross_val_score\n",
      "['diff_final_hp', 'diff_final_schieramento', 'p2_n_pokemon_use', 'hp_delta_std', 'p2_pct_final_hp', 'battle_duration', 'hp_diff_mean', 'p1_hp_std', 'p1_type_advantage', 'p1_bad_status_advantage', 'mean_base_spe_diff_timeline', 'p1_hp_advantage_mean', 'net_major_status_infliction', 'mean_base_spa_diff_timeline', 'early_hp_mean_diff', 'p2_hp_std', 'boost_p2', 'diff_effective_offense', 'p1_pct_final_hp', 'diff_hp', 'nr_pokemon_sconfitti_p2', 'status_p1', 'p1_type_weakness', 'priority_diff', 'hp_delta_trend', 'p1_cumulative_major_status_turns_pct', 'p2_move_power_weighted', 'p1_number_status', 'diff_number_status', 'p1_mean_atk', 'diff_spd', 'p1_mean_sp', 'p1_mean_stab', 'nr_pokemon_sconfitti_diff', 'p1_mean_hp', 'std_base_spa_diff_timeline', 'boost_p1', 'p1_move_power_weighted', 'diff_type_advantage', 'diff_turn_first_boost', 'late_hp_mean_diff', 'net_major_status_suffering', 'p2_type_advantage', 'p1_major_status_infliction_rate', 'p1_mean_spe', 'major_status_p2', 'status_p2', 'std_base_atk_diff_timeline', 'diff_atk', 'p2_confusion_freq', 'expected_damage_ratio_turn_1', 'std_base_spe_diff_timeline', 'p2_major_status_infliction_rate', 'diff_spe', 'p2_number_status', 'p2_mean_stab', 'p1_final_hp_per_ko', 'p1_number_attacks', 'p1_mean_def', 'mean_base_atk_diff_timeline', 'p1_team_super_effective_moves', 'p1_reflect_first_turn', 'p1_type_diversity', 'diff_number_attack', 'diff_mean_stab', 'p2_status_change', 'p1_avg_high_speed_stat_battaglia', 'diff_def', 'diff_boost_count_turni', 'p1_max_speed_offense_product', 'p1_confusion_first_turn', 'p2_number_attacks', 'p1_max_speed_stat', 'p1_max_offense_boost_diff', 'p2_reflect_freq', 'p1_reflect_freq', 'p2_reflect_first_turn'],\n",
      "[47sec-77feat]\n",
      "0.8791->0.8418 ± 0.0086, 0.9528929199999999->0.9133 ± 0.0068\n",
      "Generating predictions on the test set...\n",
      "\n",
      "submission.csv file created successfully!\n",
      "Total execution time: 66 seconds\n"
     ]
    }
   ],
   "source": [
    "#BASE\n",
    "middle_time = time.time()\n",
    "VOTING = True#False#True\n",
    "NEW_VOTING = True#False#True\n",
    "BASE = True#False#True\n",
    "FINAL_VOTING = True#False#True\n",
    "LOGISTIC = False#False#True\n",
    "if LOGISTIC:\n",
    "    #provo a usare il voting per la selezione delle feature e poi le passo alla logistic\n",
    "    model, features, importance_table = train_with_feature_selection(\n",
    "        X, y, k=80\n",
    "    )\n",
    "    X_reduced = X[features]\n",
    "    features = correlation_pruning(X_reduced, threshold=0.92)\n",
    "    selected = features\n",
    "    X_selected = X[selected]\n",
    "    final_pipe = train_regularization(X_selected,y)\n",
    "    y_train_pred = final_pipe.predict(X_selected)\n",
    "    y_train_proba = final_pipe.predict_proba(X_selected)[:, 1]\n",
    "    #CHECK OVERFITTING\n",
    "    acc = cross_val_score(final_pipe, X_selected, y, cv=5, scoring=\"accuracy\")\n",
    "    auc = cross_val_score(final_pipe, X_selected, y, cv=5, scoring=\"roc_auc\")\n",
    "    end_time = time.time()\n",
    "    print(\"featureArray,accuracy_score_training,roc_auc_score,accuracy_cross_val_score,roc_auc_cross_val_score\")\n",
    "    print(f\"{[f for f in selected]},\\n[{int(end_time-middle_time)}sec-{len(selected)}feat]\\n{accuracy_score(y, y_train_pred)}->{acc.mean():.4f} ± {acc.std():.4f}, {roc_auc_score(y, y_train_proba)}->{auc.mean():.4f} ± {auc.std():.4f}\")\n",
    "    prefix = str(int(10000*accuracy_score(y, y_train_pred)))+\"_\"+str(int(10000*acc.mean()))\n",
    "    \n",
    "    predict_and_submit(test_df, features, final_pipe, prefix=\"LOGISTIC_FEATU_VOTING_\")\n",
    "elif FINAL_VOTING:\n",
    "    model, features, importance_table = train_with_feature_selection(\n",
    "        X, y, k=80\n",
    "    )\n",
    "    X_reduced = X[features]\n",
    "    \n",
    "    features = correlation_pruning(X_reduced, threshold=0.92)\n",
    "    print(\"\\nModello finale pronto!\")\n",
    "    final(model, \"FINAL_VOTING\")\n",
    "elif NEW_VOTING:\n",
    "    #Logistic Regression (stabile per feature quasi lineari)\n",
    "    lr = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lr\", LogisticRegression(\n",
    "            C=0.5,\n",
    "            penalty=\"l2\",\n",
    "            solver=\"liblinear\",\n",
    "            max_iter=1000,\n",
    "            random_state=1234\n",
    "        ))\n",
    "    ])\n",
    "    #Random Forest (robusto, ottimo su high-dimensional noise)\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=600,\n",
    "        max_depth=6,\n",
    "        max_features=\"sqrt\",\n",
    "        bootstrap=True,\n",
    "        n_jobs=-1,\n",
    "        random_state=1234\n",
    "    )\n",
    "    #XGBoost (il più forte)\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=4,\n",
    "        min_child_weight=1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1.0,\n",
    "        reg_alpha=0.0,\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        tree_method=\"hist\",\n",
    "        random_state=1234,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    #Voting Ensemble\n",
    "    model = VotingClassifier(\n",
    "        estimators=[\n",
    "            (\"xgb\", xgb),\n",
    "            (\"rf\", rf),\n",
    "            (\"lr\", lr)\n",
    "        ],\n",
    "        voting=\"soft\",\n",
    "        weights=[3, 1, 2],   #XGB più forte => peso maggiore\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    final(model, \"\")\n",
    "elif VOTING:\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=1100,\n",
    "        max_depth=5,                #più profondo\n",
    "        min_samples_leaf=2,          #contro overfitting\n",
    "        max_features=0.2,            #più decorrelazione\n",
    "        bootstrap=True,\n",
    "        class_weight=\"balanced\",     #migliora roc_auc\n",
    "        random_state=1234,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    ada = AdaBoostClassifier(\n",
    "        estimator=DecisionTreeClassifier(max_depth=3),\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.5,\n",
    "        random_state=1234\n",
    "    )\n",
    "    gb = GradientBoostingClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=2,\n",
    "        subsample=0.8,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=1234\n",
    "    )\n",
    "    lr = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        #(\"pca\", PCA(n_components=0.95)), #keep 95% variance\n",
    "        (\"lr\", LogisticRegression(\n",
    "            C=1,\n",
    "            max_iter=1000,\n",
    "            solver=\"liblinear\",\n",
    "            #penalty=\"l1\" \n",
    "        ))\n",
    "    ])\n",
    "    model = VotingClassifier(\n",
    "        estimators=[\n",
    "            (\"rf\", rf),\n",
    "            #(\"ada\", ada),\n",
    "            (\"gb\", gb),\n",
    "            (\"lr\", lr)\n",
    "        ],\n",
    "        voting=\"soft\",\n",
    "        weights=[1,1, 2],  #tune on performance\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    #scegli K = 40 (poi provo 30–60)\n",
    "    features, importance_table = select_top_features(gb, X, y, k=90)\n",
    "    #model = rf\n",
    "    #model = gb\n",
    "    #1112 850 918\n",
    "    #2112 850 917\n",
    "    #2113 852 917 rf,ada,gb,lr\n",
    "    #213 tolto gb 847 916 rf,ada,lr\n",
    "    #213 tolto ada 852 917 rf,gb,lr\n",
    "    #113 850 917 rf,gb,lr\n",
    "    #stacked_model = voting_model\n",
    "    final(model, \"\")\n",
    "elif BASE:\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=6,  \n",
    "        random_state=1234,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    gb = GradientBoostingClassifier(\n",
    "        n_estimators=200,      \n",
    "        learning_rate=0.03,\n",
    "        max_depth=3, \n",
    "        random_state=1234\n",
    "    )\n",
    "    model = StackingClassifier(\n",
    "        estimators=[\n",
    "            (\"rf\", rf),         \n",
    "            (\"gb\", gb)          \n",
    "        ],\n",
    "        final_estimator=LogisticRegression(\n",
    "            max_iter=2000, \n",
    "            C=0.05, \n",
    "            random_state=1234\n",
    "        ), \n",
    "        passthrough=False, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    final(model, \"\")\n",
    "else:\n",
    "    rf = RandomForestClassifier(random_state=1234, n_jobs=-1)\n",
    "    gb = GradientBoostingClassifier(random_state=1234)\n",
    "    log_reg = LogisticRegression(random_state=1234, max_iter=2000)\n",
    "   \n",
    "    stacked_model_base = StackingClassifier(\n",
    "        estimators=[(\"rf\", rf), (\"gb\", gb)],\n",
    "        final_estimator=XGBClassifier(random_state=1234, n_estimators=100, learning_rate=0.05),\n",
    "        passthrough=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    param_grid = {\n",
    "        #Random Forest \n",
    "        \"rf__n_estimators\": [100, 300, 500],\n",
    "        \"rf__max_depth\": [None, 5, 10, 20],\n",
    "        \"rf__min_samples_split\": [2, 5, 10],\n",
    "        \"rf__min_samples_leaf\": [1, 2, 4],\n",
    "        \n",
    "        #Gradient Boosting \n",
    "        \"gb__n_estimators\": [100, 200, 300],\n",
    "        \"gb__learning_rate\": [0.01, 0.05, 0.1],\n",
    "        \"gb__max_depth\": [2, 3, 5],\n",
    "        \"gb__subsample\": [0.8, 1.0],\n",
    "        \n",
    "        #XGBoost (meta-model) \n",
    "        \"final_estimator__n_estimators\": [100, 200, 300],\n",
    "        \"final_estimator__learning_rate\": [0.01, 0.05, 0.1],\n",
    "        \"final_estimator__max_depth\": [3, 5, 7],\n",
    "        \"final_estimator__subsample\": [0.8, 1.0],\n",
    "        \"final_estimator__colsample_bytree\": [0.8, 1.0]\n",
    "    }\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "    \n",
    "    model = RandomizedSearchCV(\n",
    "        estimator=stacked_model_base,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=50,  #prova anche con 100?\n",
    "        cv=5,\n",
    "        scoring=\"roc_auc\",\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        random_state=1234\n",
    "    )\n",
    "    final(model, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ea8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fds-kaggle-competition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
