{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeab5c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "import json\n",
    "#train\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "type_chart = {\n",
    "    \"NORMAL\":     {\"ROCK\":0.5, \"GHOST\":0.0, \"STEEL\":0.5},\n",
    "    \"FIRE\":       {\"FIRE\":0.5, \"WATER\":0.5, \"GRASS\":2.0, \"ICE\":2.0, \"BUG\":2.0, \"ROCK\":0.5, \"DRAGON\":0.5, \"STEEL\":2.0},\n",
    "    \"WATER\":      {\"FIRE\":2.0, \"WATER\":0.5, \"GRASS\":0.5, \"GROUND\":2.0, \"ROCK\":2.0, \"DRAGON\":0.5},\n",
    "    \"ELECTRIC\":   {\"WATER\":2.0, \"ELECTRIC\":0.5, \"GRASS\":0.5, \"GROUND\":0.0, \"FLYING\":2.0, \"DRAGON\":0.5},\n",
    "    \"GRASS\":      {\"FIRE\":0.5, \"WATER\":2.0, \"GRASS\":0.5, \"POISON\":0.5, \"GROUND\":2.0, \"FLYING\":0.5, \"BUG\":0.5, \"ROCK\":2.0, \"DRAGON\":0.5, \"STEEL\":0.5},\n",
    "    \"ICE\":        {\"FIRE\":0.5, \"WATER\":0.5, \"GRASS\":2.0, \"ICE\": 0.5, \"GROUND\":2.0, \"FLYING\":2.0, \"DRAGON\":2.0, \"STEEL\":0.5},\n",
    "    \"FIGHTING\":   {\"NORMAL\":2.0, \"ICE\":2.0, \"POISON\":0.5, \"FLYING\":0.5, \"PSYCHIC\":0.5, \"BUG\":0.5, \"ROCK\":2.0, \"GHOST\":0.0, \"DARK\":2.0, \"STEEL\":2.0, \"FAIRY\":0.5},\n",
    "    \"POISON\":     {\"GRASS\":2.0, \"POISON\":0.5, \"GROUND\":0.5, \"ROCK\":0.5, \"GHOST\":0.5, \"STEEL\":0.0, \"FAIRY\":2.0},\n",
    "    \"GROUND\":     {\"FIRE\":2.0, \"ELECTRIC\":2.0, \"GRASS\":0.5, \"POISON\":2.0, \"FLYING\":0.0, \"BUG\":0.5, \"ROCK\":2.0, \"STEEL\":2.0},\n",
    "    \"FLYING\":     {\"ELECTRIC\":0.5, \"GRASS\":2.0, \"FIGHTING\":2.0, \"BUG\":2.0, \"ROCK\":0.5, \"STEEL\":0.5},\n",
    "    \"PSYCHIC\":    {\"FIGHTING\":2.0, \"POISON\":2.0, \"PSYCHIC\":0.5, \"DARK\":0.0, \"STEEL\":0.5},\n",
    "    \"BUG\":        {\"FIRE\":0.5, \"GRASS\":2.0, \"FIGHTING\":0.5, \"POISON\":0.5, \"FLYING\":0.5, \"PSYCHIC\":2.0, \"GHOST\":0.5, \"DARK\":2.0, \"STEEL\":0.5, \"FAIRY\":0.5},\n",
    "    \"ROCK\":       {\"FIRE\":2.0, \"ICE\":2.0, \"FIGHTING\":0.5, \"GROUND\":0.5, \"FLYING\":2.0, \"BUG\":2.0, \"STEEL\":0.5},\n",
    "    \"GHOST\":      {\"NORMAL\":0.0, \"PSYCHIC\":2.0, \"GHOST\":2.0, \"DARK\":0.5},\n",
    "    \"DRAGON\":     {\"DRAGON\":2.0, \"STEEL\":0.5, \"FAIRY\":0.0},\n",
    "    \"DARK\":       {\"FIGHTING\":0.5, \"PSYCHIC\":2.0, \"GHOST\":2.0, \"DARK\": 0.5, \"FAIRY\":0.5},\n",
    "    \"STEEL\":      {\"FIRE\":0.5, \"WATER\":0.5, \"ELECTRIC\":0.5, \"ICE\":2.0, \"ROCK\":2.0, \"STEEL\":0.5, \"FAIRY\":2.0},\n",
    "    \"FAIRY\":      {\"FIRE\":0.5, \"FIGHTING\":2.0, \"POISON\":0.5, \"DRAGON\":2.0, \"DARK\":2.0, \"STEEL\":0.5}\n",
    "}\n",
    "def read_train_data(train_file_path):\n",
    "    train_data = []\n",
    "    # Read the file line by line\n",
    "    try:\n",
    "        with open(train_file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                # json.loads() parses one line (one JSON object) into a Python dictionary\n",
    "                train_data.append(json.loads(line))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Could not find the training file at '{train_file_path}'.\")\n",
    "        print(\"Please make sure you have added the competition data to this notebook.\")\n",
    "    finally:\n",
    "        return train_data\n",
    "\n",
    "def read_test_data(test_file_path):\n",
    "    test_data = []\n",
    "    with open(test_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            test_data.append(json.loads(line))\n",
    "    return test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa8257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "COMPETITION_NAME = 'fds-pokemon-battles-prediction-2025'\n",
    "DATA_PATH = os.path.join('input', COMPETITION_NAME)\n",
    "\n",
    "train_file_path = os.path.join(DATA_PATH, 'train.jsonl')\n",
    "test_file_path = os.path.join(DATA_PATH, 'test.jsonl')\n",
    "\n",
    "train_data = read_train_data(train_file_path)\n",
    "test_data = read_test_data(test_file_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d144339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'conteggio_livelli_diversi_totale_nel_dataset': 3, 'livelli_unici_trovati': [55, 85, 100]}\n",
      "2\n",
      "{'conteggio_livelli_diversi_totale_nel_dataset': 3, 'livelli_unici_trovati': [25, 55, 100]}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "# def get_move_type_counts(df: pd.DataFrame) -> dict:\n",
    "#     \"\"\"\n",
    "#     Analyzes the 'battle_timeline(30)' column in the DataFrame to count the \n",
    "#     occurrences of each move type used.\n",
    "#     \"\"\"\n",
    "#     BATTLE_TIMELINE_COL = \"battle_timeline\"#(30)\n",
    "#     all_move_types = Counter()\n",
    "    \n",
    "#     # Iterate over the list of turns (timeline) in each row of the correct column\n",
    "#     for timeline in df[BATTLE_TIMELINE_COL]:\n",
    "#         if timeline is None:\n",
    "#             continue\n",
    "#         for turn in timeline:\n",
    "#             # --- Check for P1's move details (Corrected for NoneType) ---\n",
    "#             if 'p1_move_details' in turn:\n",
    "#                 details = turn['p1_move_details']\n",
    "#                 if details is not None and 'type' in details:\n",
    "#                     all_move_types[details['type']] += 1\n",
    "            \n",
    "#             # --- Check for P2's move details (Corrected for NoneType) ---\n",
    "#             if 'p2_move_details' in turn:\n",
    "#                 details = turn['p2_move_details']\n",
    "#                 if details is not None and 'type' in details:\n",
    "#                     all_move_types[details['type']] += 1\n",
    "#     return dict(all_move_types)\n",
    "\n",
    "# # Execute the function\n",
    "# move_counts_train = get_move_type_counts(pd.DataFrame(train_data))\n",
    "# #print(f\"Move Type Counts:\\n{move_counts_train}\")\n",
    "# move_counts_test= get_move_type_counts(pd.DataFrame(test_data))\n",
    "# #print(f\"Move Type Counts:\\n{move_counts_test}\")\n",
    "\n",
    "# # Assuming you have loaded your test data correctly:\n",
    "# # move_counts_test = get_move_type_counts(pd.DataFrame(test_data)) \n",
    "\n",
    "# # Create sets of unique move types (keys)\n",
    "# train_moves = set(move_counts_train.keys())\n",
    "# test_moves = set(move_counts_test.keys())\n",
    "\n",
    "# # --- Analysis ---\n",
    "\n",
    "# # 1. Moves unique to the Training Set\n",
    "# unique_to_train = train_moves - test_moves\n",
    "# print(\"Moves unique to Training Set (not in Test):\")\n",
    "# print(unique_to_train)\n",
    "\n",
    "# # 2. Moves unique to the Testing Set\n",
    "# unique_to_test = test_moves - train_moves\n",
    "# print(\"\\nMoves unique to Testing Set (not in Train):\")\n",
    "# print(unique_to_test)\n",
    "\n",
    "# # 3. Common Moves\n",
    "# common_moves = train_moves.intersection(test_moves)\n",
    "# print(\"\\nMoves common to both sets:\")\n",
    "# print(common_moves)\n",
    "\n",
    "# # 4. Check for *Any* difference\n",
    "# if unique_to_train or unique_to_test:\n",
    "#     print(f\"\\nDIFFERENCE FOUND: The move sets are NOT identical.\")\n",
    "# else:\n",
    "#     print(f\"\\nNO DIFFERENCE FOUND: The unique move sets are identical.\")\n",
    "    \n",
    "    \n",
    "# chart_types = set(type_chart.keys())\n",
    "\n",
    "# # 3. Find move types that are in the training data but not in the chart\n",
    "# missing_in_chart = train_moves - chart_types\n",
    "\n",
    "# print(f\"Total Unique Move Types in Training Data: {len(train_moves)}\")\n",
    "# print(f\"Total Unique Types in type_chart: {len(chart_types)}\")\n",
    "# print(\"-\" * 50)\n",
    "\n",
    "# if missing_in_chart:\n",
    "#     print(f\"Moves in Training Data NOT defined in type_chart:\")\n",
    "#     print(f\"{list(missing_in_chart)}\")\n",
    "# else:\n",
    "#     print(\"All move types in the training data are defined as keys in type_chart.\")\n",
    "    \n",
    "\n",
    "#STATUS COUNT\n",
    "\n",
    "\n",
    "# def get_status_counts(df: pd.DataFrame) -> dict:\n",
    "#     \"\"\"\n",
    "#     Analyzes the 'battle_timeline(30)' column in the DataFrame to count the \n",
    "#     occurrences of each status condition reported at the start of a turn.\n",
    "    \n",
    "#     Status is found in: turn['p1_pokemon_state|p2_pokemon_state']['status']\n",
    "#     The format is 'p1_status|p2_status'.\n",
    "#     \"\"\"\n",
    "#     BATTLE_TIMELINE_COL = \"battle_timeline\"\n",
    "#     all_statuses = Counter()\n",
    "#     # Iterate over the list of turns (timeline) in each row of the correct column\n",
    "#     for timeline in df[BATTLE_TIMELINE_COL]:\n",
    "#         if timeline is None:\n",
    "#             continue\n",
    "#         for turn in timeline:\n",
    "            \n",
    "#             # Check if the state details are present\n",
    "#             if 'p1_pokemon_state' in turn:\n",
    "#                 state_details = turn['p1_pokemon_state']\n",
    "#                 if state_details is not None and 'status' in state_details:\n",
    "#                     status_string = state_details['status']\n",
    "#                     if status_string != 'nostatus':\n",
    "#                         all_statuses[status_string] += 1\n",
    "#             if 'p2_pokemon_state' in turn:\n",
    "#                 state_details = turn['p2_pokemon_state']\n",
    "#                 if state_details is not None and 'status' in state_details:\n",
    "#                     status_string = state_details['status']\n",
    "#                     if status_string != 'nostatus':\n",
    "#                         all_statuses[status_string] += 1\n",
    "                        \n",
    "#     return dict(all_statuses)\n",
    "\n",
    "# # --- Execution Example (Assuming train_data and test_data are defined) ---\n",
    "# # NOTE: This part requires the actual data to run and get results.\n",
    "\n",
    "# # Execute the function for training data\n",
    "# status_counts_train = get_status_counts(pd.DataFrame(train_data))\n",
    "# print(f\"Train Status Counts:\\n{status_counts_train}\")\n",
    "\n",
    "# # Execute the function for testing data\n",
    "# status_counts_test = get_status_counts(pd.DataFrame(test_data))\n",
    "# print(f\"\\nTest Status Counts:\\n{status_counts_test}\")\n",
    "\n",
    "# # --- Comparison Analysis ---\n",
    "# train_statuses = set(status_counts_train.keys())\n",
    "# test_statuses = set(status_counts_test.keys())\n",
    "\n",
    "# print(\"-\" * 50)\n",
    "# print(f\"Total Unique Statuses in Training Data: {len(train_statuses)}\")\n",
    "# print(f\"Total Unique Statuses in Testing Data: {len(test_statuses)}\")\n",
    "# print(\"-\" * 50)\n",
    "\n",
    "# # Statuses common to both sets\n",
    "# common_statuses = train_statuses.intersection(test_statuses)\n",
    "# print(\"Statuses common to both sets:\")\n",
    "# print(common_statuses)\n",
    "\n",
    "# # Check for *Any* difference\n",
    "# unique_to_train = train_statuses - test_statuses\n",
    "# unique_to_test = test_statuses - train_statuses\n",
    "\n",
    "# if unique_to_train or unique_to_test:\n",
    "#     print(f\"\\nDIFFERENCE FOUND: The unique status sets are NOT identical.\")\n",
    "#     if unique_to_train:\n",
    "#         print(f\"  - Unique to Train: {unique_to_train}\")\n",
    "#     if unique_to_test:\n",
    "#         print(f\"  - Unique to Test: {unique_to_test}\")\n",
    "# else:\n",
    "#     print(f\"\\nNO DIFFERENCE FOUND: The unique status sets are identical.\")\n",
    "\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any, Counter\n",
    "\n",
    "# # La funzione per contare i livelli diversi in una singola battaglia\n",
    "# def conta_livelli_diversi(battle_data: dict) -> dict:\n",
    "#     \"\"\"\n",
    "#     Conta i turni in cui il livello del primo Pokémon di P1 è diverso da P2.\n",
    "#     Restituisce un dizionario con i livelli e il conteggio.\n",
    "\n",
    "#     Args:\n",
    "#         battle_data: Un dizionario contenente \"p1_team_details\", \"p2_lead_details\"\n",
    "#                      e \"battle_timeline\".\n",
    "\n",
    "#     Returns:\n",
    "#         Un dizionario con \"livellop1\", \"livellop2\" e \"conteggio\".\n",
    "#     \"\"\"\n",
    "#     # Usa le chiavi corrette che appaiono nei tuoi dati\n",
    "#     P1_DETAILS_KEY = \"p1_team_details\"\n",
    "#     P2_DETAILS_KEY = \"p2_lead_details\"\n",
    "#     TIMELINE_KEY = \"battle_timeline\" # O la chiave corretta per la timeline\n",
    "\n",
    "#     try:\n",
    "#         # Estrae il livello del primo Pokémon di P1 (è una lista, prendiamo il primo elemento [0])\n",
    "#         livello_p1 = battle_data[P1_DETAILS_KEY][0][\"level\"]\n",
    "        \n",
    "#         # Estrae il livello del Pokémon in campo di P2\n",
    "#         livello_p2 = battle_data[P2_DETAILS_KEY][\"level\"]\n",
    "        \n",
    "#         # Estrae la timeline per contare i turni totali\n",
    "#         conteggio = 0\n",
    "#         # La differenza di livello è costante, quindi la condizione è fissa.\n",
    "#         if livello_p1 != livello_p2:\n",
    "#             print(livello_p1,livello_p2)\n",
    "#             conteggio=1\n",
    "        \n",
    "\n",
    "#     except (KeyError, IndexError, TypeError) as e:\n",
    "#         # Gestisce i casi in cui i dati sono mancanti o con formato errato\n",
    "#         print(f\"Errore di accesso ai dati in una battaglia: {e}. Restituito conteggio 0.\")\n",
    "#         return {\n",
    "#             \"livellop1\": None,\n",
    "#             \"livellop2\": None,\n",
    "#             \"conteggio\": 0\n",
    "#         }\n",
    "\n",
    "#     # Restituisce il dizionario richiesto\n",
    "#     return {\n",
    "#         \"livellop1\": livello_p1,\n",
    "#         \"livellop2\": livello_p2,\n",
    "#         \"conteggio\": conteggio\n",
    "#     }\n",
    "\n",
    "# # --- Funzione per aggregare i conteggi su tutte le battaglie (DataFrame) ---\n",
    "\n",
    "# def conta_livelli_diversi_totale(df: pd.DataFrame) -> dict:\n",
    "#     \"\"\"\n",
    "#     Applica la logica di conteggio dei livelli diversi a tutte le battaglie\n",
    "#     in un DataFrame e restituisce il conteggio totale aggregato.\n",
    "\n",
    "#     Args:\n",
    "#         df: Un DataFrame dove ogni riga rappresenta una battaglia\n",
    "#             e contiene le colonne necessarie.\n",
    "\n",
    "#     Returns:\n",
    "#         Un dizionario con il conteggio totale e il conteggio separato per\n",
    "#         i livelli di P1 e P2 (solo se i livelli sono fissi nel dataset).\n",
    "#         Altrimenti, restituisce solo il conteggio totale.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Inizializza il contatore totale\n",
    "#     conteggio_totale_turni_diversi = 0\n",
    "    \n",
    "#     # Inizializza i set per tracciare i livelli unici (per informazioni aggiuntive)\n",
    "#     livelli_p1_unici = set()\n",
    "#     livelli_p2_unici = set()\n",
    "\n",
    "#     # Itera su tutte le righe del DataFrame\n",
    "#     for _, battle_data in df.iterrows():\n",
    "#         # Converte la Serie in un dizionario per l'uso nella funzione\n",
    "#         battle_dict = battle_data.to_dict()\n",
    "        \n",
    "#         # Applica la funzione alla singola battaglia\n",
    "#         risultato = conta_livelli_diversi(battle_dict)\n",
    "        \n",
    "#         # Aggiorna il conteggio totale\n",
    "#         conteggio_totale_turni_diversi += risultato[\"conteggio\"]\n",
    "        \n",
    "#         # Traccia i livelli per l'output informativo (se presenti)\n",
    "#         if risultato[\"livellop1\"] is not None:\n",
    "#             livelli_p1_unici.add(risultato[\"livellop1\"])\n",
    "#         if risultato[\"livellop2\"] is not None:\n",
    "#             livelli_p2_unici.add(risultato[\"livellop2\"])\n",
    "            \n",
    "#     # Prepara il risultato finale\n",
    "#     risultato_finale = {\n",
    "#         \"conteggio_totale_turni_livelli_diversi\": conteggio_totale_turni_diversi\n",
    "#     }\n",
    "    \n",
    "#     # Aggiunge informazioni sui livelli (se rilevanti)\n",
    "#     if len(livelli_p1_unici) == 1 and len(livelli_p2_unici) <= 1:\n",
    "#         risultato_finale[\"livello_p1_fisso\"] = next(iter(livelli_p1_unici), None)\n",
    "#         risultato_finale[\"livello_p2_fisso\"] = next(iter(livelli_p2_unici), None)\n",
    "#     else:\n",
    "#         # Se i livelli sono variabili, lo si indica\n",
    "#         risultato_finale[\"livelli_p1_unici_trovati\"] = sorted(list(livelli_p1_unici))\n",
    "#         risultato_finale[\"livelli_p2_unici_trovati\"] = sorted(list(livelli_p2_unici))\n",
    "        \n",
    "#     return risultato_finale\n",
    "\n",
    "# # --- Esempio di Utilizzo con un DataFrame Fittizio ---\n",
    "# # Nota: Creerò un DataFrame con due battaglie per dimostrazione.\n",
    "\n",
    "# # Dati di esempio per la riga 1 (Livelli Diversi: 100 vs 50)\n",
    "\n",
    "\n",
    "# # Conteggio Totale\n",
    "# risultato_aggregato = conta_livelli_diversi_totale(pd.DataFrame(train_data))\n",
    "\n",
    "# print(risultato_aggregato)\n",
    "\n",
    "# risultato_aggregato = conta_livelli_diversi_totale(pd.DataFrame(test_data))\n",
    "\n",
    "# print(risultato_aggregato)\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# def conta_livelli_team1(battle_data: dict) -> dict:\n",
    "#     # Questa funzione rimane invariata per estrarre i livelli unici di una singola battaglia\n",
    "#     P1_DETAILS_KEY = \"p1_team_details\"\n",
    "    \n",
    "#     livelli_team1 = []\n",
    "#     livelli_unici_team1 = set()\n",
    "\n",
    "#     try:\n",
    "#         for pokemon_details in battle_data.get(P1_DETAILS_KEY, []):\n",
    "#             if \"level\" in pokemon_details:\n",
    "#                 livello = pokemon_details[\"level\"]\n",
    "#                 livelli_team1.append(livello)\n",
    "#                 livelli_unici_team1.add(livello)\n",
    "                \n",
    "#     except (TypeError, KeyError, IndexError) as e:\n",
    "#         # È buona pratica non stampare messaggi di errore in cicli se non strettamente necessario\n",
    "#         return {\n",
    "#             \"livelli_team1\": [],\n",
    "#             \"livelli_unici_team1\": set() # Restituisce un set vuoto in caso di errore\n",
    "#         }\n",
    "#     if(len(livelli_unici_team1) >1):\n",
    "#         print(len(livelli_unici_team1))\n",
    "#     return {\n",
    "#         \"livelli_team1\": livelli_team1,\n",
    "#         \"livelli_unici_team1\": livelli_unici_team1 # Restituiamo il set di livelli unici\n",
    "#     }\n",
    "\n",
    "# def conta_livelli_diversi_totale_team1_globale(df: pd.DataFrame) -> dict:\n",
    "#     \"\"\"\n",
    "#     Calcola il numero totale di valori di livello diversi (es. {50, 100, 75})\n",
    "#     utilizzati dal Team 1 in tutte le battaglie del DataFrame.\n",
    "\n",
    "#     Args:\n",
    "#         df: Un DataFrame dove ogni riga rappresenta una battaglia.\n",
    "\n",
    "#     Returns:\n",
    "#         Un dizionario contenente il conteggio totale dei livelli unici.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Inizializza un set globale per tracciare TUTTI i livelli unici\n",
    "#     livelli_unici_globali = set()\n",
    "    \n",
    "#     # Itera su tutte le righe del DataFrame\n",
    "#     for _, battle_data in df.iterrows():\n",
    "#         battle_dict = battle_data.to_dict()\n",
    "        \n",
    "#         # Applica la funzione alla singola battaglia\n",
    "#         risultato = conta_livelli_team1(battle_dict)\n",
    "        \n",
    "#         # Aggiorna il set globale con i livelli unici trovati in questa battaglia\n",
    "#         livelli_unici_globali.update(risultato[\"livelli_unici_team1\"])\n",
    "            \n",
    "#     # Prepara il risultato finale\n",
    "#     risultato_finale = {\n",
    "#         \"conteggio_livelli_diversi_totale_nel_dataset\": len(livelli_unici_globali),\n",
    "#         \"livelli_unici_trovati\": sorted(list(livelli_unici_globali))\n",
    "#     }\n",
    "        \n",
    "#     return risultato_finale\n",
    "\n",
    "# # Esempio di applicazione (Assumendo che train_data sia disponibile)\n",
    "# # risultato_aggregato_globale = conta_livelli_diversi_totale_team1_globale(pd.DataFrame(train_data))\n",
    "# # print(risultato_aggregato_globale)\n",
    "    \n",
    "# risultato_aggregato = conta_livelli_diversi_totale_team1_globale(pd.DataFrame(train_data))\n",
    "\n",
    "# print(risultato_aggregato)\n",
    "\n",
    "# risultato_aggregato = conta_livelli_diversi_totale_team1_globale(pd.DataFrame(test_data))\n",
    "\n",
    "# print(risultato_aggregato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e14c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_type_advantage_over_timeline(timeline, pokemon_dict, type_chart, is_test=False, battle_id=''):\n",
    "    if not timeline:\n",
    "        return {\n",
    "            \"p1_type_advantage\": 1.0,\n",
    "            \"p2_type_advantage\": 1.0,\n",
    "            \"diff_type_advantage\": 0.0\n",
    "        }\n",
    "\n",
    "    p1_advantages = []\n",
    "    p2_advantages = []\n",
    "    for turn in timeline:\n",
    "        p1_name = turn.get(\"p1_pokemon_state\", {}).get(\"name\")\n",
    "        p2_name = turn.get(\"p2_pokemon_state\", {}).get(\"name\")\n",
    "\n",
    "        if not p1_name or not p2_name:\n",
    "            continue\n",
    "\n",
    "        # Get types from dictionary\n",
    "        p1_types = pokemon_dict.get(p1_name.lower(), [])\n",
    "        p2_types = pokemon_dict.get(p2_name.lower(), [])\n",
    "        #print(len(p1_types),len(p2_types))\n",
    "        if not p1_types or not p2_types:\n",
    "            continue\n",
    "        # --- P1 attacking P2 ---\n",
    "        p1_mult = []\n",
    "        for atk_type in p1_types:\n",
    "            mult = 1.0\n",
    "            for def_type in p2_types:\n",
    "                mult *= type_chart.get(atk_type.upper(), {}).get(def_type.upper(), 1.0)\n",
    "            p1_mult.append(mult)\n",
    "        #turn summary\n",
    "        p1_adv = np.mean(p1_mult) if p1_mult else 1.0\n",
    "\n",
    "        # --- P2 attacking P1 ---\n",
    "        p2_mult = []\n",
    "        for atk_type in p2_types:\n",
    "            mult = 1.0\n",
    "            for def_type in p1_types:\n",
    "                mult *= type_chart.get(atk_type.upper(), {}).get(def_type.upper(), 1.0)\n",
    "            p2_mult.append(mult)\n",
    "        #turn summary\n",
    "        p2_adv = np.mean(p2_mult) if p2_mult else 1.0\n",
    "\n",
    "        p1_advantages.append(p1_adv)\n",
    "        p2_advantages.append(p2_adv)\n",
    "\n",
    "    if not p1_advantages or not p2_advantages:\n",
    "        return {\n",
    "            \"p1_type_advantage\": 1.0,\n",
    "            \"p2_type_advantage\": 1.0,\n",
    "            \"diff_type_advantage\": 0.0\n",
    "        }\n",
    "\n",
    "    #timeline summary\n",
    "    p1_avg = np.mean(p1_advantages)\n",
    "    p2_avg = np.mean(p2_advantages)\n",
    "    # if is_test and battle_id == 109:\n",
    "    #     print(f\"first team:{debug_dict_p1}, second team:{debug_dict_p2}\")\n",
    "    #     #,p1_avg,p2_avg,p1_avg - p2_avg\n",
    "    #     exit()\n",
    "    return {\n",
    "        \"p1_type_advantage\": p1_avg,\n",
    "        \"p2_type_advantage\": p2_avg,\n",
    "        \"diff_type_advantage\": p1_avg - p2_avg\n",
    "    }\n",
    "\n",
    "def compute_avg_offensive_potential(timeline, pokemon_dict, type_chart, is_test=False, battle_id=''):\n",
    "    # ... (initial checks are the same)\n",
    "    if not timeline:\n",
    "        return {\n",
    "            \"p1_type_advantage\": 1.0,\n",
    "            \"p2_type_advantage\": 1.0,\n",
    "            \"diff_type_advantage\": 0.0\n",
    "        }\n",
    "\n",
    "    p1_advantages = []\n",
    "    p2_advantages = []\n",
    "    \n",
    "    # Get all possible move types from the type chart keys\n",
    "    all_move_types = list(type_chart.keys())\n",
    "\n",
    "    for turn in timeline:\n",
    "        # ... (get names and types, same as before)\n",
    "        p1_name = turn.get(\"p1_pokemon_state\", {}).get(\"name\")\n",
    "        p2_name = turn.get(\"p2_pokemon_state\", {}).get(\"name\")\n",
    "\n",
    "        if not p1_name or not p2_name:\n",
    "            continue\n",
    "\n",
    "        p1_types = pokemon_dict.get(p1_name.lower(), [])\n",
    "        p2_types = pokemon_dict.get(p2_name.lower(), [])\n",
    "\n",
    "        if not p1_types or not p2_types:\n",
    "            continue\n",
    "        # --- P1 attacking P2: Calculate average effectiveness of ALL move types ---\n",
    "        p1_mult = []\n",
    "        for atk_type in all_move_types: # <-- **CHANGE**: Iterate over ALL possible move types\n",
    "            mult = 1.0\n",
    "            for def_type in p2_types:\n",
    "                mult *= type_chart.get(atk_type.upper(), {}).get(def_type.upper(), 1.0)\n",
    "            p1_mult.append(mult)\n",
    "        # turn summary\n",
    "        p1_adv = np.mean(p1_mult) if p1_mult else 1.0\n",
    "\n",
    "        # --- P2 attacking P1: Calculate average effectiveness of ALL move types ---\n",
    "        p2_mult = []\n",
    "        for atk_type in all_move_types: # <-- **CHANGE**: Iterate over ALL possible move types\n",
    "            mult = 1.0\n",
    "            for def_type in p1_types:\n",
    "                mult *= type_chart.get(atk_type.upper(), {}).get(def_type.upper(), 1.0)\n",
    "            p2_mult.append(mult)\n",
    "        # turn summary\n",
    "        p2_adv = np.mean(p2_mult) if p2_mult else 1.0\n",
    "\n",
    "        p1_advantages.append(p1_adv)\n",
    "        p2_advantages.append(p2_adv)\n",
    "\n",
    "    # ... (final calculation and return are the same)\n",
    "    if not p1_advantages or not p2_advantages:\n",
    "        return {\n",
    "            \"p1_type_advantage\": 1.0,\n",
    "            \"p2_type_advantage\": 1.0,\n",
    "            \"diff_type_advantage\": 0.0\n",
    "        }\n",
    "\n",
    "    p1_avg = np.mean(p1_advantages)\n",
    "    p2_avg = np.mean(p2_advantages)\n",
    "    \n",
    "    return {\n",
    "        \"p1_type_advantage\": p1_avg,\n",
    "        \"p2_type_advantage\": p2_avg,\n",
    "        \"diff_type_advantage\": p1_avg - p2_avg\n",
    "    }\n",
    "    \n",
    "def conta_status_anomali(timeline):\n",
    "    \"\"\"\n",
    "    Conta il numero di volte in cui i Pokémon di P1 e P2 hanno subito uno stato\n",
    "    diverso da 'nostatus' in ogni turno della battaglia.\n",
    "\n",
    "    Args:\n",
    "        dati_battaglia (dict): Il dizionario contenente la struttura dei dati della battaglia.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un dizionario con i conteggi totali per p1, p2 e la loro differenza.\n",
    "    \"\"\"\n",
    "    conteggio_p1 = 0\n",
    "    conteggio_p2 = 0\n",
    "\n",
    "    for turno in timeline:\n",
    "        # Assumiamo che la chiave contenga lo stato del Pokémon nel formato\n",
    "        # \"p1_pokemon_state|p2_pokemon_state\" e che lo stato sia la seconda parte dopo la virgola.\n",
    "        # È fondamentale sapere esattamente come sono formattati i dati.\n",
    "\n",
    "        # Ipotizzando che la chiave sia presente e il suo valore sia un dizionario:\n",
    "        stato_dettagli = turno.get(\"p1_pokemon_state\", {})\n",
    "        # Estraiamo la stringa dello stato\n",
    "        # Esempio: \"name\": \"starmie\", \"hp_pct\": 1.0, \"status\": \"'nostatus'|'slp', 'frz', 'brn', ...\n",
    "        status_string = stato_dettagli.get(\"status\", \"\")\n",
    "        if status_string:\n",
    "            # La stringa è formattata come \"stato_p1|stato_p2\". La dividiamo.\n",
    "            if status_string.lower() != 'nostatus':\n",
    "                conteggio_p1 += 1\n",
    "                \n",
    "        stato_dettagli = turno.get(\"p2_pokemon_state\", {})\n",
    "        status_string = stato_dettagli.get(\"status\", \"\")\n",
    "        if status_string:\n",
    "            # La stringa è formattata come \"stato_p1|stato_p2\". La dividiamo.\n",
    "            if status_string.lower() != 'nostatus':\n",
    "                conteggio_p2 += 1\n",
    "\n",
    "\n",
    "    differenza = conteggio_p1 - conteggio_p2 # P1 meno P2\n",
    "\n",
    "    return {\n",
    "        \"status_p1\": conteggio_p1,\n",
    "        \"status_p2\": conteggio_p2,\n",
    "        \"diff_status\": differenza\n",
    "    }\n",
    "    \n",
    "def get_p1_base_speed(pokemon_name, p1_team_details):\n",
    "    search_name = pokemon_name.lower().strip()\n",
    "    for pokemon in p1_team_details:\n",
    "        if pokemon.get(\"name\", \"\").lower().strip() == search_name:\n",
    "            return pokemon.get(\"base_spe\", 0)\n",
    "    return 0    \n",
    "\n",
    "def calculate_battle_stats(battle):\n",
    "    \"\"\"\n",
    "    Calcola tre feature basate sui dettagli della squadra e della timeline della battaglia:\n",
    "    1. diff_speed_first: Differenza di velocità tra i leader.\n",
    "    2. diff_speed_timeline: Differenza di velocità media tra i Pokémon in campo in ogni turno.\n",
    "    3. diff_stat: Differenza media tra le statistiche base rilevanti del Team 1\n",
    "                  (media di tutti i 6 Pokémon) e le statistiche base rilevanti del Lead del Team 2.\n",
    "\n",
    "    Args:\n",
    "        data (dict): Dizionario contenente i dettagli della battaglia.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dizionario con le tre feature calcolate.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1. diff_speed_first: Differenza di velocità tra i leader ---\n",
    "\n",
    "    # Leader P1: p1_team_details[0]\n",
    "    p1_lead_spe = battle[\"p1_team_details\"][0][\"base_spe\"]\n",
    "    # Leader P2: p2_lead_details\n",
    "    p2_lead_spe = battle[\"p2_lead_details\"][\"base_spe\"]\n",
    "\n",
    "    diff_speed_first = p1_lead_spe - p2_lead_spe\n",
    "\n",
    "    # --- 2. diff_speed_timeline: Differenza di velocità media nella timeline ---\n",
    "\n",
    "    timeline_speeds_diffs = []\n",
    "    \n",
    "    p1_team_details = battle.get(\"p1_team_details\", [])\n",
    "    p2_lead_details = battle.get(\"p2_lead_details\", {})\n",
    "    p2_lead_name = p2_lead_details.get(\"name\", \"\").lower().strip()\n",
    "    p2_base_spe = p2_lead_details.get(\"base_spe\", 0)\n",
    "    \n",
    "    # Itera attraverso la timeline\n",
    "    for turn in battle.get(\"battle_timeline\", []):\n",
    "        \n",
    "        # Stato Pokémon P1\n",
    "        # Assumiamo che il nome sia in 'p1_pokemon_state|p2_pokemon_state' o simili\n",
    "        p1_state_data = turn.get(\"p1_pokemon_state\")\n",
    "        \n",
    "        p1_name = p1_state_data.get(\"name\", \"\") if p1_state_data else \"\"\n",
    "        \n",
    "        # Stato Pokémon P2 (assumiamo lo stesso per semplicità o cerchiamo una chiave separata)\n",
    "        p2_state_data = turn.get(\"p2_pokemon_state\")\n",
    "        \n",
    "        p2_name = p2_state_data.get(\"name\", \"\") if p2_state_data else \"\"\n",
    "\n",
    "        # Recupera la velocità base di P1\n",
    "        p1_speed = get_p1_base_speed(p1_name, p1_team_details)\n",
    "        \n",
    "        # Recupera la velocità base di P2.\n",
    "        # Usa base_spe da p2_lead_details solo se il nome in campo corrisponde al lead P2.\n",
    "        # Altrimenti, per P2, non abbiamo dati nel JSON fornito per altri Pokémon del team.\n",
    "        p2_speed = 0\n",
    "        if p2_name.lower().strip() == p2_lead_name:\n",
    "            p2_speed = p2_base_spe\n",
    "        # Se P2 non ha il lead in campo (se il JSON fosse completo), il dato non sarebbe disponibile con i vincoli dati.\n",
    "        \n",
    "        # Calcola e aggiungi la differenza (P1 - P2)\n",
    "        if p1_speed != 0 or p2_speed != 0:\n",
    "            timeline_speeds_diffs.append(p1_speed - p2_speed)\n",
    "\n",
    "    # Calcola la media delle differenze di velocità\n",
    "    if timeline_speeds_diffs:\n",
    "        diff_speed_timeline = np.mean(timeline_speeds_diffs)\n",
    "    else:\n",
    "        # Se la timeline è vuota o non si trovano dati validi, usa la differenza del lead\n",
    "        diff_speed_timeline = diff_speed_first\n",
    "\n",
    "\n",
    "    # --- 3. diff_stat: Differenza media delle statistiche rilevanti ---\n",
    "\n",
    "    # Statistiche base da considerare\n",
    "    stats_keys = [\"base_hp\", \"base_atk\", \"base_def\", \"base_spa\", \"base_spd\", \"base_spe\"]\n",
    "\n",
    "    # Calcolo della media delle statistiche per il Team 1 (6 Pokémon)\n",
    "    p1_stats_sums = {key: 0 for key in stats_keys}\n",
    "    \n",
    "    for pokemon in battle[\"p1_team_details\"]:\n",
    "        for key in stats_keys:\n",
    "            p1_stats_sums[key] += pokemon[key]\n",
    "    \n",
    "    #lead p1\n",
    "    sum_stat_lead_p1 = 0\n",
    "    sum_stat_lead_p2 = 0\n",
    "    for key in stats_keys:\n",
    "        sum_stat_lead_p1 += battle[\"p1_team_details\"][0][key]\n",
    "        sum_stat_lead_p2 += battle[\"p2_lead_details\"][key]\n",
    "        \n",
    "    num_p1_pokemon = len(battle[\"p1_team_details\"])\n",
    "    p1_avg_stats = {key: p1_stats_sums[key] / num_p1_pokemon for key in stats_keys}\n",
    "\n",
    "    # Statistiche del Lead del Team 2\n",
    "    p2_lead_stats = {key: battle[\"p2_lead_details\"][key] for key in stats_keys}\n",
    "\n",
    "    # Calcolo della differenza media delle statistiche\n",
    "    # Differenza: Media(Team 1) - Statistiche(Lead Team 2)\n",
    "    stat_diffs = []\n",
    "    for key in stats_keys:\n",
    "        diff = p1_avg_stats[key] - p2_lead_stats[key]\n",
    "        stat_diffs.append(diff)\n",
    "\n",
    "    # La feature è la media di queste 6 differenze di statistica\n",
    "    diff_stat = np.mean(stat_diffs) if stat_diffs else 0\n",
    "\n",
    "\n",
    "    # --- Ritorno dei risultati ---\n",
    "    return {\n",
    "        \"diff_speed_first\": diff_speed_first,\n",
    "        \"diff_speed_timeline\": diff_speed_timeline,\n",
    "        \"diff_stat\": diff_stat,\n",
    "        \n",
    "        #non ancora usate\n",
    "        \"sum_stat_lead_p1\": sum_stat_lead_p1,\n",
    "        \"sum_stat_lead_p2\": sum_stat_lead_p2,\n",
    "        \"diff_stat_lead\": sum_stat_lead_p1 - sum_stat_lead_p2\n",
    "    }\n",
    "\n",
    "def extract_hp_features(battle):\n",
    "    \"\"\"\n",
    "    Calcola tre feature basate sui dati di battaglia:\n",
    "    1. p1_hp_pct_sum: Somma del massimo hp_pct per i Pokémon distinti del Team 1.\n",
    "    2. p2_hp_pct_sum: Somma del massimo hp_pct per i Pokémon distinti del Team 2.\n",
    "    3. diff_hp_pct: Differenza (p1_hp_pct_sum - p2_hp_pct_sum).\n",
    "\n",
    "    Args:\n",
    "        battle_data (dict): Dizionario contenente i dettagli della battaglia.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un dizionario con le tre feature calcolate.\n",
    "    \"\"\"\n",
    "\n",
    "    # Dizionari per tenere traccia del massimo hp_pct raggiunto da ciascun Pokémon distinto\n",
    "    # La chiave è il nome del Pokémon, il valore è il massimo hp_pct visto.\n",
    "    p1_set_hp_pct = {}\n",
    "    p2_set_hp_pct = {}\n",
    "\n",
    "    timeline = battle.get(\"battle_timeline\", [])\n",
    "    # 2. Scorre la timeline della battaglia\n",
    "    for turn in timeline:#\n",
    "        # Estrai lo stato del Pokémon 1\n",
    "        p1_pokemon_state = turn.get(\"p1_pokemon_state\", None)\n",
    "        if p1_pokemon_state:\n",
    "            p1_name = p1_pokemon_state.get(\"name\")\n",
    "            p1_hp_pct = p1_pokemon_state.get(\"hp_pct\")\n",
    "            p1_set_hp_pct[p1_name] = p1_hp_pct\n",
    "\n",
    "        # Estrai lo stato del Pokémon 2\n",
    "        p2_pokemon_state = turn.get(\"p2_pokemon_state\", None)\n",
    "        if p2_pokemon_state:\n",
    "            p2_name = p2_pokemon_state.get(\"name\")\n",
    "            p2_hp_pct = p2_pokemon_state.get(\"hp_pct\")\n",
    "            p2_set_hp_pct[p2_name] = p2_hp_pct\n",
    "\n",
    "    team_member_count =  len(battle.get('p1_team_details'))-len(p1_set_hp_pct.keys())\n",
    "    p1_hp_pct_sum = sum(p1_set_hp_pct.values()) + (team_member_count-len(p1_set_hp_pct.keys()))\n",
    "\n",
    "    p2_hp_pct_sum = sum(p2_set_hp_pct.values()) + (team_member_count-len(p2_set_hp_pct.keys()))\n",
    "\n",
    "    diff_hp_pct = p1_hp_pct_sum - p2_hp_pct_sum\n",
    "    #print(p1_hp_pct_sum,p2_hp_pct_sum,diff_hp_pct)\n",
    "    return {\n",
    "        \"p1_hp_pct_sum\": p1_hp_pct_sum,\n",
    "        \"p2_hp_pct_sum\": p2_hp_pct_sum,\n",
    "        \"diff_hp_pct\": diff_hp_pct\n",
    "    }\n",
    "\n",
    "#MOVES\n",
    "def create_move_features(timeline):\n",
    "    \n",
    "    # Mappa per la codifica numerica della categoria\n",
    "    category_map = {\n",
    "        \"PHYSICAL\": 1,\n",
    "        \"SPECIAL\": 2,\n",
    "        \"STATUS\": 0\n",
    "    }\n",
    "    \n",
    "    # Lista per contenere i dati della timeline con le nuove feature\n",
    "    extended_timeline = []\n",
    "    p1_move_power_weighted = []\n",
    "    p1_number_attacks = 0\n",
    "    p1_number_status = 0\n",
    "    \n",
    "    p1_sum_negative_priority = 0\n",
    "    p2_sum_negative_priority = 0\n",
    "    \n",
    "    \n",
    "    p2_move_power_weighted = []\n",
    "    p2_number_attacks = 0\n",
    "    p2_number_status = 0\n",
    "    for turn in timeline:\n",
    "        # Assumiamo che la mossa sia sotto 'p1_move_details|p2_move_details'\n",
    "        move_details_key = \"p1_move_details\"#|p2_move_details\n",
    "        if turn.get(move_details_key) != None:\n",
    "            move = turn[move_details_key]\n",
    "            \n",
    "            # 1. Feature: move_power_weighted\n",
    "            # Un 'danno atteso' che combina potenza e accuratezza\n",
    "            accuracy = move.get(\"accuracy\", 1.0) # Default a 1.0 se mancante\n",
    "            base_power = move.get(\"base_power\", 0)\n",
    "            priority = move.get(\"priority\", 0)\n",
    "            # Se la precisione è 0, assumiamo che sia una mossa a 100% di precisione \n",
    "            # se non è specificato (come \"noaccuracy\"), altrimenti usiamo il valore fornito.\n",
    "            if accuracy == 0:\n",
    "                 weighted_power = base_power\n",
    "            else:\n",
    "                weighted_power = base_power * accuracy\n",
    "            \n",
    "            p1_move_power_weighted.append(round(weighted_power, 3))\n",
    "\n",
    "            # 2. Feature: is_physical_or_special\n",
    "            # Codifica della categoria di attacco (1 per attacco, 0 per status)\n",
    "            category = move.get(\"category\", \"STATUS\").upper()\n",
    "            if category in [\"PHYSICAL\", \"SPECIAL\"]:\n",
    "                p1_number_attacks+=1\n",
    "            elif category == \"STATUS\":\n",
    "                p1_number_status+=1\n",
    "                \n",
    "            if(priority == -1):\n",
    "                p1_sum_negative_priority +=1\n",
    "        move_details_key = \"p2_move_details\"#|p2_move_details\n",
    "        if turn.get(move_details_key) != None:\n",
    "            move = turn[move_details_key]\n",
    "            \n",
    "            # 1. Feature: move_power_weighted\n",
    "            # Un 'danno atteso' che combina potenza e accuratezza\n",
    "            accuracy = move.get(\"accuracy\", 1.0) # Default a 1.0 se mancante\n",
    "            base_power = move.get(\"base_power\", 0)\n",
    "            priority = move.get(\"priority\", 0)\n",
    "            # Se la precisione è 0, assumiamo che sia una mossa a 100% di precisione \n",
    "            # se non è specificato (come \"noaccuracy\"), altrimenti usiamo il valore fornito.\n",
    "            if accuracy == 0:\n",
    "                 weighted_power = base_power\n",
    "            else:\n",
    "                weighted_power = base_power * accuracy\n",
    "            \n",
    "            p2_move_power_weighted.append(round(weighted_power, 3))\n",
    "\n",
    "            # 2. Feature: is_physical_or_special\n",
    "            # Codifica della categoria di attacco (1 per attacco, 0 per status)\n",
    "            category = move.get(\"category\", \"STATUS\").upper()\n",
    "            if category in [\"PHYSICAL\", \"SPECIAL\"]:\n",
    "                p2_number_attacks+=1\n",
    "            elif category == \"STATUS\":\n",
    "                p2_number_status+=1\n",
    "                \n",
    "            if(priority == -1):\n",
    "                p2_sum_negative_priority +=1\n",
    "            \n",
    "    return {\n",
    "        \"p1_move_power_weighted\": np.sum(p1_move_power_weighted),\n",
    "        \"p1_number_attacks\": p1_number_attacks,\n",
    "        \"p1_number_status\": p1_number_status,\n",
    "        \n",
    "        \"p2_move_power_weighted\": np.sum(p2_move_power_weighted),\n",
    "        \"p2_number_attacks\": p2_number_attacks,\n",
    "        \"p2_number_status\": p2_number_status,\n",
    "        \n",
    "        #non ancora usate\n",
    "        \"diff_number_attack\": p1_number_attacks - p2_number_attacks,\n",
    "        \"diff_number_status\": p1_number_status - p2_number_status,\n",
    "        \n",
    "        \"p1_sum_negative_priority\": p1_sum_negative_priority,\n",
    "        \"p2_sum_negative_priority\": p2_sum_negative_priority,\n",
    "        \"diff_negative_priority\": p1_sum_negative_priority-p2_sum_negative_priority,\n",
    "        \n",
    "    }\n",
    "\n",
    "def calcola_feature_boost(timeline):\n",
    "    totale_boost_p1 = 0\n",
    "    totale_boost_p2 = 0\n",
    "    for turno in timeline:\n",
    "        # Funzione helper per calcolare la somma dei boost di un singolo Pokémon\n",
    "        def somma_boosts(pokemon_state):\n",
    "            somma = 0\n",
    "            if pokemon_state and \"boosts\" in pokemon_state:\n",
    "                # Somma tutti i valori di boost (atk, def, spa, spd, spe)\n",
    "                somma = sum(pokemon_state[\"boosts\"].values())\n",
    "            return somma\n",
    "\n",
    "        # Prova ad accedere allo stato del P1 (presumendo che sia una chiave nel JSON)\n",
    "        if \"p1_pokemon_state\" in turno:\n",
    "            boost_corrente_p1 = somma_boosts(turno[\"p1_pokemon_state\"])\n",
    "            totale_boost_p1 += boost_corrente_p1\n",
    "\n",
    "        # Prova ad accedere allo stato del P2 (presumendo che sia una chiave nel JSON)\n",
    "        if \"p2_pokemon_state\" in turno:\n",
    "            boost_corrente_p2 = somma_boosts(turno[\"p2_pokemon_state\"])\n",
    "            totale_boost_p2 += boost_corrente_p2\n",
    "\n",
    "    # Calcola la differenza\n",
    "    diff_boost = totale_boost_p1 - totale_boost_p2\n",
    "\n",
    "    # Restituisce le feature\n",
    "    return {\n",
    "        \"boost_p1\": totale_boost_p1,\n",
    "        \"boost_p2\": totale_boost_p2,\n",
    "        \"diff_boost\": diff_boost\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c779c793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0301860bc3a145e5b77605e76e8fc0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Output: {'p1_hp_pct_sum': 2.0, 'p2_hp_pct_sum': 1.9, 'diff_hp_pct': 0.1}\n",
    "def create_features(data: list[dict], is_test=False) -> pd.DataFrame:\n",
    "    feature_list = []\n",
    "    pokemon_dict = {}\n",
    "    for battle in data:\n",
    "        p1_team = battle.get('p1_team_details', [])\n",
    "        for p in p1_team:\n",
    "            name = p.get(\"name\")\n",
    "            types = [t for t in p.get(\"types\", []) if t != \"notype\"]\n",
    "            if name:\n",
    "                if name not in pokemon_dict:\n",
    "                    pokemon_dict[name] = set()\n",
    "                pokemon_dict[name].update(types)\n",
    "        p2_lead = battle.get('p2_lead_details')\n",
    "        if p2_lead:\n",
    "            name = p2_lead.get(\"name\")\n",
    "            types = [t for t in p2_lead.get(\"types\", []) if t != \"notype\"]\n",
    "            if name:\n",
    "                if name not in pokemon_dict:\n",
    "                    pokemon_dict[name] = set()\n",
    "                pokemon_dict[name].update(types)\n",
    "    #features\n",
    "    for battle in tqdm(data, desc=\"Extracting features\"):\n",
    "        battle_id = battle.get(\"battle_id\")\n",
    "        features = {}\n",
    "        \n",
    "        features['battle_id'] = battle_id\n",
    "        if 'player_won' in battle:\n",
    "            features['player_won'] = int(battle['player_won'])\n",
    "\n",
    "        battle_stats_results = calculate_battle_stats(battle)\n",
    "        features['diff_speed_first'] = battle_stats_results['diff_speed_first']\n",
    "        features['diff_speed_timeline'] = battle_stats_results['diff_speed_timeline']\n",
    "        features['diff_stat'] = battle_stats_results['diff_stat']\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        #non ancora usate sum e diff stat lead\n",
    "        features['sum_stat_lead_p1'] = battle_stats_results['sum_stat_lead_p1']\n",
    "        features['sum_stat_lead_p2'] = battle_stats_results['sum_stat_lead_p2']\n",
    "        features['diff_stat_lead'] = battle_stats_results['diff_stat_lead']\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        hp_result = extract_hp_features(battle)\n",
    "        features['p1_hp_pct_sum'] = hp_result['p1_hp_pct_sum']\n",
    "        features['p2_hp_pct_sum'] = hp_result['p2_hp_pct_sum']\n",
    "        features['diff_hp_pct'] = hp_result['diff_hp_pct']\n",
    "        timeline = battle.get('battle_timeline', [])\n",
    "        if timeline:\n",
    "            #result = compute_avg_type_advantage_over_timeline(timeline, pokemon_dict, type_chart, is_test, battle_id)\n",
    "            off_potential_result = compute_avg_offensive_potential(timeline, pokemon_dict, type_chart, is_test, battle_id)\n",
    "            #CHECK 84.40% (+/- 1.12%) =>  84.35% (+/- 1.01%)\n",
    "            features['p1_type_advantage'] = off_potential_result['p1_type_advantage']\n",
    "            features['p2_type_advantage'] = off_potential_result['p2_type_advantage']\n",
    "            features['diff_type_advantage'] = off_potential_result['diff_type_advantage']\n",
    "            \n",
    "            status_anomali_result = conta_status_anomali(timeline)\n",
    "            features['status_p1'] = status_anomali_result['status_p1']\n",
    "            features['status_p2'] = status_anomali_result['status_p2']\n",
    "            features['diff_status'] = status_anomali_result['diff_status']\n",
    "            \n",
    "            moves_result = create_move_features(timeline)\n",
    "            features['p1_move_power_weighted'] = moves_result['p1_move_power_weighted']\n",
    "            features['p1_number_attacks'] = moves_result['p1_number_attacks']\n",
    "            features['p1_number_status'] = moves_result['p1_number_status']\n",
    "            \n",
    "            features['p2_move_power_weighted'] = moves_result['p2_move_power_weighted']\n",
    "            features['p2_number_attacks'] = moves_result['p2_number_attacks']\n",
    "            features['p2_number_status'] = moves_result['p2_number_status']\n",
    "            \n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            #non ancora usate priority\n",
    "            features['diff_number_attack'] = moves_result['diff_number_attack']\n",
    "            features['diff_number_status'] = moves_result['diff_number_status']\n",
    "            features['p1_sum_negative_priority'] = moves_result['p1_sum_negative_priority']\n",
    "            features['p2_sum_negative_priority'] = moves_result['p2_sum_negative_priority']\n",
    "            features['diff_negative_priority'] = moves_result['diff_negative_priority']\n",
    "            \"\"\"\n",
    "            \"\"\"\n",
    "            #boost\n",
    "            boost_result = calcola_feature_boost(timeline)\n",
    "            features['boost_p1'] = boost_result['boost_p1']\n",
    "            features['boost_p2'] = boost_result['boost_p2']\n",
    "            features['diff_boost'] = boost_result['diff_boost']\n",
    "            \n",
    "        feature_list.append(features)\n",
    "    return pd.DataFrame(feature_list).fillna(0)\n",
    "train_df = create_features(train_data)\n",
    "#\"\"\"\n",
    "features = [col for col in train_df.columns if col not in ['battle_id', 'player_won']]\n",
    "X = train_df[features]\n",
    "y = train_df['player_won']\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5e658aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sum_stat_lead_p1  sum_stat_lead_p2  diff_stat_lead\n",
      "8145               540               435             105\n",
      "1196               535               540              -5\n",
      "2617               435               555            -120\n",
      "2249               540               580             -40\n",
      "3956               540               535               5\n",
      "3882               435               435               0\n",
      "9304               540               540               0\n",
      "7287               535               555             -20\n",
      "876                555               435             120\n",
      "4764               535               540              -5\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "#'p1_sum_positive_priority','p2_sum_positive_priority',   sempre 0\n",
    "seed = random.randint(0, 10_000)\n",
    "n_samples=10\n",
    "#print(X.head(10))\n",
    "#print(X.describe)\n",
    "\n",
    "# print(X[['diff_number_attack', 'diff_number_status', 'diff_positive_priority', 'diff_negative_priority']].head(10))\n",
    "# print(X[['diff_number_attack', 'diff_number_status', 'diff_positive_priority', 'diff_negative_priority']].describe)\n",
    "\n",
    "#print(X[['p1_sum_negative_priority', 'p2_sum_negative_priority']].sample(n=n_samples, random_state=seed))\n",
    "#print(X[['p1_sum_positive_priority', 'p1_sum_negative_priority', 'p2_sum_positive_priority', 'p2_sum_negative_priority']].describe)\n",
    "\n",
    "print(X[['sum_stat_lead_p1','sum_stat_lead_p2','diff_stat_lead']].sample(n=n_samples, random_state=seed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "485fc09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np # Importa numpy per gli intervalli di parametri\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#BASE\n",
    "BASE = True#False#True\n",
    "if BASE:\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=6,  \n",
    "        random_state=1234,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    gb = GradientBoostingClassifier(\n",
    "        n_estimators=200,      \n",
    "        learning_rate=0.03,\n",
    "        max_depth=3, \n",
    "        random_state=1234\n",
    "    )\n",
    "\n",
    "    stacked_model = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', rf),         \n",
    "            ('gb', gb)          \n",
    "        ],\n",
    "        final_estimator=LogisticRegression(\n",
    "            max_iter=2000, \n",
    "            C=0.05, \n",
    "            random_state=1234\n",
    "        ), \n",
    "        passthrough=False, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "else:\n",
    "\n",
    "\n",
    "\n",
    "    # 1. Definizione degli stimatori di base con valori di default o iniziali\n",
    "    rf = RandomForestClassifier(random_state=1234, n_jobs=-1)\n",
    "    gb = GradientBoostingClassifier(random_state=1234)\n",
    "    log_reg = LogisticRegression(random_state=1234, max_iter=2000)\n",
    "\n",
    "    # 2. Definizione del modello Stacking\n",
    "    # stacked_model_base = StackingClassifier(\n",
    "    #     estimators=[\n",
    "    #         ('rf', rf),         \n",
    "    #         ('gb', gb)          \n",
    "    #     ],\n",
    "    #     final_estimator=log_reg, \n",
    "    #     passthrough=False, \n",
    "    #     n_jobs=-1\n",
    "    # )\n",
    "\n",
    "    stacked_model_base = StackingClassifier(\n",
    "        estimators=[('rf', rf), ('gb', gb)],\n",
    "        final_estimator=XGBClassifier(random_state=1234, n_estimators=100, learning_rate=0.05),\n",
    "        passthrough=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    # 3. Definizione della griglia di iperparametri per la ricerca\n",
    "    # param_grid = {\n",
    "    #     # Parametri per il Random Forest (rf)\n",
    "    #     'rf__n_estimators': [100, 200],  # Ridotti per una ricerca più veloce\n",
    "    #     'rf__max_depth': [4, 6],         # Valori di profondità da testare\n",
    "        \n",
    "    #     # Parametri per il Gradient Boosting (gb)\n",
    "    #     'gb__n_estimators': [100, 150],\n",
    "    #     'gb__learning_rate': [0.01, 0.05],\n",
    "        \n",
    "    #     # Parametri per il meta-stimatore (final_estimator) che è LogisticRegression\n",
    "    #     'final_estimator__C': np.logspace(-4, -2, 3), # Esempio: [0.0001, 0.001, 0.01]\n",
    "    #     'final_estimator__solver': ['liblinear']\n",
    "    # }\n",
    "    param_grid = {\n",
    "        # --- Random Forest ---\n",
    "        'rf__n_estimators': [100, 300, 500],\n",
    "        'rf__max_depth': [None, 5, 10, 20],\n",
    "        'rf__min_samples_split': [2, 5, 10],\n",
    "        'rf__min_samples_leaf': [1, 2, 4],\n",
    "        \n",
    "        # --- Gradient Boosting ---\n",
    "        'gb__n_estimators': [100, 200, 300],\n",
    "        'gb__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'gb__max_depth': [2, 3, 5],\n",
    "        'gb__subsample': [0.8, 1.0],\n",
    "        \n",
    "        # --- XGBoost (meta-model) ---\n",
    "        'final_estimator__n_estimators': [100, 200, 300],\n",
    "        'final_estimator__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'final_estimator__max_depth': [3, 5, 7],\n",
    "        'final_estimator__subsample': [0.8, 1.0],\n",
    "        'final_estimator__colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    # 4. Inizializzazione di GridSearchCV\n",
    "    # stacked_model = GridSearchCV(\n",
    "    #     estimator=stacked_model_base,\n",
    "    #     param_grid=param_grid,\n",
    "    #     cv=3,                 \n",
    "    #     scoring='accuracy',   \n",
    "    #     verbose=2,            # Aumenta il dettaglio dell'output\n",
    "    #     n_jobs=-1             # Usa tutti i core\n",
    "    # )\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "    \"\"\"\n",
    "    Fitting 5 folds for each of 629856 candidates, totalling 3149280 fits\n",
    "    \"\"\"\n",
    "    # stacked_model = GridSearchCV(\n",
    "    #     estimator=stacked_model_base,\n",
    "    #     param_grid=param_grid,\n",
    "    #     cv=cv,\n",
    "    #     scoring='roc_auc',\n",
    "    #     n_jobs=-1,\n",
    "    #     verbose=2\n",
    "    # )\n",
    "\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "    stacked_model = RandomizedSearchCV(\n",
    "        estimator=stacked_model_base,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=50,  #prova anche con 100?\n",
    "        cv=5,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        random_state=1234\n",
    "    )\n",
    "\n",
    "import itertools\n",
    "\n",
    "def get_power_set_non_empty_as_list(array):\n",
    "  n = len(array)\n",
    "  combinations_iterators = (\n",
    "      itertools.combinations(array, k) for k in range(1, n + 1)\n",
    "  )\n",
    "  non_empty_subsets_tuples = itertools.chain.from_iterable(combinations_iterators)\n",
    "  non_empty_subsets_lists = [\n",
    "      list(subset_tuple) for subset_tuple in non_empty_subsets_tuples\n",
    "  ]\n",
    "  \n",
    "  return non_empty_subsets_lists\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15f04d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be5778a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featureArray,accuracy_score_training,roc_auc_score,accuracy_cross_val_score,roc_auc_cross_val_score\n",
      "['diff_speed_first', 'diff_speed_timeline', 'diff_stat', 'sum_stat_lead_p1', 'sum_stat_lead_p2', 'diff_stat_lead', 'p1_hp_pct_sum', 'p2_hp_pct_sum', 'diff_hp_pct', 'p1_type_advantage', 'p2_type_advantage', 'diff_type_advantage', 'status_p1', 'status_p2', 'diff_status', 'p1_move_power_weighted', 'p1_number_attacks', 'p1_number_status', 'p2_move_power_weighted', 'p2_number_attacks', 'p2_number_status', 'diff_number_attack', 'diff_number_status', 'p1_sum_negative_priority', 'p2_sum_negative_priority', 'diff_negative_priority', 'boost_p1', 'boost_p2', 'diff_boost'],0.8357, 0.91219104, 0.8240 ± 0.0139, 0.8954 ± 0.0096\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "featureArray,accuracy_score_training,roc_auc_score,accuracy_cross_val_score,roc_auc_cross_val_score\n",
    "['diff_type_advantage', 'p1_type_advantage', 'diff_status', 'diff_speed_first', 'diff_stat', 'p2_hp_pct_sum', 'diff_hp_pct', 'p1_number_attacks', 'p1_number_status'],0.832, 0.90755308, 0.8209 ± 0.0141, 0.8928 ± 0.0090\n",
    "['diff_type_advantage', 'p1_type_advantage', 'diff_status', 'diff_speed_first', 'diff_stat', 'p2_hp_pct_sum', 'diff_hp_pct', 'p1_number_attacks', 'p1_number_status', 'boost_p1', 'boost_p2', 'diff_boost'],0.832, 0.90715636, 0.8210 ± 0.0131, 0.8926 ± 0.0091\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "1. base model, base features\n",
    "featureArray,accuracy_score_training,roc_auc_score,accuracy_cross_val_score,roc_auc_cross_val_score\n",
    "['diff_type_advantage', 'p1_type_advantage', 'diff_status', 'diff_speed_first', 'diff_stat', 'p2_hp_pct_sum', 'diff_hp_pct', 'p1_number_attacks', 'p1_number_status', 'boost_p1', 'boost_p2', 'diff_boost'],0.832, 0.90715636, 0.8210 ± 0.0131, 0.8926 ± 0.0091\n",
    "\n",
    "2. new model, base features\n",
    "featureArray,accuracy_score_training,roc_auc_score,accuracy_cross_val_score,roc_auc_cross_val_score\n",
    "['diff_type_advantage', 'p1_type_advantage', 'diff_status', 'diff_speed_first', 'diff_stat', 'p2_hp_pct_sum', 'diff_hp_pct', 'p1_number_attacks', 'p1_number_status', 'boost_p1', 'boost_p2', 'diff_boost'],0.8303, 0.90590852, 0.8198 ± 0.0143, 0.8914 ± 0.0104\n",
    "\n",
    "3. base model, new features\n",
    "featureArray,accuracy_score_training,roc_auc_score,accuracy_cross_val_score,roc_auc_cross_val_score\n",
    "['diff_type_advantage', 'p1_type_advantage', 'diff_status', 'diff_speed_first', 'diff_stat', 'p2_hp_pct_sum', 'diff_hp_pct', 'p1_number_attacks', 'p1_number_status', 'p2_sum_negative_priority', 'p1_move_power_weighted', 'boost_p1', 'boost_p2', 'diff_boost', 'sum_stat_lead_p1', 'sum_stat_lead_p2'],0.832, 0.90853532, 0.8206 ± 0.0138, 0.8927 ± 0.0091\n",
    "\n",
    "4. advanced model, base features\n",
    "featureArray,accuracy_score_training,roc_auc_score,accuracy_cross_val_score,roc_auc_cross_val_score\n",
    "['diff_type_advantage', 'p1_type_advantage', 'diff_status', 'diff_speed_first', 'diff_stat', 'p2_hp_pct_sum', 'diff_hp_pct', 'p1_number_attacks', 'p1_number_status', 'boost_p1', 'boost_p2', 'diff_boost'],0.8668, 0.92523774, 0.8215 ± 0.0132, 0.8928 ± 0.0087\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "featureArray,accuracy_score_training,roc_auc_score,accuracy_cross_val_score,roc_auc_cross_val_score\n",
    "['p1_move_power_weighted'],0.5968, 0.6324084600000001, 0.5616 ± 0.0042, 0.5915 ± 0.0081\n",
    "['p1_sum_negative_priority'],0.516, 0.5163315200000002, 0.5096 ± 0.0091, 0.5087 ± 0.0093\n",
    "['p2_sum_negative_priority'],0.5187, 0.5192220200000001, 0.5182 ± 0.0045, 0.5183 ± 0.0046\n",
    "['p1_move_power_weighted'],0.5968, 0.6324084600000001, 0.5616 ± 0.0042, 0.5915 ± 0.0081\n",
    "['p1_sum_negative_priority', 'p2_sum_negative_priority'],0.52, 0.53486568, 0.5182 ± 0.0043, 0.5309 ± 0.0105\n",
    "['p1_sum_negative_priority', 'p1_move_power_weighted'],0.5921, 0.6349669, 0.5686 ± 0.0090, 0.5959 ± 0.0073\n",
    "['p2_sum_negative_priority', 'p1_move_power_weighted'],0.5914, 0.6366776399999999, 0.5720 ± 0.0051, 0.6007 ± 0.0071\n",
    "['p1_sum_negative_priority', 'p2_sum_negative_priority', 'p1_move_power_weighted'],0.597, 0.64039074, 0.5732 ± 0.0072, 0.6054 ± 0.0075\n",
    "\n",
    "\n",
    "featureArray,accuracy_score_training,roc_auc_score,accuracy_cross_val_score,roc_auc_cross_val_score\n",
    "['sum_stat_lead_p1'],0.5374, 0.54829176, 0.5360 ± 0.0093, 0.5421 ± 0.0139\n",
    "['sum_stat_lead_p2'],0.5286, 0.5358371399999999, 0.5270 ± 0.0105, 0.5230 ± 0.0144\n",
    "['diff_stat_lead'],0.526, 0.542862, 0.5070 ± 0.0065, 0.5190 ± 0.0107\n",
    "['sum_stat_lead_p1', 'sum_stat_lead_p2'],0.5502, 0.5792500599999999, 0.5389 ± 0.0113, 0.5613 ± 0.0128\n",
    "['sum_stat_lead_p1', 'diff_stat_lead'],0.5489, 0.57557634, 0.5342 ± 0.0113, 0.5571 ± 0.0119\n",
    "['sum_stat_lead_p2', 'diff_stat_lead'],0.5496, 0.57714694, 0.5374 ± 0.0133, 0.5581 ± 0.0131\n",
    "['sum_stat_lead_p1', 'sum_stat_lead_p2', 'diff_stat_lead'],0.5511, 0.57960366, 0.5357 ± 0.0128, 0.5616 ± 0.0129\n",
    "\"\"\"\n",
    "def final():\n",
    "    \n",
    "#     sample_features = [\n",
    "                \n",
    "# # print(X[['diff_number_attack', 'diff_number_status', 'diff_positive_priority', 'diff_negative_priority']].head(10))\n",
    "# # print(X[['diff_number_attack', 'diff_number_status', 'diff_positive_priority', 'diff_negative_priority',\n",
    "# #'p1_sum_negative_priority', 'p2_sum_negative_priority', 'p1_move_power_weighted'\n",
    "# 'sum_stat_lead_p1','sum_stat_lead_p2','diff_stat_lead'\n",
    "#             ]\n",
    "#     power_set = get_power_set_non_empty_as_list(sample_features)\n",
    "#     print(\"featureArray,accuracy_score_training,roc_auc_score,accuracy_cross_val_score,roc_auc_cross_val_score\")\n",
    "#     for selected in power_set:\n",
    "#         #print(selected)\n",
    "#         X_selected = X[selected]\n",
    "#         stacked_model.fit(X_selected, y)\n",
    "#         final_pipe = stacked_model\n",
    "#         #EVALUATE\n",
    "\n",
    "#         y_train_pred = final_pipe.predict(X_selected)\n",
    "#         y_train_proba = final_pipe.predict_proba(X_selected)[:, 1]\n",
    "\n",
    "#         #CHECK OVERFITTING\n",
    "#         acc = cross_val_score(final_pipe, X_selected, y, cv=5, scoring='accuracy')\n",
    "#         auc = cross_val_score(final_pipe, X_selected, y, cv=5, scoring='roc_auc')\n",
    "#         print(f\"{[f for f in selected]},{accuracy_score(y, y_train_pred)}, {roc_auc_score(y, y_train_proba)}, {acc.mean():.4f} ± {acc.std():.4f}, {auc.mean():.4f} ± {auc.std():.4f}\")\n",
    "\n",
    "#     #     #predict_and_submit(test_df, selected, final_pipe)\n",
    "        \n",
    "\n",
    "#     return\n",
    "    #diff_status',#minor overfitting\n",
    "    final_features = [\n",
    "                'diff_type_advantage', 'p1_type_advantage', \n",
    "                'diff_status',\n",
    "                'diff_speed_first', 'diff_stat',\n",
    "                'p2_hp_pct_sum', 'diff_hp_pct',\n",
    "                'p1_number_attacks', 'p1_number_status',\n",
    "                'p2_sum_negative_priority', 'p1_move_power_weighted',#\n",
    "                'boost_p1', 'boost_p2', 'diff_boost',#14\n",
    "                'sum_stat_lead_p1', 'sum_stat_lead_p2',#16\n",
    "            ]\n",
    "    selected = features\n",
    "    #print(f\"Definite {len(features)} features totali\")\n",
    "    #return\n",
    "    #print(selected)\n",
    "\n",
    "    X_selected = X[selected]\n",
    "    stacked_model.fit(X_selected, y)\n",
    "    final_pipe = stacked_model\n",
    "    #EVALUATE\n",
    "\n",
    "    y_train_pred = final_pipe.predict(X_selected)\n",
    "    y_train_proba = final_pipe.predict_proba(X_selected)[:, 1]\n",
    "\n",
    "    #CHECK OVERFITTING\n",
    "    acc = cross_val_score(final_pipe, X_selected, y, cv=5, scoring='accuracy')\n",
    "    auc = cross_val_score(final_pipe, X_selected, y, cv=5, scoring='roc_auc')\n",
    "    print(\"featureArray,accuracy_score_training,roc_auc_score,accuracy_cross_val_score,roc_auc_cross_val_score\")\n",
    "    print(f\"{[f for f in selected]},{accuracy_score(y, y_train_pred)}, {roc_auc_score(y, y_train_proba)}, {acc.mean():.4f} ± {acc.std():.4f}, {auc.mean():.4f} ± {auc.std():.4f}\")\n",
    "\n",
    "    #predict_and_submit(test_df, selected, final_pipe)\n",
    "final()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396409ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fds-kaggle-competition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
