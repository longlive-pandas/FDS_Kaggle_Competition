{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eeba489",
   "metadata": {},
   "source": [
    "Greadsearching su un gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26498de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os\\nimport time\\nimport pandas as pd\\nimport numpy as np\\nimport json\\nfrom tqdm import tqdm\\nfrom typing import List, Dict \\n\\n# --- Importazioni dal tuo file di utility ---\\n# Assicurati che \\'start_utils.py\\' sia nella stessa cartella\\nfrom start_utils import create_features, read_train_data, read_test_data\\n\\n# --- Importazioni per il Modello Avanzato ---\\nfrom sklearn.ensemble import GradientBoostingClassifier\\nfrom sklearn.model_selection import StratifiedKFold, GridSearchCV\\nfrom sklearn.metrics import accuracy_score\\nimport warnings\\n\\ndef main():\\n    # Ignora i warning per un output pi√π pulito\\n    warnings.simplefilter(action=\\'ignore\\', category=FutureWarning)\\n\\n    # === 1. CARICAMENTO DATI ===\\n    print(\"--- 1. Caricamento Dati ---\")\\n    COMPETITION_NAME = \\'fds-pokemon-battles-prediction-2025\\'\\n    # Modifica il percorso se \\'input\\' non √® nella stessa cartella di \\'start.py\\'\\n    DATA_PATH = \\'input\\' \\n\\n    train_file_path = os.path.join(DATA_PATH, COMPETITION_NAME, \\'train.jsonl\\')\\n    test_file_path = os.path.join(DATA_PATH, COMPETITION_NAME, \\'test.jsonl\\')\\n\\n    try:\\n        train_data = read_train_data(train_file_path)\\n        test_data = read_test_data(test_file_path)\\n        print(f\"Dati di training caricati: {len(train_data)} battaglie.\")\\n        print(f\"Dati di test caricati: {len(test_data)} battaglie.\")\\n    except FileNotFoundError:\\n        print(f\"ERRORE: Dati non trovati. Assicurati che la cartella \\'{DATA_PATH}/{COMPETITION_NAME}\\' esista.\")\\n        return\\n\\n    # === 2. CREAZIONE FEATURE ===\\n    print(\"\\n--- 2. Creazione Feature (Feature Engineering) ---\")\\n\\n    print(\"Processing training data...\")\\n    train_df = create_features(train_data)\\n\\n    print(\"\\nProcessing test data...\")\\n    test_df = create_features(test_data, is_test=True)\\n\\n    # === 3. SELEZIONE FEATURE (Il set vincente!) ===\\n    print(\"\\n--- 3. Selezione Feature (Pre-Training) ---\")\\n\\n    # Questa √® la lista di feature che ha dato i risultati migliori (96.31%)\\n    # Derivata dalla nostra analisi di importanza precedente.\\n    TOP_FEATURES = [\\n        \\'status_change_diff\\',\\n        \\'diff_final_schieramento\\',\\n        \\'diff_final_hp\\',\\n        \\'p1_bad_status_advantage\\',\\n        \\'p1_pct_final_hp\\',\\n        \\'p2_n_pokemon_use\\',\\n        \\'p2_hp_std\\',\\n        \\'diff_hp\\',\\n        \\'p1_hp_std\\',\\n        \\'hp_delta_std\\'\\n        # Aggiungi qui altre feature che erano nel tuo \\'TOP_FEATURES\\' se diverse\\n    ]\\n\\n    # Aggiungiamo le nuove feature di danno che abbiamo integrato\\n    TOP_FEATURES.extend([\\'diff_move_damage_mean\\', \\'diff_move_damage_max\\'])\\n\\n    # Rimuoviamo duplicati se ce ne sono\\n    TOP_FEATURES = sorted(list(set(TOP_FEATURES))) \\n\\n    print(f\"Utilizzo di {len(TOP_FEATURES)} feature selezionate.\")\\n\\n    TARGET = \\'player_won\\'\\n\\n    # Creiamo i set di dati X/y usando SOLO le feature migliori\\n    X = train_df[TOP_FEATURES]\\n    y = train_df[TARGET]\\n\\n    # Prepariamo il set di test\\n    X_test = test_df[TOP_FEATURES]\\n\\n    # === 4. OTTIMIZZAZIONE MODELLO (Grid Search) ===\\n    print(\"\\n--- 4. Ottimizzazione Modello (Grid Search) ---\")\\n    start_time = time.time()\\n\\n    # Definiamo il modello base\\n    gb_model = GradientBoostingClassifier(random_state=42)\\n\\n    # Definiamo la griglia che ha prodotto i risultati migliori\\n    param_grid = {\\n        \\'n_estimators\\': [300, 500],\\n        \\'learning_rate\\': [0.05, 0.1],\\n        \\'max_depth\\': [5, 7]\\n    }\\n    # (Ho ristretto la griglia ai valori vicini a quelli vincenti per velocizzare)\\n\\n    # Definiamo la Cross-Validation\\n    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\\n\\n    # Inizializza GridSearch\\n    grid_search = GridSearchCV(\\n        estimator=gb_model, \\n        param_grid=param_grid, \\n        scoring=\\'accuracy\\', \\n        cv=kf, \\n        verbose=2, # Mostra i progressi\\n        n_jobs=-1  # Usa tutti i processori\\n    )\\n\\n    grid_search.fit(X, y)\\n\\n    print(\"\\n--- üìä Risultati Ottimizzazione ---\")\\n    print(f\"Migliore Accuratezza in Cross-Validation: {grid_search.best_score_:.4f}\")\\n    print(f\"Migliori Iperparametri Trovati: {grid_search.best_params_}\")\\n\\n    end_time = time.time()\\n    print(f\"Tempo di ottimizzazione: {(end_time - start_time) / 60:.2f} minuti\")\\n\\n    # === 5. CREAZIONE SUBMISSION ===\\n    print(\"\\n--- 5. Creazione File di Submission ---\")\\n\\n    best_model = grid_search.best_estimator_\\n\\n    predictions = best_model.predict(X_test)\\n\\n    submission_df = pd.DataFrame({\\n        \\'battle_id\\': test_df[\\'battle_id\\'],\\n        TARGET: predictions\\n    })\\n\\n    submission_df.to_csv(\\'submission1.csv\\', index=False)\\n    print(\"File \\'submission1.csv\\' creato con successo!\")\\n\\n# --- Esecuzione dello script ---\\nif __name__ == \"__main__\":\\n    main()'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict \n",
    "\n",
    "# --- Importazioni dal tuo file di utility ---\n",
    "# Assicurati che 'start_utils.py' sia nella stessa cartella\n",
    "from start_utils import create_features, read_train_data, read_test_data\n",
    "\n",
    "# --- Importazioni per il Modello Avanzato ---\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "\n",
    "def main():\n",
    "    # Ignora i warning per un output pi√π pulito\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    \n",
    "    # === 1. CARICAMENTO DATI ===\n",
    "    print(\"--- 1. Caricamento Dati ---\")\n",
    "    COMPETITION_NAME = 'fds-pokemon-battles-prediction-2025'\n",
    "    # Modifica il percorso se 'input' non √® nella stessa cartella di 'start.py'\n",
    "    DATA_PATH = 'input' \n",
    "    \n",
    "    train_file_path = os.path.join(DATA_PATH, COMPETITION_NAME, 'train.jsonl')\n",
    "    test_file_path = os.path.join(DATA_PATH, COMPETITION_NAME, 'test.jsonl')\n",
    "\n",
    "    try:\n",
    "        train_data = read_train_data(train_file_path)\n",
    "        test_data = read_test_data(test_file_path)\n",
    "        print(f\"Dati di training caricati: {len(train_data)} battaglie.\")\n",
    "        print(f\"Dati di test caricati: {len(test_data)} battaglie.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERRORE: Dati non trovati. Assicurati che la cartella '{DATA_PATH}/{COMPETITION_NAME}' esista.\")\n",
    "        return\n",
    "\n",
    "    # === 2. CREAZIONE FEATURE ===\n",
    "    print(\"\\n--- 2. Creazione Feature (Feature Engineering) ---\")\n",
    "    \n",
    "    print(\"Processing training data...\")\n",
    "    train_df = create_features(train_data)\n",
    "    \n",
    "    print(\"\\nProcessing test data...\")\n",
    "    test_df = create_features(test_data, is_test=True)\n",
    "\n",
    "    # === 3. SELEZIONE FEATURE (Il set vincente!) ===\n",
    "    print(\"\\n--- 3. Selezione Feature (Pre-Training) ---\")\n",
    "\n",
    "    # Questa √® la lista di feature che ha dato i risultati migliori (96.31%)\n",
    "    # Derivata dalla nostra analisi di importanza precedente.\n",
    "    TOP_FEATURES = [\n",
    "        'status_change_diff',\n",
    "        'diff_final_schieramento',\n",
    "        'diff_final_hp',\n",
    "        'p1_bad_status_advantage',\n",
    "        'p1_pct_final_hp',\n",
    "        'p2_n_pokemon_use',\n",
    "        'p2_hp_std',\n",
    "        'diff_hp',\n",
    "        'p1_hp_std',\n",
    "        'hp_delta_std'\n",
    "        # Aggiungi qui altre feature che erano nel tuo 'TOP_FEATURES' se diverse\n",
    "    ]\n",
    "    \n",
    "    # Aggiungiamo le nuove feature di danno che abbiamo integrato\n",
    "    TOP_FEATURES.extend(['diff_move_damage_mean', 'diff_move_damage_max'])\n",
    "    \n",
    "    # Rimuoviamo duplicati se ce ne sono\n",
    "    TOP_FEATURES = sorted(list(set(TOP_FEATURES))) \n",
    "    \n",
    "    print(f\"Utilizzo di {len(TOP_FEATURES)} feature selezionate.\")\n",
    "\n",
    "    TARGET = 'player_won'\n",
    "    \n",
    "    # Creiamo i set di dati X/y usando SOLO le feature migliori\n",
    "    X = train_df[TOP_FEATURES]\n",
    "    y = train_df[TARGET]\n",
    "    \n",
    "    # Prepariamo il set di test\n",
    "    X_test = test_df[TOP_FEATURES]\n",
    "\n",
    "    # === 4. OTTIMIZZAZIONE MODELLO (Grid Search) ===\n",
    "    print(\"\\n--- 4. Ottimizzazione Modello (Grid Search) ---\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Definiamo il modello base\n",
    "    gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "    # Definiamo la griglia che ha prodotto i risultati migliori\n",
    "    param_grid = {\n",
    "        'n_estimators': [300, 500],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [5, 7]\n",
    "    }\n",
    "    # (Ho ristretto la griglia ai valori vicini a quelli vincenti per velocizzare)\n",
    "\n",
    "    # Definiamo la Cross-Validation\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Inizializza GridSearch\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=gb_model, \n",
    "        param_grid=param_grid, \n",
    "        scoring='accuracy', \n",
    "        cv=kf, \n",
    "        verbose=2, # Mostra i progressi\n",
    "        n_jobs=-1  # Usa tutti i processori\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    print(\"\\n--- üìä Risultati Ottimizzazione ---\")\n",
    "    print(f\"Migliore Accuratezza in Cross-Validation: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Migliori Iperparametri Trovati: {grid_search.best_params_}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Tempo di ottimizzazione: {(end_time - start_time) / 60:.2f} minuti\")\n",
    "\n",
    "    # === 5. CREAZIONE SUBMISSION ===\n",
    "    print(\"\\n--- 5. Creazione File di Submission ---\")\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    predictions = best_model.predict(X_test)\n",
    "\n",
    "    submission_df = pd.DataFrame({\n",
    "        'battle_id': test_df['battle_id'],\n",
    "        TARGET: predictions\n",
    "    })\n",
    "\n",
    "    submission_df.to_csv('submission1.csv', index=False)\n",
    "    print(\"File 'submission1.csv' creato con successo!\")\n",
    "\n",
    "# --- Esecuzione dello script ---\n",
    "if __name__ == \"__main__\":\n",
    "    main()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d19071",
   "metadata": {},
   "source": [
    "uso modelli random forest e ada boosting e poi li faccio votare tra loro per capire quale √® l'aproccio migliore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37565461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Caricamento Dati ---\n",
      "Dati di training caricati: 10000 battaglie.\n",
      "Dati di test caricati: 5000 battaglie.\n",
      "\n",
      "--- 2. Creazione Feature (Feature Engineering) ---\n",
      "Processing training data...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "create_features() missing 1 required positional argument: 'POKEDEX'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 127\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# --- Esecuzione dello script ---\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- 2. Creazione Feature (Feature Engineering) ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mProcessing training data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m train_df = \u001b[43mcreate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mProcessing test data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     46\u001b[39m test_df = create_features(test_data, is_test=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: create_features() missing 1 required positional argument: 'POKEDEX'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict \n",
    "\n",
    "# --- Importazioni dal tuo file di utility ---\n",
    "from start_utils import build_pokedex, create_features, read_train_data, read_test_data\n",
    "\n",
    "# --- Importazioni per i Nuovi Modelli ---\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "\n",
    "def main():\n",
    "    # Ignora i warning per un output pi√π pulito\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    \n",
    "    # === 1. CARICAMENTO DATI ===\n",
    "    print(\"--- 1. Caricamento Dati ---\")\n",
    "    COMPETITION_NAME = 'fds-pokemon-battles-prediction-2025'\n",
    "    DATA_PATH = 'input' \n",
    "    \n",
    "    train_file_path = os.path.join(DATA_PATH, COMPETITION_NAME, 'train.jsonl')\n",
    "    test_file_path = os.path.join(DATA_PATH, COMPETITION_NAME, 'test.jsonl')\n",
    "\n",
    "    try:\n",
    "        train_data = read_train_data(train_file_path)\n",
    "        test_data = read_test_data(test_file_path)\n",
    "        print(f\"Dati di training caricati: {len(train_data)} battaglie.\")\n",
    "        print(f\"Dati di test caricati: {len(test_data)} battaglie.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERRORE: Dati non trovati. Assicurati che la cartella '{DATA_PATH}/{COMPETITION_NAME}' esista.\")\n",
    "        return\n",
    "    \n",
    "    # --- 2. COSTRUZIONE POKEDEX  ---\n",
    "    # Combiniamo i dati per trovare tutti i Pok√©mon\n",
    "    all_data = train_data + test_data\n",
    "    # CHIAMIAMO LA FUNZIONE per creare il dizionario\n",
    "    POKEDEX = build_pokedex(all_data)\n",
    "\n",
    "    # === 2. CREAZIONE FEATURE ===\n",
    "    print(\"\\n--- 2. Creazione Feature (Feature Engineering) ---\")\n",
    "    \n",
    "    print(\"Processing training data...\")\n",
    "    train_df = create_features(train_data,POKEDEX)\n",
    "    \n",
    "    print(\"\\nProcessing test data...\")\n",
    "    test_df = create_features(test_data,POKEDEX, is_test=True)\n",
    "\n",
    "    # === 3. SELEZIONE FEATURE ===\n",
    "    print(\"\\n--- 3. Selezione Feature (Pre-Training) ---\")\n",
    "\n",
    "    # Usiamo le feature che sappiamo essere forti\n",
    "    # (Sentiti libero di usare la tua lista 'TOP_FEATURES' se l'hai salvata)\n",
    "    features_da_usare = [col for col in train_df.columns if col not in ['battle_id', 'player_won']]\n",
    "    \n",
    "    print(f\"Utilizzo di {len(features_da_usare)} feature totali.\")\n",
    "\n",
    "    TARGET = 'player_won'\n",
    "    \n",
    "    X = train_df[features_da_usare]\n",
    "    y = train_df[TARGET]\n",
    "    X_test = test_df[features_da_usare]\n",
    "\n",
    "    # === 4. DEFINIZIONE MODELLI (RF + AdaBoost) ===\n",
    "    print(\"\\n--- 4. Definizione Modelli Non Lineari ---\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Modello 1: RandomForestClassifier\n",
    "    # (Un buon punto di partenza: 300 alberi, profondit√† massima 7)\n",
    "    clf_rf = RandomForestClassifier(\n",
    "        n_estimators=300, \n",
    "        max_depth=7, \n",
    "        random_state=42, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Modello 2: AdaBoostClassifier\n",
    "    # (Un buon punto di partenza: 500 stimatori, learning rate 0.1)\n",
    "    clf_ada = AdaBoostClassifier(\n",
    "        n_estimators=500, \n",
    "        learning_rate=0.1, \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Modello 3: VotingClassifier\n",
    "    # Combina i due modelli. 'voting='soft'' fa la media delle probabilit√† (di solito √® meglio).\n",
    "    print(\"Combinazione dei modelli in un VotingClassifier...\")\n",
    "    voting_clf = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('rf', clf_rf),  # (nome, modello)\n",
    "            ('ada', clf_ada) # (nome, modello)\n",
    "        ],\n",
    "        voting='soft' # 'soft' fa la media delle probabilit√†, 'hard' fa votare 0 o 1\n",
    "    )\n",
    "    \n",
    "\n",
    "    # === 5. VALIDAZIONE VELOCE (Opzionale) ===\n",
    "    # Controlliamo rapidamente le prestazioni prima del training finale\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    print(\"\\nValidazione del VotingClassifier (potrebbe richiedere un minuto)...\")\n",
    "    voting_scores = cross_val_score(voting_clf, X, y, cv=kf, scoring='accuracy', n_jobs=-1)\n",
    "    print(f\"Accuratezza media CV del VotingClassifier: {np.mean(voting_scores):.4f}\")\n",
    "\n",
    "    # === 6. TRAINING FINALE E SUBMISSION ===\n",
    "    print(\"\\n--- 6. Training Modello Finale e Submission ---\")\n",
    "    \n",
    "    print(\"Addestramento del VotingClassifier su tutti i dati...\")\n",
    "    voting_clf.fit(X, y) # Addestra il modello combinato\n",
    "    \n",
    "    print(\"Creazione delle predizioni...\")\n",
    "    predictions = voting_clf.predict(X_test)\n",
    "    \n",
    "    submission_df = pd.DataFrame({\n",
    "        'battle_id': test_df['battle_id'],\n",
    "        TARGET: predictions\n",
    "    })\n",
    "\n",
    "    submission_df.to_csv('submission2.csv', index=False)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"\\nFile 'submission2.csv' creato con successo!\")\n",
    "    print(f\"Tempo totale esecuzione: {(end_time - start_time) / 60:.2f} minuti\")\n",
    "\n",
    "# --- Esecuzione dello script ---\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
